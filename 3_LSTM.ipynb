{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Yy4aRMXN4cFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "train = pd.read_csv('/content/drive/MyDrive/Thesis/Train_dataset_3.csv', low_memory=False)\n",
        "test = pd.read_csv('/content/drive/MyDrive/Thesis/Test_dataset_3.csv', low_memory=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUXc5Q005UR9",
        "outputId": "9a341681-9dbe-4dd5-862e-b944b3338c44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_repeats = 5\n",
        "metrics = {\n",
        "    'accuracy': [],\n",
        "    'precision': [],\n",
        "    'recall': [],\n",
        "    'auc': [],\n",
        "    'loss': []\n",
        "}"
      ],
      "metadata": {
        "id": "ga55Qev69WQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequences(data, seq_length=5):\n",
        "    sequences = []\n",
        "    targets = []\n",
        "    for i in range(len(data) - seq_length):\n",
        "        seq = data.iloc[i:i+seq_length, :-1].values\n",
        "        label = data.iloc[i+seq_length, -1]\n",
        "        sequences.append(seq)\n",
        "        targets.append(label)\n",
        "    return np.array(sequences), np.array(targets)\n",
        "\n",
        "\n",
        "SEQ_LENGTH = 5\n",
        "FEATURES = train.shape[1] - 1\n",
        "\n",
        "\n",
        "X_train, y_train = create_sequences(train, SEQ_LENGTH)\n",
        "\n",
        "\n",
        "X_test, y_test = create_sequences(test, SEQ_LENGTH)"
      ],
      "metadata": {
        "id": "cKn72PVl4pLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)"
      ],
      "metadata": {
        "id": "dS_sNBIP4ruG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "    ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n",
        "]"
      ],
      "metadata": {
        "id": "fbFF-RprA7r_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for run in range(n_repeats):\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Run {run+1}/{n_repeats}\")\n",
        "    print(f\"{'='*50}\")\n",
        "\n",
        "    model = Sequential([\n",
        "        LSTM(128, input_shape=(SEQ_LENGTH, FEATURES), return_sequences=True),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        LSTM(128, return_sequences=False),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(64, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    optimizer = Adam(learning_rate=0.0001)\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy',\n",
        "                           tf.keras.metrics.Precision(name='precision'),\n",
        "                           tf.keras.metrics.Recall(name='recall'),\n",
        "                           tf.keras.metrics.AUC(name='auc')])\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=100,\n",
        "        batch_size=64,\n",
        "        callbacks=callbacks,\n",
        "        class_weight={0: 1, 1: 2},\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    results = model.evaluate(X_test, y_test, verbose=0)\n",
        "    metrics['loss'].append(results[0])\n",
        "    metrics['accuracy'].append(results[1])\n",
        "    metrics['precision'].append(results[2])\n",
        "    metrics['recall'].append(results[3])\n",
        "    metrics['auc'].append(results[4])\n",
        "\n",
        "    print(f\"\\nRun {run+1} Results:\")\n",
        "    print(f\"Test Loss: {results[0]:.4f}\")\n",
        "    print(f\"Test Accuracy: {results[1]:.4f}\")\n",
        "    print(f\"Test Precision: {results[2]:.4f}\")\n",
        "    print(f\"Test Recall: {results[3]:.4f}\")\n",
        "    print(f\"Test AUC: {results[4]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gONhjr1p5X8R",
        "outputId": "56c4290c-96d1-4389-ab2e-21b7b524aa66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Run 1/5\n",
            "==================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m497/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8287 - auc: 0.9073 - loss: 0.5311 - precision: 0.8026 - recall: 0.8657"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 15ms/step - accuracy: 0.8290 - auc: 0.9076 - loss: 0.5299 - precision: 0.8029 - recall: 0.8662 - val_accuracy: 0.9312 - val_auc: 0.9844 - val_loss: 0.2042 - val_precision: 0.8995 - val_recall: 0.9710\n",
            "Epoch 2/100\n",
            "\u001b[1m497/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9187 - auc: 0.9754 - loss: 0.2771 - precision: 0.8901 - recall: 0.9547"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9187 - auc: 0.9754 - loss: 0.2770 - precision: 0.8902 - recall: 0.9547 - val_accuracy: 0.9426 - val_auc: 0.9879 - val_loss: 0.1529 - val_precision: 0.9177 - val_recall: 0.9725\n",
            "Epoch 3/100\n",
            "\u001b[1m499/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9290 - auc: 0.9802 - loss: 0.2450 - precision: 0.9059 - recall: 0.9590"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9290 - auc: 0.9802 - loss: 0.2450 - precision: 0.9059 - recall: 0.9590 - val_accuracy: 0.9519 - val_auc: 0.9903 - val_loss: 0.1252 - val_precision: 0.9460 - val_recall: 0.9585\n",
            "Epoch 4/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9330 - auc: 0.9830 - loss: 0.2278 - precision: 0.9093 - recall: 0.9609 - val_accuracy: 0.9462 - val_auc: 0.9914 - val_loss: 0.1347 - val_precision: 0.9214 - val_recall: 0.9758\n",
            "Epoch 5/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9419 - auc: 0.9863 - loss: 0.2056 - precision: 0.9233 - recall: 0.9644 - val_accuracy: 0.9489 - val_auc: 0.9927 - val_loss: 0.1274 - val_precision: 0.9228 - val_recall: 0.9797\n",
            "Epoch 6/100\n",
            "\u001b[1m498/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9406 - auc: 0.9871 - loss: 0.1997 - precision: 0.9217 - recall: 0.9639"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.9406 - auc: 0.9871 - loss: 0.1997 - precision: 0.9217 - recall: 0.9639 - val_accuracy: 0.9596 - val_auc: 0.9935 - val_loss: 0.1038 - val_precision: 0.9483 - val_recall: 0.9722\n",
            "Epoch 7/100\n",
            "\u001b[1m496/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9462 - auc: 0.9890 - loss: 0.1832 - precision: 0.9282 - recall: 0.9674"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9462 - auc: 0.9890 - loss: 0.1832 - precision: 0.9282 - recall: 0.9675 - val_accuracy: 0.9622 - val_auc: 0.9947 - val_loss: 0.0999 - val_precision: 0.9475 - val_recall: 0.9787\n",
            "Epoch 8/100\n",
            "\u001b[1m497/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9514 - auc: 0.9900 - loss: 0.1707 - precision: 0.9346 - recall: 0.9704"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9514 - auc: 0.9900 - loss: 0.1708 - precision: 0.9346 - recall: 0.9704 - val_accuracy: 0.9599 - val_auc: 0.9953 - val_loss: 0.0993 - val_precision: 0.9414 - val_recall: 0.9808\n",
            "Epoch 9/100\n",
            "\u001b[1m496/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9523 - auc: 0.9912 - loss: 0.1604 - precision: 0.9330 - recall: 0.9739"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9523 - auc: 0.9912 - loss: 0.1604 - precision: 0.9330 - recall: 0.9739 - val_accuracy: 0.9639 - val_auc: 0.9955 - val_loss: 0.0931 - val_precision: 0.9464 - val_recall: 0.9835\n",
            "Epoch 10/100\n",
            "\u001b[1m498/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9533 - auc: 0.9915 - loss: 0.1580 - precision: 0.9350 - recall: 0.9739"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.9533 - auc: 0.9915 - loss: 0.1580 - precision: 0.9350 - recall: 0.9739 - val_accuracy: 0.9665 - val_auc: 0.9959 - val_loss: 0.0866 - val_precision: 0.9545 - val_recall: 0.9797\n",
            "Epoch 11/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9585 - auc: 0.9926 - loss: 0.1474 - precision: 0.9426 - recall: 0.9762 - val_accuracy: 0.9459 - val_auc: 0.9947 - val_loss: 0.1443 - val_precision: 0.9084 - val_recall: 0.9918\n",
            "Epoch 12/100\n",
            "\u001b[1m498/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9604 - auc: 0.9929 - loss: 0.1417 - precision: 0.9460 - recall: 0.9764"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9604 - auc: 0.9929 - loss: 0.1417 - precision: 0.9460 - recall: 0.9764 - val_accuracy: 0.9692 - val_auc: 0.9963 - val_loss: 0.0787 - val_precision: 0.9578 - val_recall: 0.9818\n",
            "Epoch 13/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9598 - auc: 0.9928 - loss: 0.1413 - precision: 0.9455 - recall: 0.9756"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9598 - auc: 0.9928 - loss: 0.1413 - precision: 0.9455 - recall: 0.9756 - val_accuracy: 0.9727 - val_auc: 0.9968 - val_loss: 0.0700 - val_precision: 0.9676 - val_recall: 0.9783\n",
            "Epoch 14/100\n",
            "\u001b[1m496/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9607 - auc: 0.9930 - loss: 0.1387 - precision: 0.9459 - recall: 0.9774"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9607 - auc: 0.9930 - loss: 0.1387 - precision: 0.9459 - recall: 0.9774 - val_accuracy: 0.9742 - val_auc: 0.9972 - val_loss: 0.0664 - val_precision: 0.9707 - val_recall: 0.9780\n",
            "Epoch 15/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9652 - auc: 0.9947 - loss: 0.1225 - precision: 0.9537 - recall: 0.9779 - val_accuracy: 0.9751 - val_auc: 0.9973 - val_loss: 0.0672 - val_precision: 0.9691 - val_recall: 0.9815\n",
            "Epoch 16/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9638 - auc: 0.9941 - loss: 0.1273 - precision: 0.9504 - recall: 0.9789 - val_accuracy: 0.9755 - val_auc: 0.9971 - val_loss: 0.0673 - val_precision: 0.9666 - val_recall: 0.9850\n",
            "Epoch 17/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9665 - auc: 0.9948 - loss: 0.1180 - precision: 0.9542 - recall: 0.9803 - val_accuracy: 0.9737 - val_auc: 0.9971 - val_loss: 0.0732 - val_precision: 0.9608 - val_recall: 0.9877\n",
            "Epoch 18/100\n",
            "\u001b[1m495/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9670 - auc: 0.9944 - loss: 0.1191 - precision: 0.9525 - recall: 0.9818"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9670 - auc: 0.9944 - loss: 0.1190 - precision: 0.9525 - recall: 0.9818 - val_accuracy: 0.9776 - val_auc: 0.9975 - val_loss: 0.0638 - val_precision: 0.9702 - val_recall: 0.9855\n",
            "Epoch 19/100\n",
            "\u001b[1m495/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9712 - auc: 0.9964 - loss: 0.1010 - precision: 0.9595 - recall: 0.9839"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9712 - auc: 0.9964 - loss: 0.1010 - precision: 0.9595 - recall: 0.9839 - val_accuracy: 0.9791 - val_auc: 0.9976 - val_loss: 0.0591 - val_precision: 0.9764 - val_recall: 0.9820\n",
            "Epoch 20/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9698 - auc: 0.9950 - loss: 0.1120 - precision: 0.9584 - recall: 0.9826 - val_accuracy: 0.9796 - val_auc: 0.9977 - val_loss: 0.0601 - val_precision: 0.9724 - val_recall: 0.9872\n",
            "Epoch 21/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9697 - auc: 0.9954 - loss: 0.1122 - precision: 0.9592 - recall: 0.9814 - val_accuracy: 0.9771 - val_auc: 0.9977 - val_loss: 0.0628 - val_precision: 0.9865 - val_recall: 0.9675\n",
            "Epoch 22/100\n",
            "\u001b[1m497/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9721 - auc: 0.9962 - loss: 0.1007 - precision: 0.9605 - recall: 0.9851"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9721 - auc: 0.9962 - loss: 0.1007 - precision: 0.9604 - recall: 0.9851 - val_accuracy: 0.9799 - val_auc: 0.9976 - val_loss: 0.0556 - val_precision: 0.9741 - val_recall: 0.9860\n",
            "Epoch 23/100\n",
            "\u001b[1m498/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9728 - auc: 0.9965 - loss: 0.0962 - precision: 0.9622 - recall: 0.9842"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9728 - auc: 0.9965 - loss: 0.0962 - precision: 0.9622 - recall: 0.9842 - val_accuracy: 0.9809 - val_auc: 0.9979 - val_loss: 0.0554 - val_precision: 0.9744 - val_recall: 0.9877\n",
            "Epoch 24/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9735 - auc: 0.9962 - loss: 0.0988 - precision: 0.9632 - recall: 0.9847 - val_accuracy: 0.9786 - val_auc: 0.9978 - val_loss: 0.0621 - val_precision: 0.9668 - val_recall: 0.9912\n",
            "Epoch 25/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9746 - auc: 0.9963 - loss: 0.0959 - precision: 0.9645 - recall: 0.9851 - val_accuracy: 0.9721 - val_auc: 0.9969 - val_loss: 0.0763 - val_precision: 0.9536 - val_recall: 0.9925\n",
            "Epoch 26/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.9748 - auc: 0.9965 - loss: 0.0913 - precision: 0.9646 - recall: 0.9857 - val_accuracy: 0.9761 - val_auc: 0.9976 - val_loss: 0.0675 - val_precision: 0.9610 - val_recall: 0.9925\n",
            "Epoch 27/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9762 - auc: 0.9972 - loss: 0.0869 - precision: 0.9675 - recall: 0.9853 - val_accuracy: 0.9731 - val_auc: 0.9971 - val_loss: 0.0757 - val_precision: 0.9561 - val_recall: 0.9918\n",
            "Epoch 28/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9759 - auc: 0.9965 - loss: 0.0916 - precision: 0.9680 - recall: 0.9844 - val_accuracy: 0.9786 - val_auc: 0.9978 - val_loss: 0.0594 - val_precision: 0.9671 - val_recall: 0.9910\n",
            "Epoch 29/100\n",
            "\u001b[1m496/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9771 - auc: 0.9965 - loss: 0.0871 - precision: 0.9677 - recall: 0.9870"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9772 - auc: 0.9965 - loss: 0.0871 - precision: 0.9677 - recall: 0.9870 - val_accuracy: 0.9829 - val_auc: 0.9984 - val_loss: 0.0485 - val_precision: 0.9830 - val_recall: 0.9827\n",
            "Epoch 30/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9779 - auc: 0.9970 - loss: 0.0831 - precision: 0.9697 - recall: 0.9868 - val_accuracy: 0.9834 - val_auc: 0.9983 - val_loss: 0.0508 - val_precision: 0.9766 - val_recall: 0.9905\n",
            "Epoch 31/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9774 - auc: 0.9972 - loss: 0.0811 - precision: 0.9690 - recall: 0.9866 - val_accuracy: 0.9821 - val_auc: 0.9984 - val_loss: 0.0492 - val_precision: 0.9763 - val_recall: 0.9883\n",
            "Epoch 32/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9786 - auc: 0.9974 - loss: 0.0799 - precision: 0.9697 - recall: 0.9880 - val_accuracy: 0.9821 - val_auc: 0.9983 - val_loss: 0.0492 - val_precision: 0.9871 - val_recall: 0.9770\n",
            "Epoch 33/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9795 - auc: 0.9970 - loss: 0.0795 - precision: 0.9720 - recall: 0.9872 - val_accuracy: 0.9831 - val_auc: 0.9981 - val_loss: 0.0487 - val_precision: 0.9768 - val_recall: 0.9898\n",
            "Epoch 34/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9783 - auc: 0.9974 - loss: 0.0789 - precision: 0.9698 - recall: 0.9873 - val_accuracy: 0.9821 - val_auc: 0.9982 - val_loss: 0.0501 - val_precision: 0.9739 - val_recall: 0.9908\n",
            "Epoch 35/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9785 - auc: 0.9975 - loss: 0.0763 - precision: 0.9692 - recall: 0.9883"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9785 - auc: 0.9975 - loss: 0.0763 - precision: 0.9692 - recall: 0.9883 - val_accuracy: 0.9854 - val_auc: 0.9985 - val_loss: 0.0447 - val_precision: 0.9865 - val_recall: 0.9843\n",
            "Epoch 36/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9796 - auc: 0.9978 - loss: 0.0734 - precision: 0.9724 - recall: 0.9878 - val_accuracy: 0.9837 - val_auc: 0.9983 - val_loss: 0.0473 - val_precision: 0.9889 - val_recall: 0.9785\n",
            "Epoch 37/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9792 - auc: 0.9974 - loss: 0.0779 - precision: 0.9716 - recall: 0.9872 - val_accuracy: 0.9845 - val_auc: 0.9982 - val_loss: 0.0469 - val_precision: 0.9850 - val_recall: 0.9840\n",
            "Epoch 38/100\n",
            "\u001b[1m497/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9819 - auc: 0.9980 - loss: 0.0676 - precision: 0.9737 - recall: 0.9903"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9819 - auc: 0.9980 - loss: 0.0677 - precision: 0.9737 - recall: 0.9903 - val_accuracy: 0.9849 - val_auc: 0.9985 - val_loss: 0.0433 - val_precision: 0.9840 - val_recall: 0.9858\n",
            "Epoch 39/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9811 - auc: 0.9977 - loss: 0.0690 - precision: 0.9740 - recall: 0.9887 - val_accuracy: 0.9741 - val_auc: 0.9983 - val_loss: 0.0675 - val_precision: 0.9932 - val_recall: 0.9548\n",
            "Epoch 40/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9824 - auc: 0.9982 - loss: 0.0645 - precision: 0.9747 - recall: 0.9905 - val_accuracy: 0.9842 - val_auc: 0.9984 - val_loss: 0.0446 - val_precision: 0.9874 - val_recall: 0.9810\n",
            "Epoch 41/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9817 - auc: 0.9978 - loss: 0.0669 - precision: 0.9751 - recall: 0.9889 - val_accuracy: 0.9800 - val_auc: 0.9985 - val_loss: 0.0532 - val_precision: 0.9921 - val_recall: 0.9678\n",
            "Epoch 42/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9815 - auc: 0.9978 - loss: 0.0687 - precision: 0.9745 - recall: 0.9889 - val_accuracy: 0.9825 - val_auc: 0.9985 - val_loss: 0.0484 - val_precision: 0.9728 - val_recall: 0.9927\n",
            "Epoch 43/100\n",
            "\u001b[1m497/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9826 - auc: 0.9979 - loss: 0.0651 - precision: 0.9758 - recall: 0.9898"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9826 - auc: 0.9979 - loss: 0.0651 - precision: 0.9758 - recall: 0.9898 - val_accuracy: 0.9875 - val_auc: 0.9983 - val_loss: 0.0409 - val_precision: 0.9858 - val_recall: 0.9893\n",
            "Epoch 44/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9800 - auc: 0.9977 - loss: 0.0692 - precision: 0.9711 - recall: 0.9892 - val_accuracy: 0.9817 - val_auc: 0.9984 - val_loss: 0.0510 - val_precision: 0.9711 - val_recall: 0.9930\n",
            "Epoch 45/100\n",
            "\u001b[1m499/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9836 - auc: 0.9984 - loss: 0.0592 - precision: 0.9760 - recall: 0.9914"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9836 - auc: 0.9984 - loss: 0.0593 - precision: 0.9760 - recall: 0.9914 - val_accuracy: 0.9856 - val_auc: 0.9987 - val_loss: 0.0407 - val_precision: 0.9824 - val_recall: 0.9890\n",
            "Epoch 46/100\n",
            "\u001b[1m499/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9840 - auc: 0.9983 - loss: 0.0596 - precision: 0.9780 - recall: 0.9908"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9840 - auc: 0.9983 - loss: 0.0596 - precision: 0.9780 - recall: 0.9908 - val_accuracy: 0.9861 - val_auc: 0.9984 - val_loss: 0.0397 - val_precision: 0.9843 - val_recall: 0.9880\n",
            "Epoch 47/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9837 - auc: 0.9982 - loss: 0.0621 - precision: 0.9765 - recall: 0.9911 - val_accuracy: 0.9846 - val_auc: 0.9989 - val_loss: 0.0428 - val_precision: 0.9919 - val_recall: 0.9772\n",
            "Epoch 48/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9849 - auc: 0.9981 - loss: 0.0600 - precision: 0.9784 - recall: 0.9917 - val_accuracy: 0.9776 - val_auc: 0.9975 - val_loss: 0.0636 - val_precision: 0.9618 - val_recall: 0.9948\n",
            "Epoch 49/100\n",
            "\u001b[1m499/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9825 - auc: 0.9977 - loss: 0.0631 - precision: 0.9749 - recall: 0.9907"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9825 - auc: 0.9977 - loss: 0.0631 - precision: 0.9749 - recall: 0.9907 - val_accuracy: 0.9867 - val_auc: 0.9987 - val_loss: 0.0388 - val_precision: 0.9841 - val_recall: 0.9895\n",
            "Epoch 50/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9846 - auc: 0.9985 - loss: 0.0574 - precision: 0.9781 - recall: 0.9916 - val_accuracy: 0.9841 - val_auc: 0.9985 - val_loss: 0.0429 - val_precision: 0.9773 - val_recall: 0.9912\n",
            "Epoch 51/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9836 - auc: 0.9980 - loss: 0.0611 - precision: 0.9769 - recall: 0.9909 - val_accuracy: 0.9857 - val_auc: 0.9986 - val_loss: 0.0412 - val_precision: 0.9793 - val_recall: 0.9925\n",
            "Epoch 52/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9857 - auc: 0.9985 - loss: 0.0533 - precision: 0.9806 - recall: 0.9912 - val_accuracy: 0.9777 - val_auc: 0.9978 - val_loss: 0.0642 - val_precision: 0.9616 - val_recall: 0.9952\n",
            "Epoch 53/100\n",
            "\u001b[1m495/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9858 - auc: 0.9985 - loss: 0.0556 - precision: 0.9795 - recall: 0.9921"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9858 - auc: 0.9985 - loss: 0.0556 - precision: 0.9795 - recall: 0.9921 - val_accuracy: 0.9877 - val_auc: 0.9989 - val_loss: 0.0356 - val_precision: 0.9873 - val_recall: 0.9883\n",
            "Epoch 54/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9859 - auc: 0.9987 - loss: 0.0530 - precision: 0.9802 - recall: 0.9918 - val_accuracy: 0.9871 - val_auc: 0.9985 - val_loss: 0.0379 - val_precision: 0.9865 - val_recall: 0.9877\n",
            "Epoch 55/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.9856 - auc: 0.9982 - loss: 0.0554 - precision: 0.9805 - recall: 0.9911 - val_accuracy: 0.9805 - val_auc: 0.9988 - val_loss: 0.0503 - val_precision: 0.9936 - val_recall: 0.9672\n",
            "Epoch 56/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9846 - auc: 0.9982 - loss: 0.0563 - precision: 0.9789 - recall: 0.9907 - val_accuracy: 0.9875 - val_auc: 0.9989 - val_loss: 0.0358 - val_precision: 0.9873 - val_recall: 0.9877\n",
            "Epoch 57/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9859 - auc: 0.9984 - loss: 0.0543 - precision: 0.9812 - recall: 0.9908"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9859 - auc: 0.9984 - loss: 0.0543 - precision: 0.9812 - recall: 0.9908 - val_accuracy: 0.9881 - val_auc: 0.9990 - val_loss: 0.0356 - val_precision: 0.9880 - val_recall: 0.9883\n",
            "Epoch 58/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9860 - auc: 0.9984 - loss: 0.0535 - precision: 0.9800 - recall: 0.9923 - val_accuracy: 0.9866 - val_auc: 0.9991 - val_loss: 0.0389 - val_precision: 0.9810 - val_recall: 0.9925\n",
            "Epoch 59/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9855 - auc: 0.9987 - loss: 0.0511 - precision: 0.9789 - recall: 0.9926 - val_accuracy: 0.9865 - val_auc: 0.9987 - val_loss: 0.0361 - val_precision: 0.9853 - val_recall: 0.9877\n",
            "Epoch 60/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9878 - auc: 0.9985 - loss: 0.0498 - precision: 0.9825 - recall: 0.9931 - val_accuracy: 0.9867 - val_auc: 0.9990 - val_loss: 0.0369 - val_precision: 0.9902 - val_recall: 0.9833\n",
            "Epoch 61/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9857 - auc: 0.9987 - loss: 0.0529 - precision: 0.9794 - recall: 0.9920 - val_accuracy: 0.9839 - val_auc: 0.9988 - val_loss: 0.0429 - val_precision: 0.9931 - val_recall: 0.9745\n",
            "Epoch 62/100\n",
            "\u001b[1m498/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9854 - auc: 0.9985 - loss: 0.0521 - precision: 0.9796 - recall: 0.9917"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.9854 - auc: 0.9985 - loss: 0.0521 - precision: 0.9796 - recall: 0.9917 - val_accuracy: 0.9877 - val_auc: 0.9990 - val_loss: 0.0346 - val_precision: 0.9834 - val_recall: 0.9923\n",
            "Epoch 63/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9845 - auc: 0.9985 - loss: 0.0550 - precision: 0.9782 - recall: 0.9911 - val_accuracy: 0.9876 - val_auc: 0.9990 - val_loss: 0.0347 - val_precision: 0.9846 - val_recall: 0.9908\n",
            "Epoch 64/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.9874 - auc: 0.9989 - loss: 0.0466 - precision: 0.9834 - recall: 0.9917 - val_accuracy: 0.9866 - val_auc: 0.9987 - val_loss: 0.0369 - val_precision: 0.9814 - val_recall: 0.9920\n",
            "Epoch 65/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9872 - auc: 0.9990 - loss: 0.0454 - precision: 0.9821 - recall: 0.9926 - val_accuracy: 0.9877 - val_auc: 0.9989 - val_loss: 0.0365 - val_precision: 0.9824 - val_recall: 0.9933\n",
            "Epoch 66/100\n",
            "\u001b[1m498/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9878 - auc: 0.9989 - loss: 0.0460 - precision: 0.9829 - recall: 0.9930"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9878 - auc: 0.9989 - loss: 0.0460 - precision: 0.9829 - recall: 0.9930 - val_accuracy: 0.9881 - val_auc: 0.9990 - val_loss: 0.0342 - val_precision: 0.9837 - val_recall: 0.9927\n",
            "Epoch 67/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.9876 - auc: 0.9990 - loss: 0.0464 - precision: 0.9827 - recall: 0.9927 - val_accuracy: 0.9850 - val_auc: 0.9987 - val_loss: 0.0397 - val_precision: 0.9767 - val_recall: 0.9937\n",
            "Epoch 68/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9877 - auc: 0.9989 - loss: 0.0448 - precision: 0.9825 - recall: 0.9929 - val_accuracy: 0.9872 - val_auc: 0.9986 - val_loss: 0.0370 - val_precision: 0.9810 - val_recall: 0.9937\n",
            "Epoch 69/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9868 - auc: 0.9990 - loss: 0.0446 - precision: 0.9821 - recall: 0.9917 - val_accuracy: 0.9842 - val_auc: 0.9985 - val_loss: 0.0436 - val_precision: 0.9748 - val_recall: 0.9942\n",
            "Epoch 70/100\n",
            "\u001b[1m499/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9883 - auc: 0.9990 - loss: 0.0420 - precision: 0.9845 - recall: 0.9925"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9883 - auc: 0.9990 - loss: 0.0420 - precision: 0.9845 - recall: 0.9925 - val_accuracy: 0.9881 - val_auc: 0.9992 - val_loss: 0.0339 - val_precision: 0.9919 - val_recall: 0.9843\n",
            "Epoch 71/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9873 - auc: 0.9987 - loss: 0.0479 - precision: 0.9820 - recall: 0.9930 - val_accuracy: 0.9879 - val_auc: 0.9990 - val_loss: 0.0340 - val_precision: 0.9832 - val_recall: 0.9927\n",
            "Epoch 72/100\n",
            "\u001b[1m499/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9865 - auc: 0.9989 - loss: 0.0472 - precision: 0.9807 - recall: 0.9923"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9865 - auc: 0.9989 - loss: 0.0472 - precision: 0.9807 - recall: 0.9923 - val_accuracy: 0.9885 - val_auc: 0.9992 - val_loss: 0.0322 - val_precision: 0.9853 - val_recall: 0.9918\n",
            "Epoch 73/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9874 - auc: 0.9989 - loss: 0.0451 - precision: 0.9820 - recall: 0.9932 - val_accuracy: 0.9854 - val_auc: 0.9986 - val_loss: 0.0409 - val_precision: 0.9767 - val_recall: 0.9945\n",
            "Epoch 74/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9875 - auc: 0.9989 - loss: 0.0453 - precision: 0.9816 - recall: 0.9937 - val_accuracy: 0.9872 - val_auc: 0.9985 - val_loss: 0.0374 - val_precision: 0.9810 - val_recall: 0.9937\n",
            "Epoch 75/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.9883 - auc: 0.9988 - loss: 0.0430 - precision: 0.9836 - recall: 0.9931 - val_accuracy: 0.9872 - val_auc: 0.9989 - val_loss: 0.0354 - val_precision: 0.9810 - val_recall: 0.9937\n",
            "Epoch 76/100\n",
            "\u001b[1m498/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9890 - auc: 0.9991 - loss: 0.0392 - precision: 0.9840 - recall: 0.9944"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9890 - auc: 0.9991 - loss: 0.0392 - precision: 0.9840 - recall: 0.9944 - val_accuracy: 0.9887 - val_auc: 0.9992 - val_loss: 0.0313 - val_precision: 0.9868 - val_recall: 0.9908\n",
            "Epoch 77/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.9887 - auc: 0.9991 - loss: 0.0425 - precision: 0.9839 - recall: 0.9936 - val_accuracy: 0.9822 - val_auc: 0.9992 - val_loss: 0.0458 - val_precision: 0.9934 - val_recall: 0.9710\n",
            "Epoch 78/100\n",
            "\u001b[1m497/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9901 - auc: 0.9989 - loss: 0.0407 - precision: 0.9869 - recall: 0.9933"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9901 - auc: 0.9989 - loss: 0.0407 - precision: 0.9869 - recall: 0.9933 - val_accuracy: 0.9894 - val_auc: 0.9994 - val_loss: 0.0286 - val_precision: 0.9880 - val_recall: 0.9908\n",
            "Epoch 79/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9883 - auc: 0.9990 - loss: 0.0416 - precision: 0.9833 - recall: 0.9937 - val_accuracy: 0.9882 - val_auc: 0.9986 - val_loss: 0.0335 - val_precision: 0.9844 - val_recall: 0.9923\n",
            "Epoch 80/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9903 - auc: 0.9992 - loss: 0.0383 - precision: 0.9867 - recall: 0.9939 - val_accuracy: 0.9890 - val_auc: 0.9993 - val_loss: 0.0299 - val_precision: 0.9888 - val_recall: 0.9893\n",
            "Epoch 81/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9883 - auc: 0.9989 - loss: 0.0411 - precision: 0.9836 - recall: 0.9932 - val_accuracy: 0.9886 - val_auc: 0.9990 - val_loss: 0.0300 - val_precision: 0.9895 - val_recall: 0.9877\n",
            "Epoch 82/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9886 - auc: 0.9992 - loss: 0.0398 - precision: 0.9832 - recall: 0.9940 - val_accuracy: 0.9884 - val_auc: 0.9993 - val_loss: 0.0308 - val_precision: 0.9875 - val_recall: 0.9893\n",
            "Epoch 83/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9892 - auc: 0.9987 - loss: 0.0414 - precision: 0.9838 - recall: 0.9948 - val_accuracy: 0.9837 - val_auc: 0.9992 - val_loss: 0.0411 - val_precision: 0.9921 - val_recall: 0.9753\n",
            "Epoch 84/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.9913 - auc: 0.9995 - loss: 0.0321 - precision: 0.9873 - recall: 0.9954 - val_accuracy: 0.9891 - val_auc: 0.9991 - val_loss: 0.0309 - val_precision: 0.9917 - val_recall: 0.9865\n",
            "Epoch 85/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9885 - auc: 0.9993 - loss: 0.0390 - precision: 0.9838 - recall: 0.9935 - val_accuracy: 0.9876 - val_auc: 0.9986 - val_loss: 0.0367 - val_precision: 0.9808 - val_recall: 0.9948\n",
            "Epoch 86/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9895 - auc: 0.9990 - loss: 0.0385 - precision: 0.9853 - recall: 0.9940 - val_accuracy: 0.9876 - val_auc: 0.9986 - val_loss: 0.0341 - val_precision: 0.9808 - val_recall: 0.9948\n",
            "Epoch 87/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9891 - auc: 0.9989 - loss: 0.0408 - precision: 0.9846 - recall: 0.9938 - val_accuracy: 0.9872 - val_auc: 0.9993 - val_loss: 0.0329 - val_precision: 0.9917 - val_recall: 0.9827\n",
            "Epoch 88/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9915 - auc: 0.9992 - loss: 0.0342 - precision: 0.9887 - recall: 0.9944 - val_accuracy: 0.9860 - val_auc: 0.9983 - val_loss: 0.0419 - val_precision: 0.9755 - val_recall: 0.9970\n",
            "\n",
            "Run 1 Results:\n",
            "Test Loss: 0.0875\n",
            "Test Accuracy: 0.9703\n",
            "Test Precision: 0.9461\n",
            "Test Recall: 0.9344\n",
            "Test AUC: 0.9907\n",
            "\n",
            "==================================================\n",
            "Run 2/5\n",
            "==================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.8212 - auc: 0.8961 - loss: 0.5724 - precision: 0.8025 - recall: 0.8510 - val_accuracy: 0.9400 - val_auc: 0.9849 - val_loss: 0.2037 - val_precision: 0.9243 - val_recall: 0.9585\n",
            "Epoch 2/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9197 - auc: 0.9762 - loss: 0.2741 - precision: 0.8909 - recall: 0.9574 - val_accuracy: 0.9454 - val_auc: 0.9885 - val_loss: 0.1414 - val_precision: 0.9265 - val_recall: 0.9675\n",
            "Epoch 3/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9255 - auc: 0.9799 - loss: 0.2516 - precision: 0.8976 - recall: 0.9591 - val_accuracy: 0.9464 - val_auc: 0.9902 - val_loss: 0.1396 - val_precision: 0.9240 - val_recall: 0.9728\n",
            "Epoch 4/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.9358 - auc: 0.9830 - loss: 0.2259 - precision: 0.9136 - recall: 0.9630 - val_accuracy: 0.9514 - val_auc: 0.9906 - val_loss: 0.1307 - val_precision: 0.9664 - val_recall: 0.9352\n",
            "Epoch 5/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9402 - auc: 0.9848 - loss: 0.2111 - precision: 0.9210 - recall: 0.9641 - val_accuracy: 0.9382 - val_auc: 0.9915 - val_loss: 0.1537 - val_precision: 0.9043 - val_recall: 0.9803\n",
            "Epoch 6/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9381 - auc: 0.9859 - loss: 0.2068 - precision: 0.9169 - recall: 0.9638 - val_accuracy: 0.9572 - val_auc: 0.9934 - val_loss: 0.1106 - val_precision: 0.9411 - val_recall: 0.9755\n",
            "Epoch 7/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9431 - auc: 0.9884 - loss: 0.1886 - precision: 0.9218 - recall: 0.9678 - val_accuracy: 0.9537 - val_auc: 0.9939 - val_loss: 0.1168 - val_precision: 0.9311 - val_recall: 0.9800\n",
            "Epoch 8/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9483 - auc: 0.9888 - loss: 0.1799 - precision: 0.9287 - recall: 0.9710 - val_accuracy: 0.9524 - val_auc: 0.9946 - val_loss: 0.1177 - val_precision: 0.9261 - val_recall: 0.9833\n",
            "Epoch 9/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9503 - auc: 0.9909 - loss: 0.1664 - precision: 0.9319 - recall: 0.9713 - val_accuracy: 0.9667 - val_auc: 0.9953 - val_loss: 0.0894 - val_precision: 0.9594 - val_recall: 0.9747\n",
            "Epoch 10/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9521 - auc: 0.9917 - loss: 0.1579 - precision: 0.9337 - recall: 0.9734 - val_accuracy: 0.9672 - val_auc: 0.9958 - val_loss: 0.0842 - val_precision: 0.9597 - val_recall: 0.9755\n",
            "Epoch 11/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9580 - auc: 0.9922 - loss: 0.1519 - precision: 0.9455 - recall: 0.9732 - val_accuracy: 0.9689 - val_auc: 0.9960 - val_loss: 0.0844 - val_precision: 0.9769 - val_recall: 0.9605\n",
            "Epoch 12/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9590 - auc: 0.9927 - loss: 0.1447 - precision: 0.9448 - recall: 0.9749 - val_accuracy: 0.9512 - val_auc: 0.9953 - val_loss: 0.1214 - val_precision: 0.9188 - val_recall: 0.9900\n",
            "Epoch 13/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9601 - auc: 0.9934 - loss: 0.1398 - precision: 0.9445 - recall: 0.9773 - val_accuracy: 0.9681 - val_auc: 0.9958 - val_loss: 0.0817 - val_precision: 0.9577 - val_recall: 0.9795\n",
            "Epoch 14/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9604 - auc: 0.9934 - loss: 0.1357 - precision: 0.9476 - recall: 0.9750 - val_accuracy: 0.9649 - val_auc: 0.9961 - val_loss: 0.0923 - val_precision: 0.9441 - val_recall: 0.9883\n",
            "Epoch 15/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9656 - auc: 0.9944 - loss: 0.1243 - precision: 0.9534 - recall: 0.9795 - val_accuracy: 0.9726 - val_auc: 0.9968 - val_loss: 0.0721 - val_precision: 0.9644 - val_recall: 0.9815\n",
            "Epoch 16/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9638 - auc: 0.9936 - loss: 0.1300 - precision: 0.9508 - recall: 0.9783 - val_accuracy: 0.9629 - val_auc: 0.9961 - val_loss: 0.0950 - val_precision: 0.9395 - val_recall: 0.9895\n",
            "Epoch 17/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9648 - auc: 0.9945 - loss: 0.1250 - precision: 0.9522 - recall: 0.9784 - val_accuracy: 0.9764 - val_auc: 0.9973 - val_loss: 0.0641 - val_precision: 0.9727 - val_recall: 0.9803\n",
            "Epoch 18/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.9670 - auc: 0.9946 - loss: 0.1227 - precision: 0.9548 - recall: 0.9802 - val_accuracy: 0.9725 - val_auc: 0.9973 - val_loss: 0.0700 - val_precision: 0.9587 - val_recall: 0.9875\n",
            "Epoch 19/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9690 - auc: 0.9951 - loss: 0.1136 - precision: 0.9578 - recall: 0.9818 - val_accuracy: 0.9766 - val_auc: 0.9975 - val_loss: 0.0630 - val_precision: 0.9716 - val_recall: 0.9820\n",
            "Epoch 20/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9670 - auc: 0.9948 - loss: 0.1159 - precision: 0.9526 - recall: 0.9820 - val_accuracy: 0.9751 - val_auc: 0.9976 - val_loss: 0.0661 - val_precision: 0.9621 - val_recall: 0.9893\n",
            "Epoch 21/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.9690 - auc: 0.9957 - loss: 0.1068 - precision: 0.9557 - recall: 0.9834 - val_accuracy: 0.9792 - val_auc: 0.9976 - val_loss: 0.0608 - val_precision: 0.9797 - val_recall: 0.9787\n",
            "Epoch 22/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9711 - auc: 0.9958 - loss: 0.1058 - precision: 0.9590 - recall: 0.9842 - val_accuracy: 0.9724 - val_auc: 0.9971 - val_loss: 0.0748 - val_precision: 0.9545 - val_recall: 0.9920\n",
            "Epoch 23/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9703 - auc: 0.9951 - loss: 0.1110 - precision: 0.9598 - recall: 0.9815 - val_accuracy: 0.9744 - val_auc: 0.9976 - val_loss: 0.0690 - val_precision: 0.9582 - val_recall: 0.9920\n",
            "Epoch 24/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9722 - auc: 0.9965 - loss: 0.0977 - precision: 0.9609 - recall: 0.9846 - val_accuracy: 0.9806 - val_auc: 0.9978 - val_loss: 0.0548 - val_precision: 0.9769 - val_recall: 0.9845\n",
            "Epoch 25/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.9729 - auc: 0.9956 - loss: 0.1010 - precision: 0.9612 - recall: 0.9854 - val_accuracy: 0.9796 - val_auc: 0.9976 - val_loss: 0.0600 - val_precision: 0.9708 - val_recall: 0.9890\n",
            "Epoch 26/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9736 - auc: 0.9962 - loss: 0.0955 - precision: 0.9637 - recall: 0.9844 - val_accuracy: 0.9745 - val_auc: 0.9976 - val_loss: 0.0689 - val_precision: 0.9578 - val_recall: 0.9927\n",
            "Epoch 27/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9756 - auc: 0.9968 - loss: 0.0897 - precision: 0.9660 - recall: 0.9862 - val_accuracy: 0.9765 - val_auc: 0.9980 - val_loss: 0.0682 - val_precision: 0.9912 - val_recall: 0.9615\n",
            "Epoch 28/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9748 - auc: 0.9968 - loss: 0.0922 - precision: 0.9640 - recall: 0.9862 - val_accuracy: 0.9727 - val_auc: 0.9973 - val_loss: 0.0719 - val_precision: 0.9543 - val_recall: 0.9930\n",
            "Epoch 29/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9753 - auc: 0.9967 - loss: 0.0904 - precision: 0.9653 - recall: 0.9858 - val_accuracy: 0.9830 - val_auc: 0.9984 - val_loss: 0.0493 - val_precision: 0.9780 - val_recall: 0.9883\n",
            "Epoch 30/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9757 - auc: 0.9969 - loss: 0.0871 - precision: 0.9664 - recall: 0.9859 - val_accuracy: 0.9826 - val_auc: 0.9983 - val_loss: 0.0491 - val_precision: 0.9813 - val_recall: 0.9840\n",
            "Epoch 31/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9758 - auc: 0.9970 - loss: 0.0881 - precision: 0.9658 - recall: 0.9862 - val_accuracy: 0.9841 - val_auc: 0.9983 - val_loss: 0.0470 - val_precision: 0.9845 - val_recall: 0.9837\n",
            "Epoch 32/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9767 - auc: 0.9968 - loss: 0.0860 - precision: 0.9660 - recall: 0.9874 - val_accuracy: 0.9711 - val_auc: 0.9968 - val_loss: 0.0809 - val_precision: 0.9503 - val_recall: 0.9942\n",
            "Epoch 33/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.9770 - auc: 0.9972 - loss: 0.0826 - precision: 0.9688 - recall: 0.9861 - val_accuracy: 0.9841 - val_auc: 0.9984 - val_loss: 0.0469 - val_precision: 0.9814 - val_recall: 0.9870\n",
            "Epoch 34/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9790 - auc: 0.9974 - loss: 0.0767 - precision: 0.9695 - recall: 0.9891 - val_accuracy: 0.9794 - val_auc: 0.9979 - val_loss: 0.0547 - val_precision: 0.9678 - val_recall: 0.9918\n",
            "Epoch 35/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9796 - auc: 0.9974 - loss: 0.0795 - precision: 0.9730 - recall: 0.9866 - val_accuracy: 0.9821 - val_auc: 0.9981 - val_loss: 0.0523 - val_precision: 0.9730 - val_recall: 0.9918\n",
            "Epoch 36/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9794 - auc: 0.9973 - loss: 0.0791 - precision: 0.9704 - recall: 0.9892 - val_accuracy: 0.9850 - val_auc: 0.9985 - val_loss: 0.0439 - val_precision: 0.9828 - val_recall: 0.9872\n",
            "Epoch 37/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9812 - auc: 0.9976 - loss: 0.0719 - precision: 0.9743 - recall: 0.9887 - val_accuracy: 0.9842 - val_auc: 0.9982 - val_loss: 0.0462 - val_precision: 0.9783 - val_recall: 0.9905\n",
            "Epoch 38/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9810 - auc: 0.9974 - loss: 0.0727 - precision: 0.9729 - recall: 0.9895 - val_accuracy: 0.9854 - val_auc: 0.9986 - val_loss: 0.0440 - val_precision: 0.9848 - val_recall: 0.9860\n",
            "Epoch 39/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9802 - auc: 0.9976 - loss: 0.0711 - precision: 0.9713 - recall: 0.9898 - val_accuracy: 0.9842 - val_auc: 0.9980 - val_loss: 0.0464 - val_precision: 0.9787 - val_recall: 0.9900\n",
            "Epoch 40/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9821 - auc: 0.9983 - loss: 0.0656 - precision: 0.9749 - recall: 0.9899 - val_accuracy: 0.9850 - val_auc: 0.9985 - val_loss: 0.0446 - val_precision: 0.9795 - val_recall: 0.9908\n",
            "Epoch 41/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9812 - auc: 0.9978 - loss: 0.0684 - precision: 0.9731 - recall: 0.9896 - val_accuracy: 0.9862 - val_auc: 0.9987 - val_loss: 0.0424 - val_precision: 0.9882 - val_recall: 0.9843\n",
            "Epoch 42/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9817 - auc: 0.9977 - loss: 0.0686 - precision: 0.9743 - recall: 0.9893 - val_accuracy: 0.9845 - val_auc: 0.9985 - val_loss: 0.0440 - val_precision: 0.9797 - val_recall: 0.9895\n",
            "Epoch 43/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9814 - auc: 0.9976 - loss: 0.0663 - precision: 0.9723 - recall: 0.9906 - val_accuracy: 0.9849 - val_auc: 0.9984 - val_loss: 0.0420 - val_precision: 0.9814 - val_recall: 0.9885\n",
            "Epoch 44/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9826 - auc: 0.9977 - loss: 0.0664 - precision: 0.9750 - recall: 0.9908 - val_accuracy: 0.9780 - val_auc: 0.9983 - val_loss: 0.0625 - val_precision: 0.9935 - val_recall: 0.9622\n",
            "Epoch 45/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9835 - auc: 0.9983 - loss: 0.0601 - precision: 0.9770 - recall: 0.9903 - val_accuracy: 0.9717 - val_auc: 0.9969 - val_loss: 0.0790 - val_precision: 0.9504 - val_recall: 0.9955\n",
            "Epoch 46/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9825 - auc: 0.9983 - loss: 0.0621 - precision: 0.9751 - recall: 0.9905 - val_accuracy: 0.9854 - val_auc: 0.9987 - val_loss: 0.0393 - val_precision: 0.9838 - val_recall: 0.9870\n",
            "Epoch 47/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 0.9842 - auc: 0.9984 - loss: 0.0574 - precision: 0.9776 - recall: 0.9910 - val_accuracy: 0.9860 - val_auc: 0.9986 - val_loss: 0.0412 - val_precision: 0.9855 - val_recall: 0.9865\n",
            "Epoch 48/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9841 - auc: 0.9984 - loss: 0.0578 - precision: 0.9769 - recall: 0.9915 - val_accuracy: 0.9866 - val_auc: 0.9988 - val_loss: 0.0387 - val_precision: 0.9870 - val_recall: 0.9862\n",
            "Epoch 49/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9835 - auc: 0.9983 - loss: 0.0623 - precision: 0.9778 - recall: 0.9894 - val_accuracy: 0.9861 - val_auc: 0.9987 - val_loss: 0.0406 - val_precision: 0.9810 - val_recall: 0.9915\n",
            "Epoch 50/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9835 - auc: 0.9982 - loss: 0.0629 - precision: 0.9762 - recall: 0.9912 - val_accuracy: 0.9835 - val_auc: 0.9987 - val_loss: 0.0444 - val_precision: 0.9740 - val_recall: 0.9935\n",
            "Epoch 51/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9824 - auc: 0.9984 - loss: 0.0627 - precision: 0.9741 - recall: 0.9911 - val_accuracy: 0.9874 - val_auc: 0.9986 - val_loss: 0.0382 - val_precision: 0.9870 - val_recall: 0.9877\n",
            "Epoch 52/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9839 - auc: 0.9983 - loss: 0.0627 - precision: 0.9773 - recall: 0.9906 - val_accuracy: 0.9792 - val_auc: 0.9985 - val_loss: 0.0586 - val_precision: 0.9933 - val_recall: 0.9650\n",
            "Epoch 53/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9834 - auc: 0.9983 - loss: 0.0600 - precision: 0.9770 - recall: 0.9901 - val_accuracy: 0.9866 - val_auc: 0.9986 - val_loss: 0.0380 - val_precision: 0.9822 - val_recall: 0.9912\n",
            "Epoch 54/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9842 - auc: 0.9983 - loss: 0.0592 - precision: 0.9784 - recall: 0.9905 - val_accuracy: 0.9877 - val_auc: 0.9986 - val_loss: 0.0364 - val_precision: 0.9858 - val_recall: 0.9898\n",
            "Epoch 55/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9847 - auc: 0.9982 - loss: 0.0576 - precision: 0.9790 - recall: 0.9908 - val_accuracy: 0.9877 - val_auc: 0.9988 - val_loss: 0.0360 - val_precision: 0.9877 - val_recall: 0.9877\n",
            "Epoch 56/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9853 - auc: 0.9985 - loss: 0.0555 - precision: 0.9787 - recall: 0.9921 - val_accuracy: 0.9851 - val_auc: 0.9987 - val_loss: 0.0405 - val_precision: 0.9778 - val_recall: 0.9927\n",
            "Epoch 57/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9845 - auc: 0.9984 - loss: 0.0551 - precision: 0.9788 - recall: 0.9904 - val_accuracy: 0.9811 - val_auc: 0.9989 - val_loss: 0.0484 - val_precision: 0.9933 - val_recall: 0.9688\n",
            "Epoch 58/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9861 - auc: 0.9989 - loss: 0.0492 - precision: 0.9799 - recall: 0.9926 - val_accuracy: 0.9816 - val_auc: 0.9988 - val_loss: 0.0452 - val_precision: 0.9936 - val_recall: 0.9695\n",
            "Epoch 59/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9866 - auc: 0.9983 - loss: 0.0539 - precision: 0.9797 - recall: 0.9938 - val_accuracy: 0.9869 - val_auc: 0.9986 - val_loss: 0.0371 - val_precision: 0.9824 - val_recall: 0.9915\n",
            "Epoch 60/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9859 - auc: 0.9983 - loss: 0.0541 - precision: 0.9807 - recall: 0.9913 - val_accuracy: 0.9874 - val_auc: 0.9991 - val_loss: 0.0353 - val_precision: 0.9922 - val_recall: 0.9825\n",
            "Epoch 61/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9871 - auc: 0.9988 - loss: 0.0471 - precision: 0.9818 - recall: 0.9925 - val_accuracy: 0.9867 - val_auc: 0.9990 - val_loss: 0.0363 - val_precision: 0.9912 - val_recall: 0.9822\n",
            "Epoch 62/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9854 - auc: 0.9988 - loss: 0.0512 - precision: 0.9782 - recall: 0.9927 - val_accuracy: 0.9855 - val_auc: 0.9987 - val_loss: 0.0433 - val_precision: 0.9767 - val_recall: 0.9948\n",
            "Epoch 63/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9873 - auc: 0.9987 - loss: 0.0482 - precision: 0.9821 - recall: 0.9927 - val_accuracy: 0.9880 - val_auc: 0.9991 - val_loss: 0.0343 - val_precision: 0.9900 - val_recall: 0.9860\n",
            "Epoch 64/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9861 - auc: 0.9989 - loss: 0.0500 - precision: 0.9820 - recall: 0.9905 - val_accuracy: 0.9879 - val_auc: 0.9991 - val_loss: 0.0329 - val_precision: 0.9907 - val_recall: 0.9850\n",
            "Epoch 65/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9872 - auc: 0.9990 - loss: 0.0440 - precision: 0.9812 - recall: 0.9935 - val_accuracy: 0.9856 - val_auc: 0.9985 - val_loss: 0.0393 - val_precision: 0.9774 - val_recall: 0.9942\n",
            "Epoch 66/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9870 - auc: 0.9985 - loss: 0.0495 - precision: 0.9809 - recall: 0.9935 - val_accuracy: 0.9884 - val_auc: 0.9991 - val_loss: 0.0330 - val_precision: 0.9907 - val_recall: 0.9860\n",
            "Epoch 67/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9871 - auc: 0.9987 - loss: 0.0472 - precision: 0.9810 - recall: 0.9933 - val_accuracy: 0.9859 - val_auc: 0.9988 - val_loss: 0.0375 - val_precision: 0.9786 - val_recall: 0.9935\n",
            "Epoch 68/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9864 - auc: 0.9988 - loss: 0.0499 - precision: 0.9811 - recall: 0.9920 - val_accuracy: 0.9886 - val_auc: 0.9992 - val_loss: 0.0316 - val_precision: 0.9905 - val_recall: 0.9868\n",
            "Epoch 69/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9871 - auc: 0.9988 - loss: 0.0467 - precision: 0.9814 - recall: 0.9931 - val_accuracy: 0.9867 - val_auc: 0.9984 - val_loss: 0.0371 - val_precision: 0.9812 - val_recall: 0.9925\n",
            "Epoch 70/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9887 - auc: 0.9987 - loss: 0.0470 - precision: 0.9840 - recall: 0.9935 - val_accuracy: 0.9886 - val_auc: 0.9990 - val_loss: 0.0321 - val_precision: 0.9858 - val_recall: 0.9915\n",
            "Epoch 71/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9870 - auc: 0.9989 - loss: 0.0466 - precision: 0.9817 - recall: 0.9923 - val_accuracy: 0.9881 - val_auc: 0.9989 - val_loss: 0.0341 - val_precision: 0.9922 - val_recall: 0.9840\n",
            "Epoch 72/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9883 - auc: 0.9992 - loss: 0.0422 - precision: 0.9831 - recall: 0.9938 - val_accuracy: 0.9885 - val_auc: 0.9991 - val_loss: 0.0323 - val_precision: 0.9890 - val_recall: 0.9880\n",
            "Epoch 73/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.9870 - auc: 0.9990 - loss: 0.0453 - precision: 0.9815 - recall: 0.9928 - val_accuracy: 0.9874 - val_auc: 0.9986 - val_loss: 0.0339 - val_precision: 0.9834 - val_recall: 0.9915\n",
            "Epoch 74/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9867 - auc: 0.9987 - loss: 0.0466 - precision: 0.9804 - recall: 0.9931 - val_accuracy: 0.9896 - val_auc: 0.9989 - val_loss: 0.0304 - val_precision: 0.9900 - val_recall: 0.9893\n",
            "Epoch 75/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9890 - auc: 0.9992 - loss: 0.0403 - precision: 0.9847 - recall: 0.9934 - val_accuracy: 0.9845 - val_auc: 0.9983 - val_loss: 0.0449 - val_precision: 0.9743 - val_recall: 0.9952\n",
            "Epoch 76/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9889 - auc: 0.9991 - loss: 0.0419 - precision: 0.9843 - recall: 0.9936 - val_accuracy: 0.9865 - val_auc: 0.9992 - val_loss: 0.0342 - val_precision: 0.9937 - val_recall: 0.9793\n",
            "Epoch 77/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9889 - auc: 0.9990 - loss: 0.0428 - precision: 0.9851 - recall: 0.9928 - val_accuracy: 0.9861 - val_auc: 0.9984 - val_loss: 0.0429 - val_precision: 0.9774 - val_recall: 0.9952\n",
            "Epoch 78/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9878 - auc: 0.9986 - loss: 0.0447 - precision: 0.9823 - recall: 0.9935 - val_accuracy: 0.9887 - val_auc: 0.9990 - val_loss: 0.0305 - val_precision: 0.9885 - val_recall: 0.9890\n",
            "Epoch 79/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9896 - auc: 0.9991 - loss: 0.0387 - precision: 0.9856 - recall: 0.9937 - val_accuracy: 0.9681 - val_auc: 0.9988 - val_loss: 0.0786 - val_precision: 0.9971 - val_recall: 0.9390\n",
            "Epoch 80/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9899 - auc: 0.9989 - loss: 0.0400 - precision: 0.9862 - recall: 0.9935 - val_accuracy: 0.9895 - val_auc: 0.9990 - val_loss: 0.0312 - val_precision: 0.9856 - val_recall: 0.9935\n",
            "Epoch 81/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9895 - auc: 0.9991 - loss: 0.0403 - precision: 0.9854 - recall: 0.9936 - val_accuracy: 0.9891 - val_auc: 0.9993 - val_loss: 0.0293 - val_precision: 0.9890 - val_recall: 0.9893\n",
            "Epoch 82/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9897 - auc: 0.9992 - loss: 0.0397 - precision: 0.9855 - recall: 0.9939 - val_accuracy: 0.9886 - val_auc: 0.9989 - val_loss: 0.0312 - val_precision: 0.9846 - val_recall: 0.9927\n",
            "Epoch 83/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9896 - auc: 0.9991 - loss: 0.0383 - precision: 0.9847 - recall: 0.9946 - val_accuracy: 0.9894 - val_auc: 0.9990 - val_loss: 0.0298 - val_precision: 0.9878 - val_recall: 0.9910\n",
            "Epoch 84/100\n",
            "\u001b[1m496/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9909 - auc: 0.9993 - loss: 0.0329 - precision: 0.9876 - recall: 0.9943"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9909 - auc: 0.9993 - loss: 0.0330 - precision: 0.9875 - recall: 0.9943 - val_accuracy: 0.9899 - val_auc: 0.9992 - val_loss: 0.0282 - val_precision: 0.9859 - val_recall: 0.9940\n",
            "Epoch 85/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9902 - auc: 0.9992 - loss: 0.0377 - precision: 0.9862 - recall: 0.9945 - val_accuracy: 0.9891 - val_auc: 0.9995 - val_loss: 0.0288 - val_precision: 0.9920 - val_recall: 0.9862\n",
            "Epoch 86/100\n",
            "\u001b[1m495/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9897 - auc: 0.9993 - loss: 0.0375 - precision: 0.9858 - recall: 0.9937"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9896 - auc: 0.9993 - loss: 0.0376 - precision: 0.9858 - recall: 0.9937 - val_accuracy: 0.9907 - val_auc: 0.9992 - val_loss: 0.0265 - val_precision: 0.9903 - val_recall: 0.9912\n",
            "Epoch 87/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9896 - auc: 0.9992 - loss: 0.0378 - precision: 0.9857 - recall: 0.9938 - val_accuracy: 0.9886 - val_auc: 0.9988 - val_loss: 0.0337 - val_precision: 0.9834 - val_recall: 0.9940\n",
            "Epoch 88/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9888 - auc: 0.9991 - loss: 0.0398 - precision: 0.9844 - recall: 0.9932 - val_accuracy: 0.9864 - val_auc: 0.9984 - val_loss: 0.0421 - val_precision: 0.9765 - val_recall: 0.9967\n",
            "Epoch 89/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9908 - auc: 0.9993 - loss: 0.0344 - precision: 0.9870 - recall: 0.9950 - val_accuracy: 0.9892 - val_auc: 0.9993 - val_loss: 0.0295 - val_precision: 0.9905 - val_recall: 0.9880\n",
            "Epoch 90/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9912 - auc: 0.9992 - loss: 0.0362 - precision: 0.9880 - recall: 0.9943 - val_accuracy: 0.9874 - val_auc: 0.9989 - val_loss: 0.0367 - val_precision: 0.9784 - val_recall: 0.9967\n",
            "Epoch 91/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9902 - auc: 0.9991 - loss: 0.0369 - precision: 0.9864 - recall: 0.9942 - val_accuracy: 0.9906 - val_auc: 0.9989 - val_loss: 0.0287 - val_precision: 0.9881 - val_recall: 0.9933\n",
            "Epoch 92/100\n",
            "\u001b[1m498/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9924 - auc: 0.9994 - loss: 0.0301 - precision: 0.9889 - recall: 0.9960"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9924 - auc: 0.9994 - loss: 0.0301 - precision: 0.9889 - recall: 0.9960 - val_accuracy: 0.9905 - val_auc: 0.9991 - val_loss: 0.0261 - val_precision: 0.9898 - val_recall: 0.9912\n",
            "Epoch 93/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9904 - auc: 0.9994 - loss: 0.0333 - precision: 0.9873 - recall: 0.9937 - val_accuracy: 0.9894 - val_auc: 0.9992 - val_loss: 0.0301 - val_precision: 0.9851 - val_recall: 0.9937\n",
            "Epoch 94/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9902 - auc: 0.9994 - loss: 0.0339 - precision: 0.9857 - recall: 0.9949 - val_accuracy: 0.9907 - val_auc: 0.9991 - val_loss: 0.0276 - val_precision: 0.9893 - val_recall: 0.9923\n",
            "Epoch 95/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9897 - auc: 0.9990 - loss: 0.0370 - precision: 0.9857 - recall: 0.9940 - val_accuracy: 0.9901 - val_auc: 0.9987 - val_loss: 0.0293 - val_precision: 0.9878 - val_recall: 0.9925\n",
            "Epoch 96/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9912 - auc: 0.9994 - loss: 0.0310 - precision: 0.9868 - recall: 0.9957 - val_accuracy: 0.9900 - val_auc: 0.9991 - val_loss: 0.0272 - val_precision: 0.9902 - val_recall: 0.9898\n",
            "Epoch 97/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9920 - auc: 0.9993 - loss: 0.0278 - precision: 0.9871 - recall: 0.9969 - val_accuracy: 0.9864 - val_auc: 0.9983 - val_loss: 0.0409 - val_precision: 0.9777 - val_recall: 0.9955\n",
            "Epoch 98/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9922 - auc: 0.9995 - loss: 0.0280 - precision: 0.9890 - recall: 0.9955 - val_accuracy: 0.9907 - val_auc: 0.9992 - val_loss: 0.0277 - val_precision: 0.9905 - val_recall: 0.9910\n",
            "Epoch 99/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9925 - auc: 0.9994 - loss: 0.0291 - precision: 0.9888 - recall: 0.9963 - val_accuracy: 0.9902 - val_auc: 0.9992 - val_loss: 0.0274 - val_precision: 0.9871 - val_recall: 0.9935\n",
            "Epoch 100/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9903 - auc: 0.9995 - loss: 0.0333 - precision: 0.9860 - recall: 0.9947 - val_accuracy: 0.9901 - val_auc: 0.9991 - val_loss: 0.0267 - val_precision: 0.9878 - val_recall: 0.9925\n",
            "\n",
            "Run 2 Results:\n",
            "Test Loss: 0.0869\n",
            "Test Accuracy: 0.9722\n",
            "Test Precision: 0.9465\n",
            "Test Recall: 0.9420\n",
            "Test AUC: 0.9916\n",
            "\n",
            "==================================================\n",
            "Run 3/5\n",
            "==================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.8183 - auc: 0.8985 - loss: 0.5533 - precision: 0.7938 - recall: 0.8510 - val_accuracy: 0.9349 - val_auc: 0.9839 - val_loss: 0.2068 - val_precision: 0.9069 - val_recall: 0.9693\n",
            "Epoch 2/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9146 - auc: 0.9739 - loss: 0.2856 - precision: 0.8844 - recall: 0.9540 - val_accuracy: 0.9312 - val_auc: 0.9877 - val_loss: 0.1844 - val_precision: 0.8940 - val_recall: 0.9785\n",
            "Epoch 3/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9276 - auc: 0.9794 - loss: 0.2534 - precision: 0.9052 - recall: 0.9571 - val_accuracy: 0.9509 - val_auc: 0.9897 - val_loss: 0.1303 - val_precision: 0.9415 - val_recall: 0.9615\n",
            "Epoch 4/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9347 - auc: 0.9844 - loss: 0.2195 - precision: 0.9141 - recall: 0.9597 - val_accuracy: 0.9546 - val_auc: 0.9914 - val_loss: 0.1184 - val_precision: 0.9489 - val_recall: 0.9610\n",
            "Epoch 5/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9369 - auc: 0.9856 - loss: 0.2138 - precision: 0.9159 - recall: 0.9620 - val_accuracy: 0.9275 - val_auc: 0.9908 - val_loss: 0.1840 - val_precision: 0.8834 - val_recall: 0.9850\n",
            "Epoch 6/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9392 - auc: 0.9857 - loss: 0.2053 - precision: 0.9186 - recall: 0.9639 - val_accuracy: 0.9585 - val_auc: 0.9935 - val_loss: 0.1050 - val_precision: 0.9511 - val_recall: 0.9668\n",
            "Epoch 7/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9453 - auc: 0.9878 - loss: 0.1939 - precision: 0.9286 - recall: 0.9645 - val_accuracy: 0.9615 - val_auc: 0.9937 - val_loss: 0.1035 - val_precision: 0.9520 - val_recall: 0.9720\n",
            "Epoch 8/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9477 - auc: 0.9889 - loss: 0.1810 - precision: 0.9270 - recall: 0.9713 - val_accuracy: 0.9572 - val_auc: 0.9948 - val_loss: 0.1072 - val_precision: 0.9357 - val_recall: 0.9820\n",
            "Epoch 9/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9494 - auc: 0.9897 - loss: 0.1767 - precision: 0.9313 - recall: 0.9695 - val_accuracy: 0.9622 - val_auc: 0.9952 - val_loss: 0.0988 - val_precision: 0.9445 - val_recall: 0.9822\n",
            "Epoch 10/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9529 - auc: 0.9905 - loss: 0.1645 - precision: 0.9359 - recall: 0.9721 - val_accuracy: 0.9704 - val_auc: 0.9958 - val_loss: 0.0832 - val_precision: 0.9740 - val_recall: 0.9665\n",
            "Epoch 11/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9550 - auc: 0.9918 - loss: 0.1562 - precision: 0.9382 - recall: 0.9745 - val_accuracy: 0.9652 - val_auc: 0.9957 - val_loss: 0.0901 - val_precision: 0.9484 - val_recall: 0.9840\n",
            "Epoch 12/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9581 - auc: 0.9928 - loss: 0.1443 - precision: 0.9413 - recall: 0.9770 - val_accuracy: 0.9714 - val_auc: 0.9965 - val_loss: 0.0783 - val_precision: 0.9602 - val_recall: 0.9835\n",
            "Epoch 13/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.9610 - auc: 0.9936 - loss: 0.1367 - precision: 0.9471 - recall: 0.9770 - val_accuracy: 0.9660 - val_auc: 0.9964 - val_loss: 0.0877 - val_precision: 0.9464 - val_recall: 0.9880\n",
            "Epoch 14/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9614 - auc: 0.9932 - loss: 0.1366 - precision: 0.9467 - recall: 0.9777 - val_accuracy: 0.9744 - val_auc: 0.9970 - val_loss: 0.0739 - val_precision: 0.9805 - val_recall: 0.9680\n",
            "Epoch 15/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9635 - auc: 0.9943 - loss: 0.1283 - precision: 0.9493 - recall: 0.9796 - val_accuracy: 0.9624 - val_auc: 0.9956 - val_loss: 0.0978 - val_precision: 0.9380 - val_recall: 0.9902\n",
            "Epoch 16/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9666 - auc: 0.9947 - loss: 0.1201 - precision: 0.9566 - recall: 0.9775 - val_accuracy: 0.9745 - val_auc: 0.9969 - val_loss: 0.0698 - val_precision: 0.9634 - val_recall: 0.9865\n",
            "Epoch 17/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9680 - auc: 0.9950 - loss: 0.1198 - precision: 0.9568 - recall: 0.9803 - val_accuracy: 0.9766 - val_auc: 0.9974 - val_loss: 0.0660 - val_precision: 0.9690 - val_recall: 0.9847\n",
            "Epoch 18/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9685 - auc: 0.9947 - loss: 0.1164 - precision: 0.9574 - recall: 0.9808 - val_accuracy: 0.9760 - val_auc: 0.9971 - val_loss: 0.0655 - val_precision: 0.9664 - val_recall: 0.9862\n",
            "Epoch 19/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9661 - auc: 0.9951 - loss: 0.1143 - precision: 0.9529 - recall: 0.9805 - val_accuracy: 0.9720 - val_auc: 0.9970 - val_loss: 0.0774 - val_precision: 0.9536 - val_recall: 0.9923\n",
            "Epoch 20/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.9691 - auc: 0.9955 - loss: 0.1101 - precision: 0.9564 - recall: 0.9832 - val_accuracy: 0.9795 - val_auc: 0.9979 - val_loss: 0.0576 - val_precision: 0.9724 - val_recall: 0.9870\n",
            "Epoch 21/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9735 - auc: 0.9962 - loss: 0.0982 - precision: 0.9646 - recall: 0.9828 - val_accuracy: 0.9799 - val_auc: 0.9979 - val_loss: 0.0569 - val_precision: 0.9729 - val_recall: 0.9872\n",
            "Epoch 22/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9706 - auc: 0.9958 - loss: 0.1023 - precision: 0.9570 - recall: 0.9851 - val_accuracy: 0.9790 - val_auc: 0.9978 - val_loss: 0.0587 - val_precision: 0.9701 - val_recall: 0.9885\n",
            "Epoch 23/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9737 - auc: 0.9959 - loss: 0.0989 - precision: 0.9625 - recall: 0.9860 - val_accuracy: 0.9807 - val_auc: 0.9981 - val_loss: 0.0531 - val_precision: 0.9776 - val_recall: 0.9840\n",
            "Epoch 24/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9742 - auc: 0.9966 - loss: 0.0956 - precision: 0.9638 - recall: 0.9851 - val_accuracy: 0.9756 - val_auc: 0.9972 - val_loss: 0.0687 - val_precision: 0.9599 - val_recall: 0.9927\n",
            "Epoch 25/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9750 - auc: 0.9965 - loss: 0.0931 - precision: 0.9663 - recall: 0.9847 - val_accuracy: 0.9767 - val_auc: 0.9982 - val_loss: 0.0626 - val_precision: 0.9631 - val_recall: 0.9915\n",
            "Epoch 26/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9739 - auc: 0.9969 - loss: 0.0921 - precision: 0.9640 - recall: 0.9849 - val_accuracy: 0.9774 - val_auc: 0.9973 - val_loss: 0.0650 - val_precision: 0.9638 - val_recall: 0.9920\n",
            "Epoch 27/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9758 - auc: 0.9968 - loss: 0.0911 - precision: 0.9680 - recall: 0.9844 - val_accuracy: 0.9825 - val_auc: 0.9981 - val_loss: 0.0516 - val_precision: 0.9849 - val_recall: 0.9800\n",
            "Epoch 28/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9754 - auc: 0.9969 - loss: 0.0886 - precision: 0.9662 - recall: 0.9853 - val_accuracy: 0.9836 - val_auc: 0.9984 - val_loss: 0.0483 - val_precision: 0.9850 - val_recall: 0.9822\n",
            "Epoch 29/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9748 - auc: 0.9969 - loss: 0.0883 - precision: 0.9652 - recall: 0.9849 - val_accuracy: 0.9821 - val_auc: 0.9983 - val_loss: 0.0496 - val_precision: 0.9876 - val_recall: 0.9765\n",
            "Epoch 30/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.9762 - auc: 0.9970 - loss: 0.0861 - precision: 0.9679 - recall: 0.9846 - val_accuracy: 0.9807 - val_auc: 0.9980 - val_loss: 0.0555 - val_precision: 0.9695 - val_recall: 0.9927\n",
            "Epoch 31/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9768 - auc: 0.9973 - loss: 0.0831 - precision: 0.9686 - recall: 0.9862 - val_accuracy: 0.9844 - val_auc: 0.9984 - val_loss: 0.0457 - val_precision: 0.9847 - val_recall: 0.9840\n",
            "Epoch 32/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9772 - auc: 0.9971 - loss: 0.0814 - precision: 0.9672 - recall: 0.9879 - val_accuracy: 0.9841 - val_auc: 0.9983 - val_loss: 0.0455 - val_precision: 0.9857 - val_recall: 0.9825\n",
            "Epoch 33/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9796 - auc: 0.9973 - loss: 0.0762 - precision: 0.9712 - recall: 0.9884 - val_accuracy: 0.9835 - val_auc: 0.9983 - val_loss: 0.0472 - val_precision: 0.9801 - val_recall: 0.9870\n",
            "Epoch 34/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9789 - auc: 0.9974 - loss: 0.0767 - precision: 0.9695 - recall: 0.9887 - val_accuracy: 0.9820 - val_auc: 0.9980 - val_loss: 0.0524 - val_precision: 0.9725 - val_recall: 0.9920\n",
            "Epoch 35/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9797 - auc: 0.9973 - loss: 0.0784 - precision: 0.9716 - recall: 0.9882 - val_accuracy: 0.9762 - val_auc: 0.9976 - val_loss: 0.0636 - val_precision: 0.9599 - val_recall: 0.9940\n",
            "Epoch 36/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.9814 - auc: 0.9979 - loss: 0.0698 - precision: 0.9747 - recall: 0.9885 - val_accuracy: 0.9745 - val_auc: 0.9981 - val_loss: 0.0669 - val_precision: 0.9938 - val_recall: 0.9550\n",
            "Epoch 37/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9809 - auc: 0.9979 - loss: 0.0698 - precision: 0.9722 - recall: 0.9897 - val_accuracy: 0.9855 - val_auc: 0.9984 - val_loss: 0.0432 - val_precision: 0.9882 - val_recall: 0.9827\n",
            "Epoch 38/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9811 - auc: 0.9981 - loss: 0.0689 - precision: 0.9728 - recall: 0.9902 - val_accuracy: 0.9786 - val_auc: 0.9975 - val_loss: 0.0607 - val_precision: 0.9641 - val_recall: 0.9942\n",
            "Epoch 39/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9823 - auc: 0.9979 - loss: 0.0685 - precision: 0.9752 - recall: 0.9898 - val_accuracy: 0.9826 - val_auc: 0.9984 - val_loss: 0.0483 - val_precision: 0.9889 - val_recall: 0.9762\n",
            "Epoch 40/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9813 - auc: 0.9982 - loss: 0.0637 - precision: 0.9734 - recall: 0.9896 - val_accuracy: 0.9815 - val_auc: 0.9983 - val_loss: 0.0489 - val_precision: 0.9707 - val_recall: 0.9930\n",
            "Epoch 41/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9802 - auc: 0.9979 - loss: 0.0710 - precision: 0.9727 - recall: 0.9879 - val_accuracy: 0.9846 - val_auc: 0.9985 - val_loss: 0.0450 - val_precision: 0.9901 - val_recall: 0.9790\n",
            "Epoch 42/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9831 - auc: 0.9976 - loss: 0.0682 - precision: 0.9768 - recall: 0.9900 - val_accuracy: 0.9845 - val_auc: 0.9987 - val_loss: 0.0435 - val_precision: 0.9778 - val_recall: 0.9915\n",
            "Epoch 43/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9820 - auc: 0.9979 - loss: 0.0686 - precision: 0.9757 - recall: 0.9889 - val_accuracy: 0.9859 - val_auc: 0.9986 - val_loss: 0.0383 - val_precision: 0.9860 - val_recall: 0.9858\n",
            "Epoch 44/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9816 - auc: 0.9982 - loss: 0.0657 - precision: 0.9734 - recall: 0.9897 - val_accuracy: 0.9800 - val_auc: 0.9983 - val_loss: 0.0525 - val_precision: 0.9667 - val_recall: 0.9942\n",
            "Epoch 45/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9818 - auc: 0.9983 - loss: 0.0639 - precision: 0.9728 - recall: 0.9913 - val_accuracy: 0.9876 - val_auc: 0.9987 - val_loss: 0.0379 - val_precision: 0.9868 - val_recall: 0.9885\n",
            "Epoch 46/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9831 - auc: 0.9982 - loss: 0.0624 - precision: 0.9759 - recall: 0.9910 - val_accuracy: 0.9840 - val_auc: 0.9984 - val_loss: 0.0448 - val_precision: 0.9914 - val_recall: 0.9765\n",
            "Epoch 47/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9837 - auc: 0.9985 - loss: 0.0598 - precision: 0.9774 - recall: 0.9905 - val_accuracy: 0.9859 - val_auc: 0.9986 - val_loss: 0.0407 - val_precision: 0.9912 - val_recall: 0.9805\n",
            "Epoch 48/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9839 - auc: 0.9985 - loss: 0.0598 - precision: 0.9780 - recall: 0.9900 - val_accuracy: 0.9860 - val_auc: 0.9988 - val_loss: 0.0406 - val_precision: 0.9892 - val_recall: 0.9827\n",
            "Epoch 49/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9827 - auc: 0.9983 - loss: 0.0612 - precision: 0.9758 - recall: 0.9897 - val_accuracy: 0.9851 - val_auc: 0.9983 - val_loss: 0.0434 - val_precision: 0.9771 - val_recall: 0.9935\n",
            "Epoch 50/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9845 - auc: 0.9984 - loss: 0.0583 - precision: 0.9789 - recall: 0.9903 - val_accuracy: 0.9844 - val_auc: 0.9986 - val_loss: 0.0424 - val_precision: 0.9764 - val_recall: 0.9927\n",
            "Epoch 51/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9855 - auc: 0.9983 - loss: 0.0594 - precision: 0.9805 - recall: 0.9906 - val_accuracy: 0.9862 - val_auc: 0.9985 - val_loss: 0.0390 - val_precision: 0.9833 - val_recall: 0.9893\n",
            "Epoch 52/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9843 - auc: 0.9982 - loss: 0.0592 - precision: 0.9771 - recall: 0.9917 - val_accuracy: 0.9864 - val_auc: 0.9983 - val_loss: 0.0412 - val_precision: 0.9805 - val_recall: 0.9925\n",
            "Epoch 53/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9844 - auc: 0.9983 - loss: 0.0560 - precision: 0.9777 - recall: 0.9912 - val_accuracy: 0.9829 - val_auc: 0.9979 - val_loss: 0.0500 - val_precision: 0.9717 - val_recall: 0.9948\n",
            "Epoch 54/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9854 - auc: 0.9983 - loss: 0.0570 - precision: 0.9790 - recall: 0.9919 - val_accuracy: 0.9850 - val_auc: 0.9985 - val_loss: 0.0401 - val_precision: 0.9785 - val_recall: 0.9918\n",
            "Epoch 55/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9855 - auc: 0.9987 - loss: 0.0527 - precision: 0.9795 - recall: 0.9918 - val_accuracy: 0.9851 - val_auc: 0.9984 - val_loss: 0.0420 - val_precision: 0.9778 - val_recall: 0.9927\n",
            "\n",
            "Run 3 Results:\n",
            "Test Loss: 0.0775\n",
            "Test Accuracy: 0.9722\n",
            "Test Precision: 0.9388\n",
            "Test Recall: 0.9508\n",
            "Test AUC: 0.9937\n",
            "\n",
            "==================================================\n",
            "Run 4/5\n",
            "==================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.8172 - auc: 0.8970 - loss: 0.5484 - precision: 0.7884 - recall: 0.8641 - val_accuracy: 0.9281 - val_auc: 0.9832 - val_loss: 0.2186 - val_precision: 0.8916 - val_recall: 0.9747\n",
            "Epoch 2/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9186 - auc: 0.9759 - loss: 0.2780 - precision: 0.8899 - recall: 0.9560 - val_accuracy: 0.9432 - val_auc: 0.9885 - val_loss: 0.1481 - val_precision: 0.9193 - val_recall: 0.9718\n",
            "Epoch 3/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9299 - auc: 0.9818 - loss: 0.2372 - precision: 0.9046 - recall: 0.9619 - val_accuracy: 0.9471 - val_auc: 0.9906 - val_loss: 0.1358 - val_precision: 0.9251 - val_recall: 0.9730\n",
            "Epoch 4/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9342 - auc: 0.9823 - loss: 0.2319 - precision: 0.9134 - recall: 0.9605 - val_accuracy: 0.9537 - val_auc: 0.9916 - val_loss: 0.1221 - val_precision: 0.9373 - val_recall: 0.9725\n",
            "Epoch 5/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9405 - auc: 0.9853 - loss: 0.2076 - precision: 0.9197 - recall: 0.9654 - val_accuracy: 0.9556 - val_auc: 0.9930 - val_loss: 0.1130 - val_precision: 0.9391 - val_recall: 0.9745\n",
            "Epoch 6/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9412 - auc: 0.9877 - loss: 0.1929 - precision: 0.9190 - recall: 0.9675 - val_accuracy: 0.9540 - val_auc: 0.9939 - val_loss: 0.1132 - val_precision: 0.9324 - val_recall: 0.9790\n",
            "Epoch 7/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.9451 - auc: 0.9888 - loss: 0.1859 - precision: 0.9264 - recall: 0.9669 - val_accuracy: 0.9510 - val_auc: 0.9941 - val_loss: 0.1176 - val_precision: 0.9255 - val_recall: 0.9810\n",
            "Epoch 8/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9495 - auc: 0.9896 - loss: 0.1751 - precision: 0.9309 - recall: 0.9711 - val_accuracy: 0.9499 - val_auc: 0.9940 - val_loss: 0.1274 - val_precision: 0.9201 - val_recall: 0.9852\n",
            "Epoch 9/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9533 - auc: 0.9916 - loss: 0.1583 - precision: 0.9369 - recall: 0.9718 - val_accuracy: 0.9529 - val_auc: 0.9938 - val_loss: 0.1192 - val_precision: 0.9277 - val_recall: 0.9822\n",
            "Epoch 10/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9526 - auc: 0.9910 - loss: 0.1616 - precision: 0.9348 - recall: 0.9731 - val_accuracy: 0.9569 - val_auc: 0.9947 - val_loss: 0.1113 - val_precision: 0.9317 - val_recall: 0.9860\n",
            "Epoch 11/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9586 - auc: 0.9922 - loss: 0.1503 - precision: 0.9411 - recall: 0.9775 - val_accuracy: 0.9724 - val_auc: 0.9961 - val_loss: 0.0787 - val_precision: 0.9742 - val_recall: 0.9705\n",
            "Epoch 12/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9584 - auc: 0.9929 - loss: 0.1415 - precision: 0.9427 - recall: 0.9763 - val_accuracy: 0.9624 - val_auc: 0.9962 - val_loss: 0.0933 - val_precision: 0.9407 - val_recall: 0.9870\n",
            "Epoch 13/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.9611 - auc: 0.9936 - loss: 0.1342 - precision: 0.9444 - recall: 0.9795 - val_accuracy: 0.9577 - val_auc: 0.9951 - val_loss: 0.1094 - val_precision: 0.9312 - val_recall: 0.9885\n",
            "Epoch 14/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9628 - auc: 0.9938 - loss: 0.1323 - precision: 0.9485 - recall: 0.9787 - val_accuracy: 0.9632 - val_auc: 0.9964 - val_loss: 0.0924 - val_precision: 0.9406 - val_recall: 0.9890\n",
            "Epoch 15/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.9659 - auc: 0.9943 - loss: 0.1218 - precision: 0.9521 - recall: 0.9812 - val_accuracy: 0.9754 - val_auc: 0.9971 - val_loss: 0.0669 - val_precision: 0.9706 - val_recall: 0.9805\n",
            "Epoch 16/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9658 - auc: 0.9941 - loss: 0.1246 - precision: 0.9529 - recall: 0.9805 - val_accuracy: 0.9731 - val_auc: 0.9968 - val_loss: 0.0706 - val_precision: 0.9631 - val_recall: 0.9840\n",
            "Epoch 17/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9685 - auc: 0.9947 - loss: 0.1186 - precision: 0.9554 - recall: 0.9829 - val_accuracy: 0.9767 - val_auc: 0.9973 - val_loss: 0.0637 - val_precision: 0.9739 - val_recall: 0.9797\n",
            "Epoch 18/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9684 - auc: 0.9945 - loss: 0.1206 - precision: 0.9584 - recall: 0.9802 - val_accuracy: 0.9772 - val_auc: 0.9976 - val_loss: 0.0610 - val_precision: 0.9751 - val_recall: 0.9795\n",
            "Epoch 19/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.9708 - auc: 0.9956 - loss: 0.1099 - precision: 0.9615 - recall: 0.9815 - val_accuracy: 0.9786 - val_auc: 0.9977 - val_loss: 0.0591 - val_precision: 0.9795 - val_recall: 0.9778\n",
            "Epoch 20/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9695 - auc: 0.9957 - loss: 0.1087 - precision: 0.9573 - recall: 0.9829 - val_accuracy: 0.9762 - val_auc: 0.9978 - val_loss: 0.0645 - val_precision: 0.9642 - val_recall: 0.9893\n",
            "Epoch 21/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9707 - auc: 0.9956 - loss: 0.1056 - precision: 0.9590 - recall: 0.9833 - val_accuracy: 0.9789 - val_auc: 0.9976 - val_loss: 0.0578 - val_precision: 0.9752 - val_recall: 0.9827\n",
            "Epoch 22/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9702 - auc: 0.9953 - loss: 0.1104 - precision: 0.9590 - recall: 0.9821 - val_accuracy: 0.9801 - val_auc: 0.9979 - val_loss: 0.0564 - val_precision: 0.9769 - val_recall: 0.9835\n",
            "Epoch 23/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9728 - auc: 0.9959 - loss: 0.0991 - precision: 0.9616 - recall: 0.9851 - val_accuracy: 0.9792 - val_auc: 0.9981 - val_loss: 0.0577 - val_precision: 0.9701 - val_recall: 0.9890\n",
            "Epoch 24/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9752 - auc: 0.9968 - loss: 0.0901 - precision: 0.9647 - recall: 0.9864 - val_accuracy: 0.9794 - val_auc: 0.9982 - val_loss: 0.0568 - val_precision: 0.9699 - val_recall: 0.9895\n",
            "Epoch 25/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9761 - auc: 0.9967 - loss: 0.0905 - precision: 0.9668 - recall: 0.9868 - val_accuracy: 0.9814 - val_auc: 0.9980 - val_loss: 0.0541 - val_precision: 0.9755 - val_recall: 0.9875\n",
            "Epoch 26/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9751 - auc: 0.9966 - loss: 0.0922 - precision: 0.9652 - recall: 0.9857 - val_accuracy: 0.9780 - val_auc: 0.9979 - val_loss: 0.0585 - val_precision: 0.9668 - val_recall: 0.9900\n",
            "Epoch 27/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9761 - auc: 0.9966 - loss: 0.0912 - precision: 0.9676 - recall: 0.9856 - val_accuracy: 0.9816 - val_auc: 0.9980 - val_loss: 0.0533 - val_precision: 0.9746 - val_recall: 0.9890\n",
            "Epoch 28/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.9762 - auc: 0.9968 - loss: 0.0886 - precision: 0.9680 - recall: 0.9849 - val_accuracy: 0.9805 - val_auc: 0.9979 - val_loss: 0.0541 - val_precision: 0.9722 - val_recall: 0.9893\n",
            "Epoch 29/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9779 - auc: 0.9974 - loss: 0.0808 - precision: 0.9694 - recall: 0.9875 - val_accuracy: 0.9832 - val_auc: 0.9983 - val_loss: 0.0483 - val_precision: 0.9854 - val_recall: 0.9810\n",
            "Epoch 30/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9784 - auc: 0.9976 - loss: 0.0783 - precision: 0.9705 - recall: 0.9868 - val_accuracy: 0.9790 - val_auc: 0.9980 - val_loss: 0.0582 - val_precision: 0.9671 - val_recall: 0.9918\n",
            "Epoch 31/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9753 - auc: 0.9962 - loss: 0.0898 - precision: 0.9639 - recall: 0.9871 - val_accuracy: 0.9822 - val_auc: 0.9984 - val_loss: 0.0508 - val_precision: 0.9742 - val_recall: 0.9908\n",
            "Epoch 32/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9780 - auc: 0.9974 - loss: 0.0807 - precision: 0.9695 - recall: 0.9866 - val_accuracy: 0.9837 - val_auc: 0.9982 - val_loss: 0.0476 - val_precision: 0.9813 - val_recall: 0.9862\n",
            "Epoch 33/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9783 - auc: 0.9971 - loss: 0.0807 - precision: 0.9692 - recall: 0.9876 - val_accuracy: 0.9841 - val_auc: 0.9984 - val_loss: 0.0476 - val_precision: 0.9879 - val_recall: 0.9803\n",
            "Epoch 34/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9798 - auc: 0.9972 - loss: 0.0767 - precision: 0.9717 - recall: 0.9884 - val_accuracy: 0.9851 - val_auc: 0.9980 - val_loss: 0.0467 - val_precision: 0.9814 - val_recall: 0.9890\n",
            "Epoch 35/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9803 - auc: 0.9978 - loss: 0.0735 - precision: 0.9731 - recall: 0.9882 - val_accuracy: 0.9847 - val_auc: 0.9985 - val_loss: 0.0456 - val_precision: 0.9852 - val_recall: 0.9843\n",
            "Epoch 36/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9792 - auc: 0.9976 - loss: 0.0762 - precision: 0.9708 - recall: 0.9886 - val_accuracy: 0.9854 - val_auc: 0.9985 - val_loss: 0.0439 - val_precision: 0.9826 - val_recall: 0.9883\n",
            "Epoch 37/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9813 - auc: 0.9976 - loss: 0.0725 - precision: 0.9748 - recall: 0.9885 - val_accuracy: 0.9837 - val_auc: 0.9984 - val_loss: 0.0475 - val_precision: 0.9764 - val_recall: 0.9915\n",
            "Epoch 38/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9799 - auc: 0.9977 - loss: 0.0728 - precision: 0.9706 - recall: 0.9894 - val_accuracy: 0.9856 - val_auc: 0.9986 - val_loss: 0.0431 - val_precision: 0.9867 - val_recall: 0.9845\n",
            "Epoch 39/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9815 - auc: 0.9980 - loss: 0.0691 - precision: 0.9738 - recall: 0.9900 - val_accuracy: 0.9857 - val_auc: 0.9986 - val_loss: 0.0437 - val_precision: 0.9814 - val_recall: 0.9902\n",
            "Epoch 40/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9802 - auc: 0.9978 - loss: 0.0703 - precision: 0.9746 - recall: 0.9865 - val_accuracy: 0.9764 - val_auc: 0.9972 - val_loss: 0.0707 - val_precision: 0.9584 - val_recall: 0.9960\n",
            "Epoch 41/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9838 - auc: 0.9983 - loss: 0.0616 - precision: 0.9768 - recall: 0.9908 - val_accuracy: 0.9684 - val_auc: 0.9981 - val_loss: 0.0798 - val_precision: 0.9945 - val_recall: 0.9420\n",
            "Epoch 42/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9805 - auc: 0.9976 - loss: 0.0722 - precision: 0.9739 - recall: 0.9876 - val_accuracy: 0.9849 - val_auc: 0.9983 - val_loss: 0.0449 - val_precision: 0.9788 - val_recall: 0.9912\n",
            "Epoch 43/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9829 - auc: 0.9977 - loss: 0.0673 - precision: 0.9754 - recall: 0.9905 - val_accuracy: 0.9845 - val_auc: 0.9986 - val_loss: 0.0441 - val_precision: 0.9776 - val_recall: 0.9918\n",
            "Epoch 44/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9828 - auc: 0.9982 - loss: 0.0641 - precision: 0.9760 - recall: 0.9904 - val_accuracy: 0.9852 - val_auc: 0.9988 - val_loss: 0.0413 - val_precision: 0.9897 - val_recall: 0.9808\n",
            "Epoch 45/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9819 - auc: 0.9979 - loss: 0.0676 - precision: 0.9754 - recall: 0.9887 - val_accuracy: 0.9816 - val_auc: 0.9987 - val_loss: 0.0512 - val_precision: 0.9916 - val_recall: 0.9715\n",
            "Epoch 46/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9834 - auc: 0.9977 - loss: 0.0645 - precision: 0.9760 - recall: 0.9911 - val_accuracy: 0.9865 - val_auc: 0.9985 - val_loss: 0.0400 - val_precision: 0.9822 - val_recall: 0.9910\n",
            "Epoch 47/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9831 - auc: 0.9982 - loss: 0.0613 - precision: 0.9762 - recall: 0.9908 - val_accuracy: 0.9869 - val_auc: 0.9983 - val_loss: 0.0412 - val_precision: 0.9848 - val_recall: 0.9890\n",
            "Epoch 48/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9846 - auc: 0.9982 - loss: 0.0595 - precision: 0.9776 - recall: 0.9918 - val_accuracy: 0.9842 - val_auc: 0.9985 - val_loss: 0.0450 - val_precision: 0.9759 - val_recall: 0.9930\n",
            "Epoch 49/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9856 - auc: 0.9983 - loss: 0.0560 - precision: 0.9788 - recall: 0.9926 - val_accuracy: 0.9851 - val_auc: 0.9987 - val_loss: 0.0418 - val_precision: 0.9901 - val_recall: 0.9800\n",
            "Epoch 50/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9837 - auc: 0.9982 - loss: 0.0606 - precision: 0.9773 - recall: 0.9906 - val_accuracy: 0.9869 - val_auc: 0.9988 - val_loss: 0.0387 - val_precision: 0.9843 - val_recall: 0.9895\n",
            "Epoch 51/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9841 - auc: 0.9987 - loss: 0.0562 - precision: 0.9778 - recall: 0.9909 - val_accuracy: 0.9819 - val_auc: 0.9988 - val_loss: 0.0473 - val_precision: 0.9941 - val_recall: 0.9695\n",
            "Epoch 52/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.9843 - auc: 0.9986 - loss: 0.0549 - precision: 0.9784 - recall: 0.9899 - val_accuracy: 0.9875 - val_auc: 0.9988 - val_loss: 0.0361 - val_precision: 0.9873 - val_recall: 0.9877\n",
            "Epoch 53/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9850 - auc: 0.9984 - loss: 0.0566 - precision: 0.9794 - recall: 0.9909 - val_accuracy: 0.9856 - val_auc: 0.9991 - val_loss: 0.0394 - val_precision: 0.9912 - val_recall: 0.9800\n",
            "Epoch 54/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9856 - auc: 0.9986 - loss: 0.0535 - precision: 0.9792 - recall: 0.9923 - val_accuracy: 0.9871 - val_auc: 0.9990 - val_loss: 0.0351 - val_precision: 0.9880 - val_recall: 0.9862\n",
            "Epoch 55/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9851 - auc: 0.9985 - loss: 0.0554 - precision: 0.9786 - recall: 0.9919 - val_accuracy: 0.9837 - val_auc: 0.9985 - val_loss: 0.0439 - val_precision: 0.9752 - val_recall: 0.9927\n",
            "Epoch 56/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9867 - auc: 0.9988 - loss: 0.0487 - precision: 0.9818 - recall: 0.9923 - val_accuracy: 0.9871 - val_auc: 0.9988 - val_loss: 0.0352 - val_precision: 0.9882 - val_recall: 0.9860\n",
            "Epoch 57/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.9861 - auc: 0.9985 - loss: 0.0529 - precision: 0.9809 - recall: 0.9916 - val_accuracy: 0.9824 - val_auc: 0.9991 - val_loss: 0.0452 - val_precision: 0.9941 - val_recall: 0.9705\n",
            "Epoch 58/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9876 - auc: 0.9983 - loss: 0.0506 - precision: 0.9823 - recall: 0.9930 - val_accuracy: 0.9867 - val_auc: 0.9988 - val_loss: 0.0380 - val_precision: 0.9807 - val_recall: 0.9930\n",
            "Epoch 59/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9871 - auc: 0.9986 - loss: 0.0520 - precision: 0.9820 - recall: 0.9924 - val_accuracy: 0.9842 - val_auc: 0.9985 - val_loss: 0.0438 - val_precision: 0.9752 - val_recall: 0.9937\n",
            "Epoch 60/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9855 - auc: 0.9987 - loss: 0.0540 - precision: 0.9786 - recall: 0.9928 - val_accuracy: 0.9880 - val_auc: 0.9991 - val_loss: 0.0347 - val_precision: 0.9907 - val_recall: 0.9852\n",
            "Epoch 61/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9867 - auc: 0.9989 - loss: 0.0488 - precision: 0.9812 - recall: 0.9923 - val_accuracy: 0.9872 - val_auc: 0.9985 - val_loss: 0.0381 - val_precision: 0.9839 - val_recall: 0.9908\n",
            "Epoch 62/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9858 - auc: 0.9986 - loss: 0.0541 - precision: 0.9801 - recall: 0.9915 - val_accuracy: 0.9887 - val_auc: 0.9991 - val_loss: 0.0341 - val_precision: 0.9910 - val_recall: 0.9865\n",
            "Epoch 63/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9864 - auc: 0.9985 - loss: 0.0496 - precision: 0.9808 - recall: 0.9921 - val_accuracy: 0.9864 - val_auc: 0.9987 - val_loss: 0.0347 - val_precision: 0.9826 - val_recall: 0.9902\n",
            "Epoch 64/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9864 - auc: 0.9987 - loss: 0.0490 - precision: 0.9813 - recall: 0.9915 - val_accuracy: 0.9869 - val_auc: 0.9990 - val_loss: 0.0383 - val_precision: 0.9924 - val_recall: 0.9812\n",
            "Epoch 65/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.9866 - auc: 0.9988 - loss: 0.0485 - precision: 0.9809 - recall: 0.9926 - val_accuracy: 0.9879 - val_auc: 0.9992 - val_loss: 0.0316 - val_precision: 0.9853 - val_recall: 0.9905\n",
            "Epoch 66/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9871 - auc: 0.9987 - loss: 0.0507 - precision: 0.9822 - recall: 0.9920 - val_accuracy: 0.9864 - val_auc: 0.9988 - val_loss: 0.0346 - val_precision: 0.9838 - val_recall: 0.9890\n",
            "Epoch 67/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9866 - auc: 0.9986 - loss: 0.0500 - precision: 0.9810 - recall: 0.9926 - val_accuracy: 0.9877 - val_auc: 0.9990 - val_loss: 0.0323 - val_precision: 0.9887 - val_recall: 0.9868\n",
            "Epoch 68/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9872 - auc: 0.9988 - loss: 0.0473 - precision: 0.9826 - recall: 0.9918 - val_accuracy: 0.9882 - val_auc: 0.9992 - val_loss: 0.0323 - val_precision: 0.9868 - val_recall: 0.9898\n",
            "Epoch 69/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9885 - auc: 0.9989 - loss: 0.0438 - precision: 0.9839 - recall: 0.9933 - val_accuracy: 0.9885 - val_auc: 0.9992 - val_loss: 0.0312 - val_precision: 0.9890 - val_recall: 0.9880\n",
            "Epoch 70/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9880 - auc: 0.9985 - loss: 0.0458 - precision: 0.9829 - recall: 0.9933 - val_accuracy: 0.9886 - val_auc: 0.9990 - val_loss: 0.0320 - val_precision: 0.9885 - val_recall: 0.9887\n",
            "Epoch 71/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9869 - auc: 0.9986 - loss: 0.0493 - precision: 0.9822 - recall: 0.9919 - val_accuracy: 0.9886 - val_auc: 0.9987 - val_loss: 0.0334 - val_precision: 0.9846 - val_recall: 0.9927\n",
            "Epoch 72/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9876 - auc: 0.9989 - loss: 0.0456 - precision: 0.9813 - recall: 0.9941 - val_accuracy: 0.9867 - val_auc: 0.9988 - val_loss: 0.0368 - val_precision: 0.9932 - val_recall: 0.9803\n",
            "Epoch 73/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9886 - auc: 0.9990 - loss: 0.0427 - precision: 0.9845 - recall: 0.9928 - val_accuracy: 0.9885 - val_auc: 0.9991 - val_loss: 0.0304 - val_precision: 0.9851 - val_recall: 0.9920\n",
            "Epoch 74/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9885 - auc: 0.9991 - loss: 0.0420 - precision: 0.9841 - recall: 0.9931 - val_accuracy: 0.9857 - val_auc: 0.9992 - val_loss: 0.0379 - val_precision: 0.9939 - val_recall: 0.9775\n",
            "Epoch 75/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9889 - auc: 0.9991 - loss: 0.0419 - precision: 0.9856 - recall: 0.9926 - val_accuracy: 0.9887 - val_auc: 0.9989 - val_loss: 0.0328 - val_precision: 0.9856 - val_recall: 0.9920\n",
            "Epoch 76/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9899 - auc: 0.9991 - loss: 0.0378 - precision: 0.9849 - recall: 0.9949 - val_accuracy: 0.9857 - val_auc: 0.9982 - val_loss: 0.0415 - val_precision: 0.9765 - val_recall: 0.9955\n",
            "Epoch 77/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9888 - auc: 0.9989 - loss: 0.0410 - precision: 0.9841 - recall: 0.9940 - val_accuracy: 0.9879 - val_auc: 0.9986 - val_loss: 0.0339 - val_precision: 0.9827 - val_recall: 0.9933\n",
            "Epoch 78/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9885 - auc: 0.9989 - loss: 0.0414 - precision: 0.9836 - recall: 0.9936 - val_accuracy: 0.9894 - val_auc: 0.9990 - val_loss: 0.0298 - val_precision: 0.9910 - val_recall: 0.9877\n",
            "Epoch 79/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9892 - auc: 0.9990 - loss: 0.0430 - precision: 0.9847 - recall: 0.9937 - val_accuracy: 0.9899 - val_auc: 0.9989 - val_loss: 0.0302 - val_precision: 0.9871 - val_recall: 0.9927\n",
            "Epoch 80/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9905 - auc: 0.9994 - loss: 0.0360 - precision: 0.9864 - recall: 0.9947 - val_accuracy: 0.9890 - val_auc: 0.9992 - val_loss: 0.0298 - val_precision: 0.9897 - val_recall: 0.9883\n",
            "Epoch 81/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9897 - auc: 0.9992 - loss: 0.0402 - precision: 0.9852 - recall: 0.9944 - val_accuracy: 0.9894 - val_auc: 0.9990 - val_loss: 0.0297 - val_precision: 0.9895 - val_recall: 0.9893\n",
            "Epoch 82/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9877 - auc: 0.9988 - loss: 0.0438 - precision: 0.9819 - recall: 0.9936 - val_accuracy: 0.9896 - val_auc: 0.9994 - val_loss: 0.0290 - val_precision: 0.9863 - val_recall: 0.9930\n",
            "Epoch 83/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9907 - auc: 0.9992 - loss: 0.0342 - precision: 0.9867 - recall: 0.9949 - val_accuracy: 0.9870 - val_auc: 0.9995 - val_loss: 0.0328 - val_precision: 0.9922 - val_recall: 0.9818\n",
            "Epoch 84/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9908 - auc: 0.9992 - loss: 0.0342 - precision: 0.9876 - recall: 0.9943 - val_accuracy: 0.9851 - val_auc: 0.9980 - val_loss: 0.0440 - val_precision: 0.9739 - val_recall: 0.9970\n",
            "Epoch 85/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.9893 - auc: 0.9990 - loss: 0.0400 - precision: 0.9849 - recall: 0.9939 - val_accuracy: 0.9896 - val_auc: 0.9992 - val_loss: 0.0283 - val_precision: 0.9910 - val_recall: 0.9883\n",
            "Epoch 86/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9907 - auc: 0.9990 - loss: 0.0389 - precision: 0.9865 - recall: 0.9951 - val_accuracy: 0.9897 - val_auc: 0.9993 - val_loss: 0.0284 - val_precision: 0.9876 - val_recall: 0.9920\n",
            "Epoch 87/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 17ms/step - accuracy: 0.9911 - auc: 0.9994 - loss: 0.0339 - precision: 0.9871 - recall: 0.9951 - val_accuracy: 0.9904 - val_auc: 0.9994 - val_loss: 0.0272 - val_precision: 0.9878 - val_recall: 0.9930\n",
            "Epoch 88/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.9900 - auc: 0.9991 - loss: 0.0363 - precision: 0.9858 - recall: 0.9943 - val_accuracy: 0.9905 - val_auc: 0.9994 - val_loss: 0.0278 - val_precision: 0.9895 - val_recall: 0.9915\n",
            "Epoch 89/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9907 - auc: 0.9992 - loss: 0.0356 - precision: 0.9869 - recall: 0.9946 - val_accuracy: 0.9870 - val_auc: 0.9993 - val_loss: 0.0349 - val_precision: 0.9932 - val_recall: 0.9808\n",
            "Epoch 90/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9914 - auc: 0.9994 - loss: 0.0322 - precision: 0.9874 - recall: 0.9954 - val_accuracy: 0.9889 - val_auc: 0.9991 - val_loss: 0.0302 - val_precision: 0.9858 - val_recall: 0.9920\n",
            "Epoch 91/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9899 - auc: 0.9992 - loss: 0.0360 - precision: 0.9856 - recall: 0.9945 - val_accuracy: 0.9892 - val_auc: 0.9990 - val_loss: 0.0277 - val_precision: 0.9858 - val_recall: 0.9927\n",
            "Epoch 92/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9895 - auc: 0.9991 - loss: 0.0364 - precision: 0.9860 - recall: 0.9931 - val_accuracy: 0.9886 - val_auc: 0.9994 - val_loss: 0.0322 - val_precision: 0.9919 - val_recall: 0.9852\n",
            "Epoch 93/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9916 - auc: 0.9989 - loss: 0.0351 - precision: 0.9876 - recall: 0.9958 - val_accuracy: 0.9902 - val_auc: 0.9992 - val_loss: 0.0276 - val_precision: 0.9883 - val_recall: 0.9923\n",
            "Epoch 94/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9910 - auc: 0.9993 - loss: 0.0330 - precision: 0.9868 - recall: 0.9952 - val_accuracy: 0.9907 - val_auc: 0.9990 - val_loss: 0.0282 - val_precision: 0.9878 - val_recall: 0.9937\n",
            "Epoch 95/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9895 - auc: 0.9991 - loss: 0.0385 - precision: 0.9858 - recall: 0.9934 - val_accuracy: 0.9895 - val_auc: 0.9992 - val_loss: 0.0265 - val_precision: 0.9875 - val_recall: 0.9915\n",
            "Epoch 96/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.9915 - auc: 0.9988 - loss: 0.0336 - precision: 0.9870 - recall: 0.9959 - val_accuracy: 0.9902 - val_auc: 0.9994 - val_loss: 0.0281 - val_precision: 0.9905 - val_recall: 0.9900\n",
            "Epoch 97/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9912 - auc: 0.9992 - loss: 0.0322 - precision: 0.9870 - recall: 0.9954 - val_accuracy: 0.9904 - val_auc: 0.9991 - val_loss: 0.0284 - val_precision: 0.9873 - val_recall: 0.9935\n",
            "Epoch 98/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.9913 - auc: 0.9990 - loss: 0.0335 - precision: 0.9878 - recall: 0.9950 - val_accuracy: 0.9892 - val_auc: 0.9988 - val_loss: 0.0290 - val_precision: 0.9849 - val_recall: 0.9937\n",
            "Epoch 99/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9908 - auc: 0.9994 - loss: 0.0316 - precision: 0.9866 - recall: 0.9951 - val_accuracy: 0.9890 - val_auc: 0.9991 - val_loss: 0.0305 - val_precision: 0.9830 - val_recall: 0.9952\n",
            "Epoch 100/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9913 - auc: 0.9992 - loss: 0.0339 - precision: 0.9873 - recall: 0.9955 - val_accuracy: 0.9897 - val_auc: 0.9993 - val_loss: 0.0288 - val_precision: 0.9910 - val_recall: 0.9885\n",
            "\n",
            "Run 4 Results:\n",
            "Test Loss: 0.0959\n",
            "Test Accuracy: 0.9715\n",
            "Test Precision: 0.9519\n",
            "Test Recall: 0.9332\n",
            "Test AUC: 0.9889\n",
            "\n",
            "==================================================\n",
            "Run 5/5\n",
            "==================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.8362 - auc: 0.9153 - loss: 0.5072 - precision: 0.8153 - recall: 0.8638 - val_accuracy: 0.9387 - val_auc: 0.9850 - val_loss: 0.2114 - val_precision: 0.9189 - val_recall: 0.9625\n",
            "Epoch 2/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9180 - auc: 0.9762 - loss: 0.2694 - precision: 0.8899 - recall: 0.9552 - val_accuracy: 0.9449 - val_auc: 0.9885 - val_loss: 0.1433 - val_precision: 0.9258 - val_recall: 0.9672\n",
            "Epoch 3/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.9303 - auc: 0.9815 - loss: 0.2407 - precision: 0.9070 - recall: 0.9591 - val_accuracy: 0.9380 - val_auc: 0.9901 - val_loss: 0.1546 - val_precision: 0.9076 - val_recall: 0.9753\n",
            "Epoch 4/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.9350 - auc: 0.9845 - loss: 0.2180 - precision: 0.9114 - recall: 0.9629 - val_accuracy: 0.9416 - val_auc: 0.9913 - val_loss: 0.1451 - val_precision: 0.9124 - val_recall: 0.9770\n",
            "Epoch 5/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9404 - auc: 0.9862 - loss: 0.2050 - precision: 0.9196 - recall: 0.9658 - val_accuracy: 0.9569 - val_auc: 0.9921 - val_loss: 0.1135 - val_precision: 0.9600 - val_recall: 0.9535\n",
            "Epoch 6/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9428 - auc: 0.9873 - loss: 0.1968 - precision: 0.9234 - recall: 0.9652 - val_accuracy: 0.9406 - val_auc: 0.9927 - val_loss: 0.1453 - val_precision: 0.9051 - val_recall: 0.9845\n",
            "Epoch 7/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.9484 - auc: 0.9897 - loss: 0.1737 - precision: 0.9283 - recall: 0.9713 - val_accuracy: 0.9644 - val_auc: 0.9945 - val_loss: 0.0952 - val_precision: 0.9617 - val_recall: 0.9672\n",
            "Epoch 8/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9539 - auc: 0.9911 - loss: 0.1625 - precision: 0.9358 - recall: 0.9739 - val_accuracy: 0.9646 - val_auc: 0.9952 - val_loss: 0.0908 - val_precision: 0.9556 - val_recall: 0.9745\n",
            "Epoch 9/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9548 - auc: 0.9919 - loss: 0.1562 - precision: 0.9388 - recall: 0.9740 - val_accuracy: 0.9666 - val_auc: 0.9955 - val_loss: 0.0886 - val_precision: 0.9698 - val_recall: 0.9632\n",
            "Epoch 10/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9570 - auc: 0.9923 - loss: 0.1509 - precision: 0.9420 - recall: 0.9742 - val_accuracy: 0.9604 - val_auc: 0.9955 - val_loss: 0.0966 - val_precision: 0.9421 - val_recall: 0.9810\n",
            "Epoch 11/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9595 - auc: 0.9926 - loss: 0.1453 - precision: 0.9435 - recall: 0.9777 - val_accuracy: 0.9615 - val_auc: 0.9959 - val_loss: 0.0959 - val_precision: 0.9389 - val_recall: 0.9872\n",
            "Epoch 12/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9590 - auc: 0.9933 - loss: 0.1403 - precision: 0.9452 - recall: 0.9754 - val_accuracy: 0.9707 - val_auc: 0.9963 - val_loss: 0.0773 - val_precision: 0.9606 - val_recall: 0.9818\n",
            "Epoch 13/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.9624 - auc: 0.9940 - loss: 0.1308 - precision: 0.9487 - recall: 0.9779 - val_accuracy: 0.9706 - val_auc: 0.9964 - val_loss: 0.0758 - val_precision: 0.9599 - val_recall: 0.9822\n",
            "Epoch 14/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.9643 - auc: 0.9944 - loss: 0.1271 - precision: 0.9511 - recall: 0.9787 - val_accuracy: 0.9630 - val_auc: 0.9963 - val_loss: 0.0959 - val_precision: 0.9374 - val_recall: 0.9923\n",
            "Epoch 15/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.9645 - auc: 0.9945 - loss: 0.1222 - precision: 0.9505 - recall: 0.9797 - val_accuracy: 0.9749 - val_auc: 0.9968 - val_loss: 0.0710 - val_precision: 0.9815 - val_recall: 0.9680\n",
            "Epoch 16/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.9668 - auc: 0.9941 - loss: 0.1253 - precision: 0.9549 - recall: 0.9802 - val_accuracy: 0.9794 - val_auc: 0.9975 - val_loss: 0.0607 - val_precision: 0.9766 - val_recall: 0.9822\n",
            "Epoch 17/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.9698 - auc: 0.9956 - loss: 0.1088 - precision: 0.9596 - recall: 0.9806 - val_accuracy: 0.9727 - val_auc: 0.9972 - val_loss: 0.0708 - val_precision: 0.9570 - val_recall: 0.9900\n",
            "Epoch 18/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9675 - auc: 0.9951 - loss: 0.1138 - precision: 0.9552 - recall: 0.9806 - val_accuracy: 0.9770 - val_auc: 0.9978 - val_loss: 0.0635 - val_precision: 0.9649 - val_recall: 0.9900\n",
            "Epoch 19/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.9692 - auc: 0.9959 - loss: 0.1077 - precision: 0.9549 - recall: 0.9849 - val_accuracy: 0.9800 - val_auc: 0.9979 - val_loss: 0.0570 - val_precision: 0.9827 - val_recall: 0.9772\n",
            "Epoch 20/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.9710 - auc: 0.9956 - loss: 0.1058 - precision: 0.9602 - recall: 0.9832 - val_accuracy: 0.9800 - val_auc: 0.9978 - val_loss: 0.0561 - val_precision: 0.9800 - val_recall: 0.9800\n",
            "Epoch 21/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9732 - auc: 0.9964 - loss: 0.0985 - precision: 0.9629 - recall: 0.9840 - val_accuracy: 0.9771 - val_auc: 0.9977 - val_loss: 0.0635 - val_precision: 0.9633 - val_recall: 0.9920\n",
            "Epoch 22/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.9709 - auc: 0.9953 - loss: 0.1083 - precision: 0.9599 - recall: 0.9826 - val_accuracy: 0.9805 - val_auc: 0.9979 - val_loss: 0.0551 - val_precision: 0.9856 - val_recall: 0.9753\n",
            "Epoch 23/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.9744 - auc: 0.9969 - loss: 0.0912 - precision: 0.9637 - recall: 0.9855 - val_accuracy: 0.9740 - val_auc: 0.9977 - val_loss: 0.0686 - val_precision: 0.9571 - val_recall: 0.9925\n",
            "Epoch 24/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9757 - auc: 0.9967 - loss: 0.0902 - precision: 0.9652 - recall: 0.9870 - val_accuracy: 0.9831 - val_auc: 0.9982 - val_loss: 0.0516 - val_precision: 0.9773 - val_recall: 0.9893\n",
            "Epoch 25/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.9761 - auc: 0.9968 - loss: 0.0872 - precision: 0.9669 - recall: 0.9862 - val_accuracy: 0.9787 - val_auc: 0.9980 - val_loss: 0.0580 - val_precision: 0.9890 - val_recall: 0.9682\n",
            "Epoch 26/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9773 - auc: 0.9968 - loss: 0.0851 - precision: 0.9681 - recall: 0.9871 - val_accuracy: 0.9835 - val_auc: 0.9981 - val_loss: 0.0487 - val_precision: 0.9782 - val_recall: 0.9890\n",
            "Epoch 27/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9757 - auc: 0.9965 - loss: 0.0892 - precision: 0.9654 - recall: 0.9868 - val_accuracy: 0.9802 - val_auc: 0.9981 - val_loss: 0.0548 - val_precision: 0.9704 - val_recall: 0.9908\n",
            "Epoch 28/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9782 - auc: 0.9971 - loss: 0.0836 - precision: 0.9692 - recall: 0.9878 - val_accuracy: 0.9820 - val_auc: 0.9982 - val_loss: 0.0547 - val_precision: 0.9888 - val_recall: 0.9750\n",
            "Epoch 29/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9775 - auc: 0.9975 - loss: 0.0797 - precision: 0.9685 - recall: 0.9872 - val_accuracy: 0.9837 - val_auc: 0.9984 - val_loss: 0.0463 - val_precision: 0.9830 - val_recall: 0.9845\n",
            "Epoch 30/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.9770 - auc: 0.9971 - loss: 0.0823 - precision: 0.9686 - recall: 0.9859 - val_accuracy: 0.9829 - val_auc: 0.9982 - val_loss: 0.0488 - val_precision: 0.9840 - val_recall: 0.9818\n",
            "Epoch 31/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9798 - auc: 0.9973 - loss: 0.0769 - precision: 0.9727 - recall: 0.9871 - val_accuracy: 0.9841 - val_auc: 0.9983 - val_loss: 0.0474 - val_precision: 0.9785 - val_recall: 0.9900\n",
            "Epoch 32/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9774 - auc: 0.9968 - loss: 0.0857 - precision: 0.9696 - recall: 0.9862 - val_accuracy: 0.9836 - val_auc: 0.9983 - val_loss: 0.0498 - val_precision: 0.9914 - val_recall: 0.9758\n",
            "Epoch 33/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.9799 - auc: 0.9977 - loss: 0.0731 - precision: 0.9712 - recall: 0.9890 - val_accuracy: 0.9842 - val_auc: 0.9987 - val_loss: 0.0453 - val_precision: 0.9783 - val_recall: 0.9905\n",
            "Epoch 34/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9797 - auc: 0.9974 - loss: 0.0750 - precision: 0.9721 - recall: 0.9875 - val_accuracy: 0.9837 - val_auc: 0.9986 - val_loss: 0.0461 - val_precision: 0.9894 - val_recall: 0.9780\n",
            "Epoch 35/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.9799 - auc: 0.9972 - loss: 0.0757 - precision: 0.9714 - recall: 0.9885 - val_accuracy: 0.9842 - val_auc: 0.9985 - val_loss: 0.0463 - val_precision: 0.9780 - val_recall: 0.9908\n",
            "Epoch 36/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.9803 - auc: 0.9977 - loss: 0.0737 - precision: 0.9727 - recall: 0.9887 - val_accuracy: 0.9846 - val_auc: 0.9985 - val_loss: 0.0438 - val_precision: 0.9804 - val_recall: 0.9890\n",
            "Epoch 37/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9790 - auc: 0.9975 - loss: 0.0738 - precision: 0.9704 - recall: 0.9877 - val_accuracy: 0.9779 - val_auc: 0.9976 - val_loss: 0.0627 - val_precision: 0.9632 - val_recall: 0.9937\n",
            "Epoch 38/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.9818 - auc: 0.9980 - loss: 0.0685 - precision: 0.9761 - recall: 0.9880 - val_accuracy: 0.9856 - val_auc: 0.9985 - val_loss: 0.0426 - val_precision: 0.9836 - val_recall: 0.9877\n",
            "Epoch 39/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9803 - auc: 0.9979 - loss: 0.0724 - precision: 0.9726 - recall: 0.9884 - val_accuracy: 0.9819 - val_auc: 0.9983 - val_loss: 0.0507 - val_precision: 0.9712 - val_recall: 0.9933\n",
            "Epoch 40/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.9813 - auc: 0.9978 - loss: 0.0697 - precision: 0.9743 - recall: 0.9892 - val_accuracy: 0.9817 - val_auc: 0.9984 - val_loss: 0.0514 - val_precision: 0.9918 - val_recall: 0.9715\n",
            "Epoch 41/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9826 - auc: 0.9980 - loss: 0.0652 - precision: 0.9746 - recall: 0.9909 - val_accuracy: 0.9836 - val_auc: 0.9985 - val_loss: 0.0479 - val_precision: 0.9750 - val_recall: 0.9927\n",
            "Epoch 42/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.9816 - auc: 0.9980 - loss: 0.0669 - precision: 0.9755 - recall: 0.9880 - val_accuracy: 0.9855 - val_auc: 0.9984 - val_loss: 0.0408 - val_precision: 0.9850 - val_recall: 0.9860\n",
            "Epoch 43/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.9829 - auc: 0.9983 - loss: 0.0616 - precision: 0.9764 - recall: 0.9896 - val_accuracy: 0.9866 - val_auc: 0.9988 - val_loss: 0.0398 - val_precision: 0.9834 - val_recall: 0.9900\n",
            "Epoch 44/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.9843 - auc: 0.9984 - loss: 0.0594 - precision: 0.9782 - recall: 0.9909 - val_accuracy: 0.9820 - val_auc: 0.9987 - val_loss: 0.0482 - val_precision: 0.9928 - val_recall: 0.9710\n",
            "Epoch 45/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.9831 - auc: 0.9984 - loss: 0.0596 - precision: 0.9761 - recall: 0.9904 - val_accuracy: 0.9694 - val_auc: 0.9983 - val_loss: 0.0761 - val_precision: 0.9953 - val_recall: 0.9433\n",
            "Epoch 46/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9835 - auc: 0.9983 - loss: 0.0606 - precision: 0.9766 - recall: 0.9908 - val_accuracy: 0.9864 - val_auc: 0.9986 - val_loss: 0.0407 - val_precision: 0.9822 - val_recall: 0.9908\n",
            "Epoch 47/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.9862 - auc: 0.9984 - loss: 0.0601 - precision: 0.9804 - recall: 0.9925 - val_accuracy: 0.9870 - val_auc: 0.9986 - val_loss: 0.0383 - val_precision: 0.9839 - val_recall: 0.9902\n",
            "Epoch 48/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.9844 - auc: 0.9986 - loss: 0.0547 - precision: 0.9786 - recall: 0.9903 - val_accuracy: 0.9881 - val_auc: 0.9987 - val_loss: 0.0374 - val_precision: 0.9865 - val_recall: 0.9898\n",
            "Epoch 49/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9853 - auc: 0.9985 - loss: 0.0573 - precision: 0.9797 - recall: 0.9912 - val_accuracy: 0.9866 - val_auc: 0.9989 - val_loss: 0.0394 - val_precision: 0.9904 - val_recall: 0.9827\n",
            "Epoch 50/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9851 - auc: 0.9985 - loss: 0.0576 - precision: 0.9799 - recall: 0.9906 - val_accuracy: 0.9856 - val_auc: 0.9988 - val_loss: 0.0411 - val_precision: 0.9786 - val_recall: 0.9930\n",
            "Epoch 51/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9848 - auc: 0.9984 - loss: 0.0570 - precision: 0.9782 - recall: 0.9915 - val_accuracy: 0.9879 - val_auc: 0.9987 - val_loss: 0.0371 - val_precision: 0.9904 - val_recall: 0.9852\n",
            "Epoch 52/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.9849 - auc: 0.9982 - loss: 0.0595 - precision: 0.9776 - recall: 0.9924 - val_accuracy: 0.9880 - val_auc: 0.9988 - val_loss: 0.0351 - val_precision: 0.9865 - val_recall: 0.9895\n",
            "Epoch 53/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9840 - auc: 0.9983 - loss: 0.0591 - precision: 0.9774 - recall: 0.9905 - val_accuracy: 0.9865 - val_auc: 0.9988 - val_loss: 0.0363 - val_precision: 0.9882 - val_recall: 0.9847\n",
            "Epoch 54/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.9853 - auc: 0.9984 - loss: 0.0559 - precision: 0.9795 - recall: 0.9910 - val_accuracy: 0.9869 - val_auc: 0.9983 - val_loss: 0.0417 - val_precision: 0.9807 - val_recall: 0.9933\n",
            "Epoch 55/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9850 - auc: 0.9985 - loss: 0.0561 - precision: 0.9797 - recall: 0.9908 - val_accuracy: 0.9875 - val_auc: 0.9990 - val_loss: 0.0347 - val_precision: 0.9892 - val_recall: 0.9858\n",
            "Epoch 56/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.9841 - auc: 0.9984 - loss: 0.0570 - precision: 0.9784 - recall: 0.9900 - val_accuracy: 0.9849 - val_auc: 0.9989 - val_loss: 0.0404 - val_precision: 0.9774 - val_recall: 0.9927\n",
            "Epoch 57/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.9877 - auc: 0.9988 - loss: 0.0475 - precision: 0.9825 - recall: 0.9932 - val_accuracy: 0.9882 - val_auc: 0.9988 - val_loss: 0.0353 - val_precision: 0.9865 - val_recall: 0.9900\n",
            "Epoch 58/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9849 - auc: 0.9983 - loss: 0.0561 - precision: 0.9783 - recall: 0.9919 - val_accuracy: 0.9826 - val_auc: 0.9984 - val_loss: 0.0468 - val_precision: 0.9719 - val_recall: 0.9940\n",
            "Epoch 59/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.9869 - auc: 0.9986 - loss: 0.0498 - precision: 0.9804 - recall: 0.9935 - val_accuracy: 0.9877 - val_auc: 0.9987 - val_loss: 0.0354 - val_precision: 0.9839 - val_recall: 0.9918\n",
            "Epoch 60/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9855 - auc: 0.9983 - loss: 0.0522 - precision: 0.9798 - recall: 0.9915 - val_accuracy: 0.9885 - val_auc: 0.9989 - val_loss: 0.0339 - val_precision: 0.9890 - val_recall: 0.9880\n",
            "Epoch 61/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.9857 - auc: 0.9984 - loss: 0.0544 - precision: 0.9800 - recall: 0.9917 - val_accuracy: 0.9864 - val_auc: 0.9991 - val_loss: 0.0373 - val_precision: 0.9914 - val_recall: 0.9812\n",
            "Epoch 62/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9860 - auc: 0.9988 - loss: 0.0500 - precision: 0.9810 - recall: 0.9913 - val_accuracy: 0.9886 - val_auc: 0.9990 - val_loss: 0.0335 - val_precision: 0.9902 - val_recall: 0.9870\n",
            "Epoch 63/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9864 - auc: 0.9987 - loss: 0.0496 - precision: 0.9805 - recall: 0.9925 - val_accuracy: 0.9856 - val_auc: 0.9985 - val_loss: 0.0398 - val_precision: 0.9786 - val_recall: 0.9930\n",
            "Epoch 64/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.9869 - auc: 0.9989 - loss: 0.0490 - precision: 0.9827 - recall: 0.9913 - val_accuracy: 0.9875 - val_auc: 0.9988 - val_loss: 0.0340 - val_precision: 0.9860 - val_recall: 0.9890\n",
            "Epoch 65/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.9868 - auc: 0.9990 - loss: 0.0460 - precision: 0.9816 - recall: 0.9922 - val_accuracy: 0.9887 - val_auc: 0.9992 - val_loss: 0.0333 - val_precision: 0.9915 - val_recall: 0.9860\n",
            "Epoch 66/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.9862 - auc: 0.9986 - loss: 0.0501 - precision: 0.9809 - recall: 0.9916 - val_accuracy: 0.9867 - val_auc: 0.9987 - val_loss: 0.0352 - val_precision: 0.9822 - val_recall: 0.9915\n",
            "Epoch 67/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9884 - auc: 0.9989 - loss: 0.0459 - precision: 0.9832 - recall: 0.9936 - val_accuracy: 0.9885 - val_auc: 0.9987 - val_loss: 0.0335 - val_precision: 0.9853 - val_recall: 0.9918\n",
            "Epoch 68/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9878 - auc: 0.9991 - loss: 0.0430 - precision: 0.9829 - recall: 0.9928 - val_accuracy: 0.9896 - val_auc: 0.9991 - val_loss: 0.0310 - val_precision: 0.9895 - val_recall: 0.9898\n",
            "Epoch 69/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9895 - auc: 0.9988 - loss: 0.0442 - precision: 0.9847 - recall: 0.9946 - val_accuracy: 0.9897 - val_auc: 0.9992 - val_loss: 0.0305 - val_precision: 0.9888 - val_recall: 0.9908\n",
            "Epoch 70/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.9879 - auc: 0.9990 - loss: 0.0431 - precision: 0.9830 - recall: 0.9927 - val_accuracy: 0.9894 - val_auc: 0.9990 - val_loss: 0.0307 - val_precision: 0.9900 - val_recall: 0.9887\n",
            "Epoch 71/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.9890 - auc: 0.9987 - loss: 0.0431 - precision: 0.9843 - recall: 0.9940 - val_accuracy: 0.9890 - val_auc: 0.9992 - val_loss: 0.0318 - val_precision: 0.9915 - val_recall: 0.9865\n",
            "Epoch 72/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9871 - auc: 0.9991 - loss: 0.0436 - precision: 0.9818 - recall: 0.9925 - val_accuracy: 0.9896 - val_auc: 0.9992 - val_loss: 0.0312 - val_precision: 0.9912 - val_recall: 0.9880\n",
            "Epoch 73/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.9902 - auc: 0.9990 - loss: 0.0391 - precision: 0.9854 - recall: 0.9951 - val_accuracy: 0.9871 - val_auc: 0.9992 - val_loss: 0.0353 - val_precision: 0.9942 - val_recall: 0.9800\n",
            "Epoch 74/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.9887 - auc: 0.9990 - loss: 0.0433 - precision: 0.9835 - recall: 0.9941 - val_accuracy: 0.9887 - val_auc: 0.9992 - val_loss: 0.0308 - val_precision: 0.9892 - val_recall: 0.9883\n",
            "Epoch 75/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.9896 - auc: 0.9991 - loss: 0.0393 - precision: 0.9857 - recall: 0.9935 - val_accuracy: 0.9882 - val_auc: 0.9991 - val_loss: 0.0317 - val_precision: 0.9922 - val_recall: 0.9843\n",
            "Epoch 76/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9891 - auc: 0.9990 - loss: 0.0391 - precision: 0.9848 - recall: 0.9935 - val_accuracy: 0.9879 - val_auc: 0.9987 - val_loss: 0.0361 - val_precision: 0.9820 - val_recall: 0.9940\n",
            "Epoch 77/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9894 - auc: 0.9990 - loss: 0.0396 - precision: 0.9855 - recall: 0.9937 - val_accuracy: 0.9879 - val_auc: 0.9990 - val_loss: 0.0336 - val_precision: 0.9820 - val_recall: 0.9940\n",
            "Epoch 78/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.9880 - auc: 0.9988 - loss: 0.0451 - precision: 0.9837 - recall: 0.9924 - val_accuracy: 0.9877 - val_auc: 0.9986 - val_loss: 0.0357 - val_precision: 0.9817 - val_recall: 0.9940\n",
            "Epoch 79/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9898 - auc: 0.9993 - loss: 0.0371 - precision: 0.9858 - recall: 0.9941 - val_accuracy: 0.9892 - val_auc: 0.9991 - val_loss: 0.0322 - val_precision: 0.9912 - val_recall: 0.9872\n",
            "\n",
            "Run 5 Results:\n",
            "Test Loss: 0.0805\n",
            "Test Accuracy: 0.9721\n",
            "Test Precision: 0.9472\n",
            "Test Recall: 0.9408\n",
            "Test AUC: 0.9921\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\\nFinal Summary:\")\n",
        "print(\"=\"*50)\n",
        "for metric_name, values in metrics.items():\n",
        "    mean = np.mean(values)\n",
        "    std = np.std(values)\n",
        "    print(f\"{metric_name}: {mean:.4f} ± {std:.4f}\")"
      ],
      "metadata": {
        "id": "8dzGTaS75d1o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc7736a2-9c69-4234-8fc1-160f001b09d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Final Summary:\n",
            "==================================================\n",
            "accuracy: 0.9716 ± 0.0007\n",
            "precision: 0.9461 ± 0.0042\n",
            "recall: 0.9402 ± 0.0063\n",
            "auc: 0.9914 ± 0.0016\n",
            "loss: 0.0857 ± 0.0064\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_history(history):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend()\n",
        "\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Model Loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_training_history(history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "mAzsarHf5o9c",
        "outputId": "136fc2aa-7fd6-4b79-cd91-93d9449c430e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAGGCAYAAACqvTJ0AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAA879JREFUeJzs3Xd4FFX3wPHv7qb3hHQIpNBbQu9NUIoi0kEUQQSliIivKIKAWFAURERF8EcRaUqzgIBEUHrvHQIpQBKSkN535/fHkIU1CSQhBcL5PM8+sztz586Zhfd1OHvvuRpFURSEEEIIIYQQQgghhChF2rIOQAghhBBCCCGEEEI8fiQpJYQQQgghhBBCCCFKnSSlhBBCCCGEEEIIIUSpk6SUEEIIIYQQQgghhCh1kpQSQgghhBBCCCGEEKVOklJCCCGEEEIIIYQQotRJUkoIIYQQQgghhBBClDpJSgkhhBBCCCGEEEKIUidJKSGEEEIIIYQQQghR6iQpJYR4KGk0GqZNm1bo865evYpGo2HJkiXFHpMQQgghxONEnseEECVNklJCiHwtWbIEjUaDRqNh165duY4rioKPjw8ajYZnnnmmDCIsHps2bUKj0eDt7Y3BYCjrcIQQQgghjMrz89iOHTvQaDSsWbOmrEMRQpQRSUoJIe7LysqKFStW5Nr/zz//EBERgaWlZRlEVXyWL1+Or68vN27c4O+//y7rcIQQQgghcinvz2NCiMeTJKWEEPfVrVs3fvnlF7Kzs032r1ixgkaNGuHp6VlGkT24lJQUfv31V8aPH0+DBg1Yvnx5WYeUr5SUlLIOQQghhBBlpDw/jwkhHl+SlBJC3NfAgQOJjY3lr7/+Mu7LzMxkzZo1PP/883mek5KSwltvvYWPjw+WlpbUqFGDL774AkVRTNplZGTw5ptv4ubmhr29Pc8++ywRERF59nnt2jVefvllPDw8sLS0pE6dOixatOiB7m39+vWkpaXRt29fBgwYwLp160hPT8/VLj09nWnTplG9enWsrKzw8vKiV69eXL582djGYDDw1VdfUa9ePaysrHBzc6NLly4cOnQIuHd9hf/WbJg2bRoajYYzZ87w/PPP4+zsTOvWrQE4ceIEQ4YMwd/fHysrKzw9PXn55ZeJjY3N8zsbNmwY3t7eWFpa4ufnx8iRI8nMzCQkJASNRsOXX36Z67w9e/ag0WhYuXJlYb9SIYQQQpSA8vw8dj8hISH07dsXFxcXbGxsaN68ORs3bszV7uuvv6ZOnTrY2Njg7OxM48aNTUaXJSUlMW7cOHx9fbG0tMTd3Z0nn3ySI0eOlGj8Qoj8mZV1AEKIh5+vry8tWrRg5cqVdO3aFYA///yThIQEBgwYwNy5c03aK4rCs88+y/bt2xk2bBhBQUFs2bKFt99+m2vXrpkkQV555RV++uknnn/+eVq2bMnff//N008/nSuGqKgomjdvjkajYcyYMbi5ufHnn38ybNgwEhMTGTduXJHubfny5XTo0AFPT08GDBjAu+++y++//07fvn2NbfR6Pc888wzBwcEMGDCAN954g6SkJP766y9OnTpFQEAAAMOGDWPJkiV07dqVV155hezsbHbu3Mm+ffto3LhxkeLr27cv1apV45NPPjE+QP7111+EhIQwdOhQPD09OX36NAsWLOD06dPs27cPjUYDwPXr12natCnx8fGMGDGCmjVrcu3aNdasWUNqair+/v60atWK5cuX8+abb+b6Xuzt7enRo0eR4hZCCCFE8SrPz2P3EhUVRcuWLUlNTWXs2LFUqFCBpUuX8uyzz7JmzRp69uwJwMKFCxk7dix9+vThjTfeID09nRMnTrB//35j0u61115jzZo1jBkzhtq1axMbG8uuXbs4e/YsDRs2LPbYhRAFoAghRD4WL16sAMrBgweVefPmKfb29kpqaqqiKIrSt29fpUOHDoqiKEqVKlWUp59+2njehg0bFED56KOPTPrr06ePotFolEuXLimKoijHjh1TAGXUqFEm7Z5//nkFUKZOnWrcN2zYMMXLy0uJiYkxaTtgwADF0dHRGNeVK1cUQFm8ePF97y8qKkoxMzNTFi5caNzXsmVLpUePHibtFi1apADK7Nmzc/VhMBgURVGUv//+WwGUsWPH5tvmXrH9936nTp2qAMrAgQNztc2517utXLlSAZR///3XuG/w4MGKVqtVDh48mG9M33//vQIoZ8+eNR7LzMxUXF1dlZdeeinXeUIIIYQoXeX5eWz79u0KoPzyyy/5thk3bpwCKDt37jTuS0pKUvz8/BRfX19Fr9criqIoPXr0UOrUqXPP6zk6OiqjR4++ZxshROmS6XtCiALp168faWlp/PHHHyQlJfHHH3/kO1R806ZN6HQ6xo4da7L/rbfeQlEU/vzzT2M7IFe7//7KpigKa9eupXv37iiKQkxMjPHVuXNnEhISijTsetWqVWi1Wnr37m3cN3DgQP78809u3bpl3Ld27VpcXV15/fXXc/WRMypp7dq1aDQapk6dmm+bonjttddy7bO2tja+T09PJyYmhubNmwMYvweDwcCGDRvo3r17nqO0cmLq168fVlZWJrW0tmzZQkxMDC+88EKR4xZCCCFE8SuPz2P3s2nTJpo2bWosYwBgZ2fHiBEjuHr1KmfOnAHAycmJiIgIDh48mG9fTk5O7N+/n+vXrxd7nEKIopGklBCiQNzc3OjUqRMrVqxg3bp16PV6+vTpk2fb0NBQvL29sbe3N9lfq1Yt4/GcrVarNU5/y1GjRg2Tzzdv3iQ+Pp4FCxbg5uZm8ho6dCgA0dHRhb6nn376iaZNmxIbG8ulS5e4dOkSDRo0IDMzk19++cXY7vLly9SoUQMzs/xnPF++fBlvb29cXFwKHce9+Pn55doXFxfHG2+8gYeHB9bW1ri5uRnbJSQkAOp3lpiYSN26de/Zv5OTE927dzept7B8+XIqVqzIE088UYx3IoQQQogHVR6fx+4nNDQ0Vyx53cc777yDnZ0dTZs2pVq1aowePZrdu3ebnDNz5kxOnTqFj48PTZs2Zdq0aYSEhBR7zEKIgpOaUkKIAnv++ecZPnw4kZGRdO3aFScnp1K5rsFgAOCFF17gpZdeyrNN/fr1C9XnxYsXjb+kVatWLdfx5cuXM2LEiEJGem/5jZjS6/X5nnP3qKgc/fr1Y8+ePbz99tsEBQVhZ2eHwWCgS5cuxu+qMAYPHswvv/zCnj17qFevHr/99hujRo1Cq5XfLYQQQoiHTXl6HitOtWrV4vz58/zxxx9s3ryZtWvX8u233zJlyhQ++OADQH2GatOmDevXr2fr1q18/vnnfPbZZ6xbt85Yp0sIUbokKSWEKLCePXvy6quvsm/fPlavXp1vuypVqrBt2zaSkpJMfp07d+6c8XjO1mAwGEci5Th//rxJfzkrwej1ejp16lQs97J8+XLMzc1ZtmwZOp3O5NiuXbuYO3cuYWFhVK5cmYCAAPbv309WVhbm5uZ59hcQEMCWLVuIi4vLd7SUs7MzAPHx8Sb7c37hK4hbt24RHBzMBx98wJQpU4z7L168aNLOzc0NBwcHTp06dd8+u3TpgpubG8uXL6dZs2akpqby4osvFjgmIYQQQpSe8vQ8VhBVqlTJFQvkvg8AW1tb+vfvT//+/cnMzKRXr158/PHHTJw4ESsrKwC8vLwYNWoUo0aNIjo6moYNG/Lxxx9LUkqIMiI/gwshCszOzo7vvvuOadOm0b1793zbdevWDb1ez7x580z2f/nll2g0GuN/9HO2/10tZs6cOSafdTodvXv3Zu3atXkmWW7evFnoe1m+fDlt2rShf//+9OnTx+T19ttvA7By5UoAevfuTUxMTK77AYwr4vXu3RtFUYy/xOXVxsHBAVdXV/7991+T499++22B485JoCn/Wcr5v9+ZVqvlueee4/fff+fQoUP5xgRgZmbGwIED+fnnn1myZAn16tUr0186hRBCCJG/8vQ8VhDdunXjwIED7N2717gvJSWFBQsW4OvrS+3atQGIjY01Oc/CwoLatWujKApZWVno9XpjmYMc7u7ueHt7k5GRUSKxCyHuT0ZKCSEKJb/h2nfr3r07HTp0YNKkSVy9epXAwEC2bt3Kr7/+yrhx44w1C4KCghg4cCDffvstCQkJtGzZkuDgYC5dupSrz08//ZTt27fTrFkzhg8fTu3atYmLi+PIkSNs27aNuLi4At/D/v37uXTpEmPGjMnzeMWKFWnYsCHLly/nnXfeYfDgwfz444+MHz+eAwcO0KZNG1JSUti2bRujRo2iR48edOjQgRdffJG5c+dy8eJF41S6nTt30qFDB+O1XnnlFT799FNeeeUVGjduzL///suFCxcKHLuDgwNt27Zl5syZZGVlUbFiRbZu3cqVK1dytf3kk0/YunUr7dq1Y8SIEdSqVYsbN27wyy+/sGvXLpPh/oMHD2bu3Lls376dzz77rMDxCCGEEKL0lYfnsbutXbvWOPLpv/f57rvvsnLlSrp27crYsWNxcXFh6dKlXLlyhbVr1xrLDTz11FN4enrSqlUrPDw8OHv2LPPmzePpp5/G3t6e+Ph4KlWqRJ8+fQgMDMTOzo5t27Zx8OBBZs2aVaS4hRDFoGwW/RNCPAruXoL4Xv67BLGiqEv1vvnmm4q3t7dibm6uVKtWTfn8888Vg8Fg0i4tLU0ZO3asUqFCBcXW1lbp3r27Eh4enmsJYkVRlKioKGX06NGKj4+PYm5urnh6eiodO3ZUFixYYGxTkCWIX3/9dQVQLl++nG+badOmKYBy/PhxRVEUJTU1VZk0aZLi5+dnvHafPn1M+sjOzlY+//xzpWbNmoqFhYXi5uamdO3aVTl8+LCxTWpqqjJs2DDF0dFRsbe3V/r166dER0fnut+pU6cqgHLz5s1csUVERCg9e/ZUnJycFEdHR6Vv377K9evX8/zOQkNDlcGDBytubm6KpaWl4u/vr4wePVrJyMjI1W+dOnUUrVarRERE5Pu9CCGEEKJ0ldfnMUVRlO3btytAvq+dO3cqiqIoly9fVvr06aM4OTkpVlZWStOmTZU//vjDpK/vv/9eadu2rVKhQgXF0tJSCQgIUN5++20lISFBURRFycjIUN5++20lMDBQsbe3V2xtbZXAwEDl22+/vWeMQoiSpVGU/8wBEUII8Vhq0KABLi4uBAcHl3UoQgghhBBCiMeA1JQSQgjBoUOHOHbsGIMHDy7rUIQQQgghhBCPCRkpJYQQj7FTp05x+PBhZs2aRUxMDCEhIcbVaYQQQgghhBCiJMlIKSGEeIytWbOGoUOHkpWVxcqVKyUhJYQQQgghhCg1MlJKCCGEEEIIIYQQQpQ6GSklhBBCCCGEEEIIIUqdJKWEEEIIIYQQQgghRKkzK+sAHkYGg4Hr169jb2+PRqMp63CEEEIIUYYURSEpKQlvb2+0Wvk9717kGUoIIYQQUPDnJ0lK5eH69ev4+PiUdRhCCCGEeIiEh4dTqVKlsg7joSbPUEIIIYS42/2enyQplQd7e3tA/fIcHBzKOBohhBBClKXExER8fHyMzwcif/IMJYQQQggo+POTJKXykDPc3MHBQR6ohBBCCAEg09EKQJ6hhBBCCHG3+z0/SWEEIYQQQgghhBBCCFHqJCklhBBCCCGEEEIIIUqdJKWEEEIIIYQQQgghRKmTmlJCCCGEEEIIIUQ5ZTAYyMzMLOswRDljbm6OTqd74H4kKSWEEEIIIYQQQpRDmZmZXLlyBYPBUNahiHLIyckJT0/PB1oMRpJSQgghhBBCCCFEOaMoCjdu3ECn0+Hj44NWK9V7RPFQFIXU1FSio6MB8PLyKnJfkpQSQgghhBBCCCHKmezsbFJTU/H29sbGxqaswxHljLW1NQDR0dG4u7sXeSqfpEqFEEIIIYQQQohyRq/XA2BhYVHGkYjyKifZmZWVVeQ+JCklhBBCCCGEEEKUUw9S70eIeymOv1uSlBJCCCGEEEIIIYQQpU5qSgkhhBCPoqRIOLoMEm9ARiJkJN1+JUJGMth5gHtNcKsJbjXUrb0XFOQXLYMerh+FqzuhYmPwa1Py9/MADofGcTQsnlfa+Jd1KKIEdZnzL7Epmfw+pjWejlZlHY4QQohHiK+vL+PGjWPcuHFlHYr4D0lKCSGEEI+SxOuwaw4cXgL6jPzb3boC4ftM91k63k5Q1QD3Wrff1wIHb0i8BpeC4fLfELID0uPVc7TmMOgXCOhw39BSMrLRaTVYmRet0GVhHbgSx1fbzuNzdQ21tWFcrbUEX1fbUrm2KH03kzKITckkPi1TklJCCFFO3W862NSpU5k2bVqh+z148CC2tg/2jNC+fXuCgoKYM2fOA/UjTElSSgghhChNiqImjJyqgLYQyZuEa7DrSzjy451klE8z8O8AlvZgaU+CYsWnf1/n0i0DXpo42jjdpItHAvaJlyAuBDISIOKA+rqbuQ1kpZrus3RUk1U3z8LqF2DIRvAOyhVWXEomW05HsunkDU5dDsVWm4WfX1XaVnOjTXVXanjY3/cBU1EUbqVmERqbQmhsKmFxqZjrtNTxdqCOtwMV7CxN2u8LieWrbRcJCznHDPMfaGt+Uo0lch+4diz4dyoeKQ7W5sSmZJKYll3WoQghhCghN27cML5fvXo1U6ZM4fz588Z9dnZ2xveKoqDX6zEzu39aw83NrXgDFcVGklJCCCEeP9mZ6migG8eh4Ytg73n/c87/qSaF2vwPqj9VtOteOwJb34fQXVC5JQxYDjYu9z4nLR5D8Idoj/4I+kx1X+WW0P4d8GtnnI4XlZjOwIX7CImzw83ekrOZen6Ly2ZivIbX2gUwpq0PVgkhcPMc3Dx/e3sOYi+rCSmNVp2qF/AEVO0I3g1B0cPyPnDlX3X78haoEEBMcoYxEbUvJA6DQc8I3Ub+z/xnLDR6roe5cORqNX7ZUpWrVrVxrdYUL1cn0rL0pGXeft1+H5WUTmhMKkkZ+ScaPB2sqFvRgdpeDhy4Gsf+kBgG6YJZaLkSO006is4KTcf3candvmh/LuKR4GBtDkBCWtFX+BFCCPFw8/S880zm6OiIRqMx7tuxYwcdOnRg06ZNTJ48mZMnT7J161Z8fHwYP348+/btIyUlhVq1ajFjxgw6depk7Ou/0/c0Gg0LFy5k48aNbNmyhYoVKzJr1iyeffbZIse+du1apkyZwqVLl/Dy8uL111/nrbfeMh7/9ttv+fLLLwkPD8fR0ZE2bdqwZs0aANasWcMHH3zApUuXsLGxoUGDBvz6668PPLrrUSBJKSGEKI/0WXBqnVpfqOFLYFZMSwHrs+6qW5QEVo7gVLl4+i6oEz/Dvm+h5wJwq17w87Iz4PJ2OPMrnN8I6Qnq/qPLYPCv4OKX/7lnfoM1Q8GQDWtehhE7wLVqwa99KxSCp8OpNXf2he2BRV3ghTX5fodZ146Tsux5nNIjAEjybIZ958ng28akNtT1+DSeX7iPq7GpVHSyZsXwZlia6Zjy6ym2noli3vZLbDx5g4971qVlvbpk6w0kpmcTn5pJQnIKmTEhWDp64uXphZudJVptTt9m0H85+sVPo4s6QdyC7oy2nMHe6DuPDx7EscBuAYHZJwBQ0OCticNbt59ndPtBD5lndVxUKnFBqcRFQ0VuKJW4qFQkTPHAcNeaK16OVlR2saFKBRtSM/WcuZ5ISEwKkYnpRCams+1sND6aKFZYLKSF9ox6UuUWaHp8AxUCCv7nIR5JDlbq37tESUoJIUSRKIpCWpa+TK5tba4rtlUA3333Xb744gv8/f1xdnYmPDycbt268fHHH2NpacmPP/5I9+7dOX/+PJUr5/+c+sEHHzBz5kw+//xzvv76awYNGkRoaCguLvf5wTAPhw8fpl+/fkybNo3+/fuzZ88eRo0aRYUKFRgyZAiHDh1i7NixLFu2jJYtWxIXF8fOnTsBdXTYwIEDmTlzJj179iQpKYmdO3eiKEqRv6NHiSSlhBCiPNFnwfGVsHMW3Lqq7ju8BJ77FrwCC9+fQQ9/TVETQRmJkJ2eu03jYfDkB+oUspIWcwl+e12NY+cs6PX9/c9Jjlbv4dwmdfpaDjsP0JpBfKiaHBq8Qa2z9F+nN6iJKEUPlg7q9/DLS/DKNjC3vve1027Bv1/AgQW3RzlpoH5/qN8Xfn0dYs7DD53Umk3/+fO5vuMHKuyYiBOZRCiuvJ31Knuv1qHLLlv+Z5tCVXd1+Hp4XCrP/7CP8Lg0fFysWfFKc3xcbABYMLgxm09FMvW3U1yJSeH5hfuxtzTLZ1RSHHAGC52Wis7WVHSyxsvRiisxKYSHj2S12TR8M64xOe19BvA+fpW8GOV5jicvfYQu/ZY6BbDrZ2jq9FKLpEccRB9+EH3YfizSY6mjCaUOoXDXjEW91oIsS2d0Wi1mWo36sJqC+tKZg50Dehd7EhUr4rIsiU2HoMS/sTCkq9frOBWajgCtLCb8OHCUkVJCCPFA0rL01J6ypUyufWZ6Z2wsiif9MH36dJ588knjZxcXFwID7zxHffjhh6xfv57ffvuNMWPG5NvPkCFDGDhwIACffPIJc+fO5cCBA3Tp0qXQMc2ePZuOHTvy/vvvA1C9enXOnDnD559/zpAhQwgLC8PW1pZnnnkGe3t7qlSpQoMGDQA1KZWdnU2vXr2oUqUKAPXq1St0DI8qSUoJIUR5kJ0Jx1eoiZr4MHWfjSsoBog6BQs6QJvx0PZtMLO8d185DHrYMApOrMp9zMwaLO0g5SYc+j+4+Bf0+Br82xesb0WBmItqUe3LwZAcBT2+Bc+694ln5J3E2On10GXG/ae//ToaLm5V39t7Qa1noc5zaj2mlJuwrCdEn4HFXWHQWqjU6M65p9fDmmFqQqr+AOj4PnzfTv1O/3wHnp2bd6gGhewzv2P+x+tocgqG+7WDpz68k3x6ZRss7wvRp2FxN+j3I1TtSGZ6KucXj6Re1AYAdtKAyE5f4RMF+w9HsPl0JH+djaJf40r0aliJcauOcS0+Dd8KNqwY3hxvJ9NEWZe6nrSsWoGZm8/x074wk4SUvaUZjjbmOFiZk5CWRWRiOpl6A1diUrgSk3JXL468azONhdnvUSc7lMPVFmPhXh0OL1YPewVC7/8D12q377UN+LVBB+gURU38RZ1WpwtG3542GHMBXXY6urSoe/7x6QDn2y/jWCjfNup37yKr7T1OcqbvJaZLUkoIIR5njRs3NvmcnJzMtGnT2LhxozHBk5aWRlhY2D37qV+/vvG9ra0tDg4OREdHFymms2fP0qNHD5N9rVq1Ys6cOej1ep588kmqVKmCv78/Xbp0oUuXLvTs2RMbGxsCAwPp2LEj9erVo3Pnzjz11FP06dMHZ2fnIsXyqJGklBBCPKoURf3H/cW/4MBCSLj9H15bN2j1BjR+GTJTYdP/4MwG+PdzOPuHOmqqYsN7952TADqxGjQ6ePZr8G1tLKiNTv3HISE71JFL8WHwYw9oNASe/BCsHHLHmngNIg6pSajL2yEh3LTNin5qosbBO++Y9n6jFui2dAA7d4i9pI4KazE6//u4ef52QkoDL6xVi4LfParG3lMt4L28L1w7BD8+CwNXgl9bOLUW1g5XE1KBA9F3n8fx60mkN/iMFrtfQXNkKYsivPlVacPNxHTSsvRkZhvI1OsZzgYmmP8MwGVNZbZVHI1t9S400VSgmkFRp8c5VoSX/1SLiF/5F2VFPyIbv0Py4VXU01/GoGj43eUlWgydQRsHG/oCr7TxZ+bm82w7G8XKA+GsPKB+h/5utqx4pXm+K5I5WJnz0XP1GNOhGqmZ2TjZWOBgZYaZznSEUbbeQGRiOhG30oi4lcb1+DTc7S1pVdVVHX11ow4sfhqL8N0Qvls9qeVYeOL9/KeIajTg7Ku+aj59Z79Bryar0hPzPk+fqY5KS789VTRn2qhrdajTS0ZHPYZkpJQQQjwYa3MdZ6Z3LrNrF5f/1ln63//+x19//cUXX3xB1apVsba2pk+fPmRmZt6zH3Nzc5PPGo0Gg8FQbHHezd7eniNHjrBjxw62bt3KlClTmDZtGgcPHsTJyYm//vqLPXv2sHXrVr7++msmTZrE/v378fO7R3mJckKSUkIIUZIyktXEjqNP0Ytj3y017vboou3qNun6nWN2HtBqnJoYslCnb2FhC/2WqlPQNr6lrqT2Q0c1kdNyrJrc+S99Nmx4DU7+ok5v67MIavfI3Q7UkVEj98K2aXBwoTpV8OI2aP+uOnXNWFD7PGQmmZ6rs4AqLdVE0bEV6lS2Ff1g6J+5pwLePA9/fwTA7qrjuRGXRB9moRxajKb5KJP6Sncz7P0WLXDeqQ3XsuvSDg25HolsXNSaUquehyv/wE99oOlwtW6VYiCj7gCWOo/nx1n/EnErDbBmnFlPxpmtY0DUbJZnunBdqQiAJZl8Yb6AHro9ACzJfoqPsl8g+5IZXDoNqHVxgio7o9Wo/7hOSRnLOI1CN8NOvA58DMAt7Dnf6kuefbKPSf2F6h72/PBSYw5djePTP89xKPQW1dztWD68Ge72eSek7pZf0iqHmU5LJWcbKjnb5N3AKxAGroDl/dR6Yj3nQ0CH+143T1qdjHQShZKTlJLV94QQomg0Gk2xTaF7mOzevZshQ4bQs2dPQB05dfXq1VKNoVatWuzevTtXXNWrV0enU58+zczM6NSpE506dWLq1Kk4OTnx999/06tXLzQaDa1ataJVq1ZMmTKFKlWqsH79esaPH1+q91EWyt/fSCGEeBhkJKl1hPbMg7Q4dbTR64ce7B/h60aotZ24q+ihmRVUaQU1u0HQoPxrHNV5Tp3y9OcEtdj2nq9h//dQrx80H3ln2pw+G9a/qrbRmkGfxVD7PquQWNrB01+oiavfxqi1rH7LY/6+1kwd5eLfXl3hrUqrO8mzOs+ptZUiT6r1mwasBJ2ZMSb9utfQ6TPYrWnAoMPVsCWdLpZW2MVeZMfWDbTs2AMLszsjZ9Iy9fy29wTPHVmBJfB+VDsOLDlEJWdrnm9Wmf6Nfahgd9c0Rks7eP5n9drnN8LeeQAcdH6awcefJS3rIqD+o7iGpz1XHUZz9UY4vokH2eC2gCvP/YadkkzFLa9gGX0cRWtGxpOf0jNoCFUjEjh4NY5DoXEcCY0nMT2bfy/cNPlqRvEab5s5M9rsN65Y1cJx8HKae+dfuLuxrwu/vNaCMzcS8Xe1w9qi+H59vC+/tjD+jJrwLOhUUCGKgYOVjJQSQgiRW7Vq1Vi3bh3du3dHo9Hw/vvvl9iIp5s3b3Ls2DGTfV5eXrz11ls0adKEDz/8kP79+7N3717mzZvHt99+C8Aff/xBSEgIbdu2xdnZmU2bNmEwGKhRowb79+8nODiYp556Cnd3d/bv38/NmzepVSuPWqflkCSlhBCiOKUnwoHv1almabfUfRqdOgVs52zoMa+I/SaoI64A3OtA1SfUxE7llmB+/xEyANhWgD7/B/X6qlP5rh2CYz+pL7+20HyUOjrq1Fo1gdR3KdR6puAx+rWBkXtgx6dwdac6Xcut5p2Xi3/+U7ycfWHgKljytDrd7s8J8PQs4tOyOL16Kq1uHCFRsWF8+jAqOtnQvkYV/jzemr5sI2HXAtofcWBYG3+equ3BL4fCWbYvlOczfsHSPJMz+OFd/wkcL8QQcSuNmZvPM+evi3Sr50nfxj7otBriUjKJTcnkluv7tLlpoEHcn6zIfoJJNwaiALW8HBja0pdng7yxyhl+nrwC5rfGPvEi9feOgxvHITkSrJ3R9FuGlV8brIDW1VxpXc0VgCy9gbM3Ejl5LQELnRZHa3OcbCxubzuRrv8MP0fPAk1N02g01PF2LPifT3G6Xx0vIUqAo9SUEkIIkYfZs2fz8ssv07JlS1xdXXnnnXdITMynPMADWrFiBStWrDDZ9+GHHzJ58mR+/vlnpkyZwocffoiXlxfTp09nyJAhADg5ObFu3TqmTZtGeno61apVY+XKldSpU4ezZ8/y77//MmfOHBITE6lSpQqzZs2ia9euJXIPDxuN8risM1gIiYmJODo6kpCQgIODw/1PEEI8/NLi1elZvq2hw3vF379BD3vmwq45kFPYukJVaDsBnHzUItpaMxh7FJzyX5o2X9ePwYJ2YOsOb18snpjDD6jJs7O/qQXRc2jN1Sl/d9f/yUNCahY3k9Pxd7VTayTdh6IopGTqsbXIf0ng1OPrsV4/FA0Kayq8xvKYqqzmHSw0emZYvkG1p0bQI8gbc52WlKuHsF3SkSzMaJY+jzju/P+1BVnstRpHBW6R8ex3WDZ8nvQsPb8fv85P+0I5HpGQ5/VzVCCBeK0TXep48lJLX5r4Oucd89VdsLT7ne/PraaaXHMp//P/HyfyXFBwJfld7bx4kxf/7wA1Pe3ZPK5tsfYthBDlUXp6OleuXMHPzw8rqwL+iClEIdzr71hBnwlkpJQQ4vFwej2E7lZf/u3VWkbFJT0R1r4CF28vsetaXU1G1e2l1s0BdeW1K//Ari/hmS8Lf41bV9Wts2/uy2fpydQbjFNbCsynqfqKD1OnGh7+UV3Zrt9SqJH3LzNZegP/XrjJmsMRBJ+NJlNvwNXOgnbV3elQ04021dyMoxkAIm6lsudSLLsvx7Dnciw3kzIw12lwtrGggp0lFWwtcLG1QKOBk9cSCLlpwTDd87xvvpxeMd/TnApYaPREenZgwvBp6O4qzG3r2xi8G2B+/Sj/F3SBN8PbcjU2lUAfJ6ZXOUGFQ7fA3gvL+n0AsDLX0bexD30b+3A8PJ6f9oXy78Wb2FqY4XI7jgp26tbd3oona3vkWskuF9/W0Gka/DUFqneBXgtzF3kXQhSLOzWlZKSUEEIIUV5IUkoI8WhKT4BboepoJIt8ijLf7eLWO+83vgWv/ntnBbkHERcCKweqxbzNrKDb52ptJ+1/avy0m6AmpY7+BG3+p668Vhj5JKX+PhfFhDUnSEzPZmATH15rH4CX430SKXfJ1hsIzXLhovdortCftNQk7KI8cEuNwN3eCnd7S9zsLbken87aIxH8euwaMcl3VjKxMNMSk5zJ2iMRrD0SgU6roVEVZ6q42HDgahyhsam5rpmlV4hOyiA6KSPPmDbb9aatVTLtEn6lEjEoVk54DpoPujymtDUaCteP0iB6A8HjJ5OQrsfZ2gzNgnfU402H5zllMNDHiUAfpwJ/T/fU6g0IekGd0pbPCDAhxIOTmlJCCCFE+SNJKSFE6crOhOjT4FAJ7Nzu3z4rDW6cgOgzpiu55aw6V/MZGLD8Pn2kQ8gO9b2ZtdrXgQXqCnQP4sq/8PNgtXaUvZcaR8VGebf1ba0W9g7dDbu/gm4zC3et/ySl0jL1fLzpDD/tCzM2Wbo3lJUHwunfxIeR7QNyjfLJyNZz6loCB6/e4tS1BC5FJxNyM4VM/X8LQd66Zyiudhb0CKpI74aVqOpux6HQOHacv8n2c9FcjE7mwJU4DlyJA0Cn1RBYyZFWVV1pGeBKnYoOJKVnE5ecSWxKBnEpmcSlZJKpN1DLy4H6FR3VAuT6dvDLS3BhC5ruc8DeM+9g6vaGrZMhLgRd6E5c/Nurfy6RJ9U/60ZDC/b9PijbCqVzHSHu8s033/D5558TGRlJYGAgX3/9NU2bNs2z7bp16/jkk0+4dOkSWVlZVKtWjbfeeosXX3zR2GbIkCEsXbrU5LzOnTuzefPmEr2PgsoZKZWSqSdLb8A8r0S1EEIIIR4pkpQSQhRdVhrs+w6OrwQ7D3UqWKUm6stWLeyMokDsZbgcDJf/his7IStFPebse7t9U6jUGDzrQeI1iDik1juKOKgmFwz3+FX8/CZIvnnvBFfoLshKVRNH7d+F39+A7TOgTi9w8CravR9aBJveBkM2eDeEASvu31e7CfBjDziyFNqMzz/Rkpe7klInIuIZt/oYITfV73FYaz/aVXdj3vZLHLgSx7J9oaw+GE7fxpVoW92NY+HxHLoax/GIBDKzc69EYm2uo5qHHVXd7XCxsSAmOYObyRlEJ6qjmRLSsrDQaelYy50+jdQ+7/7HYMsANeH0XrdahMelsuN8NDcS0mlUxZmmfi7Y/2daoYOVORXvNy1OZ6Ym+dLiwdop/3aWdlC/Hxz8AQ4tVqdm7lVXOSFooBTkFuXW6tWrGT9+PPPnz6dZs2bMmTOHzp07c/78edzd3XO1d3FxYdKkSdSsWRMLCwv++OMPhg4diru7O507dza269KlC4sXLzZ+trR8eFZYtLe689ialJ6Ni20+CycIIYQQ4pEhSSkhygt9NsReVAstF3UKkaLA4cWw52t1VbcGL0Dl5rn7MxjUleD+/ggSI9R9MRfUFddyOPuBRx2IPKHWLLqbpSNkJKqJlltX1RXfADRa04LbOWzdwav+7VXcaoBbLXCrriZ4rh9VC3U3GZb/fV24PXWv2pPQYLA6hS7iIGydBH0WFeYbAn0WbJ4IBxeqn+v2UVfUM793ksVgUIhwaIJ9hQY4xx5l2/9N5pPsFzDTaWjg40yDyk40rOJMVbd8iobfTkqtu2LGhF/2kG1Q8HCwZFbfIOPKbm2ru7H3cixfBV9gX0gcy/eHsXy/6XdfwdaCxr7ONKjsTA0Pe6q621HRyfqehcozsvUoCndWnbsHHxcbXmzhe992BXavhFSORkPVpNS5PyB0L1y4Paqj+ajii0OIh8zs2bMZPnw4Q4eqowHnz5/Pxo0bWbRoEe+++26u9u3btzf5/MYbb7B06VJ27dplkpSytLTE07MQCfNSZKbTYmdpRnJGNglpWZKUEkIIIcoBSUoJ8bDKzoCECKgQULD2f02Bfd9Ah0nqiJzCykyFP96EE6vUz3EhcOwnqFBNTU4FDgR7D7i8Hf56Xx3BBOo0vHYTAAXCD6rJnpjzcOuK+gJ1NbfKzaFqRwjoCB51ITMJrh02HRWVHq+29ap/Z8RVpSbqanV5Jdrq9FSTUqfX55+UUpQ7BcirdQatFp6eBQvaw6m10PAl8G9XsO8oNQ5+GaLWhgLoOAVaj883CRidmM7m05FsPhXJ8fB4UjL1tNM+xVKLo7S89RsJGU8QiyMXopJZfSgcAHtLM4IqO+HhYEVKRjZJ6dmkpGfwy60wzIDPDmSSjUK3ep580rMeTjam/yhrEVCBFgEt2BcSy7c7LnMjPo0gHyea+LrQ2NcZP1fbfFe+y4+l2f2TUWXKs6769yTiIKweBCjqn7VrtbKOTIgSkZmZyeHDh5k4caJxn1arpVOnTuzdu/e+5yuKwt9//8358+f57LPPTI7t2LEDd3d3nJ2deeKJJ/joo4+oUCH/6akZGRlkZNypD1dSS3DncLBSk1JS7FwIIYQoHyQpJcTD6q+psP87eG6+Og3pXpIi1ZEiADs+hYAn1OlwBRVzCX5+Ua21pNGpU8sSb8Dpderoq21TIXg6uNeCqFPqOZYOartmr90ZJdRoiLpNi4drhyDqjDqyybc1WNiaXtPKUY0z4An1s6KoSThb1/uOOjKq/ZyajAvdDUlRatLsv2IvqaOMtObq1C4Ar0Bo8opaV2rT/+C13XkWwzZx8zysHKAm68xtodcCqPVMrmaRCelsPnWDTScjORgah6LcOWZhpiXGrTVhab9SOf0cGxoe5Vzd/3Ek7BZHw25xPDyBpIxsdl6MMemzkiYaM0s9GYo5qZauzHq2Hr0aVrxncqm5fwWa+z9GdY4aDVWTUqmx6ucWMkpKlF8xMTHo9Xo8PEz/P8/Dw4Nz587le15CQgIVK1YkIyMDnU7Ht99+y5NPPmk83qVLF3r16oWfnx+XL1/mvffeo2vXruzduxedLu/k9IwZM/jggw+K58YKwMHanOsJ6VLsXAghhCgnJCklxMNIUeDs7+r7vz9URwSZW+Xffu880Gfcnv6mh3XD4bVduRNBeTnzG2wYpY5csnWHvovVJBJA10/h1Lrb090OqAkprZma0Gk7If/iztZOULWT+ioojQacfAreHsC5ilpY/NphdQpf0+G521y4PUrKt5VafyhHh0lweoM67XDfN9D6zfyvc/EvWPOyOuXQsTJpfX/iqs6PiDNRRNxKJeJWGhG3UgmLS+PsDdNRAg0qO9Gtrhftarjh72qLmU4L56fBygH4XFqBzzMTebJ2TUBdCe98VBJHw+JJTM/C3soce0szfOIPwD+gOFdhz2udctVoEqj/G9kyUV2V0aMu+BVw9JsQjxF7e3uOHTtGcnIywcHBjB8/Hn9/f+PUvgEDBhjb1qtXj/r16xMQEMCOHTvo2LFjnn1OnDiR8ePHGz8nJibi41PI/y8vBIfbxc4T0yUpJYQQQpQHkpQS4mF06+qdWk2J19Q6T81H5t02NQ4O3q6L1PN72DZNHc2zZRJ0n5P/NfRZatu989TPlVuqCam7i29b2kOjl9RX9DkI3we+bQo+pbA01OmpJqVOb8g7KXX31L27WTvBUx/C+lfhn5lqbaj/JsUUBfZ+o05XVAzEVmjEx3bv8cd318nUR+QbUsPKTnSr50XXel55F/Su3kUt6h55EvZ9C09MBtR6KXW8Hanj7Wja/nACAFZu/lhJQipvFjZqDakdM6DdO0WvqybEI8DV1RWdTkdUVJTJ/qioqHvWg9JqtVStWhWAoKAgzp49y4wZM3LVm8rh7++Pq6srly5dyjcpZWlpWarF0HNW4JORUkIIIUT5IEkpIR5GobvVrc4C9JmwcxY0HJz3yKcDC9TV7DzqQb2+6ip4Pz6rJrKqd4EaXXKfk3gD1gyFsNu1R1q+Dh2ngu4eCQ/3murrYVO7B2ydfHsKX6RpUi09EUL3qO+rdyYtU4+5TqOOVgKo3x8OL4WwPTC/lTpSzNLe+DJkJKG9XT9qjdKBideGkoVaO8XJxhwfZxsqOVtTydmaik7WVHK2oU5FB7wc7zP9UKNRR5r9/CLsX6AmUe713d+18p64h3bvQLNXwdq5rCMRokRZWFjQqFEjgoODee655wAwGAwEBwczZsyYAvdjMBhM6kH9V0REBLGxsXh5FXGV0hKQk5RKTMsu40iEEEI8zNq3b09QUBBz5swBwNfXl3HjxjFu3Lh8z9FoNKxfv97439aiKq5+HheSlBLiYXR1l7pt9po6Le3WVdj/vVrD6W4ZSbDvO/V9m9sFt/3bQfPR6pS038bAqH1qnaYcV3aqU9FSotW6UD2+gdrPlsptlQinyneKXJ/5DZqNuHMsZDsYskmwqcyra6M5cOUcVuY6GlR2onEVF5r4utDwqZnYLHlSnfaVnmDStRbQKxo+yn6Bxfou+LjY0L2+N90DvanpaV/oguEmaj4DFvaQkQCxl++d8JOkVMFoNJKQEo+N8ePH89JLL9G4cWOaNm3KnDlzSElJMa7GN3jwYCpWrMiMGTMAtfZT48aNCQgIICMjg02bNrFs2TK++079b0hycjIffPABvXv3xtPTk8uXLzNhwgSqVq1qsjpfWXOwkpFSQghRnnXv3p2srCw2b96c69jOnTtp27Ytx48fp379+oXq9+DBg9jaFqC0SSFMmzaNDRs2cOzYMZP9N27cwNm5ZJ9JlyxZwrhx44iPjy/R65SGMk9KffPNN3z++edERkYSGBjI119/TdOmTfNsm5WVxYwZM1i6dCnXrl2jRo0afPbZZ3TpcmckiF6vZ9q0afz0009ERkbi7e3NkCFDmDx58oP9A1KI0pSTlAroAB511Clmu7+Cxi+r085yHFqsrlhXoao6YihHxylqQib6DPw2FgYsV/fv/gqCPwDFAO51oP+yh2sqXlHV6akmpU6vh2YjCLmZzJ+nIqmxbxmdgDWJddgXFwdAaqae3Zdi2X1JLYit02po4v5/2KRHkpxwCztNGnakYa9Jw5Y0LloH4t+kHRsCvQms5Fh8/z+i1YJHbQjfr9bqkqSUEKIQ+vfvz82bN5kyZQqRkZEEBQWxefNmY/HzsLAwtFqtsX1KSgqjRo0iIiICa2tratasyU8//UT//v0B0Ol0nDhxgqVLlxIfH4+3tzdPPfUUH374YalOz7sfR6kpJYQQ5dqwYcPo3bs3ERERVKpUyeTY4sWLady4caETUgBubm7FFeJ93WsqvchNe/8mJWf16tWMHz+eqVOncuTIEQIDA+ncuTPR0dF5tp88eTLff/89X3/9NWfOnOG1116jZ8+eHD161Njms88+47vvvmPevHmcPXuWzz77jJkzZ/L111+X1m0JkbesdHU1uvu5FQoJ4WpBcZ9m6pQ8t5pq8mnft6b95dSDav0maO9aGcncSl0dTmsO5zeq561+QV1FTzFA4EB4ZVv5SEiBMSGnhO1lyrKtPDHrH77YcpbA9AMAXHNrw+Sna/HP2+3ZMq4tHz1Xl+eCvKnoZI3eoLAvEv6O9+SAUotw17ZYNxxAvR5v0mfs5/zfe6/x/jO1CfJxKv7EtkcddRt1+t7tjEkpv+K9vhDikTZmzBhCQ0PJyMhg//79NGvWzHhsx44dLFmyxPj5o48+4uLFi6SlpREXF8eePXuMCSkAa2trtmzZQnR0NJmZmVy9epUFCxbkWuGvrDlYq7+nykgpIYQon5555hnc3NxM/hsG6ojeX375hWHDhhEbG8vAgQOpWLEiNjY21KtXj5UrV96zX19fX+NUPoCLFy/Stm1brKysqF27Nn/99Veuc9555x2qV6+OjY0N/v7+vP/++2Rlqf/9WbJkCR988AHHjx9Ho9Gg0WiMMWs0GjZs2GDs5+TJkzzxxBNYW1tToUIFRowYQXJysvH4kCFDeO655/jiiy/w8vKiQoUKjB492nitoggLC6NHjx7Y2dnh4OBAv379TGpRHj9+nA4dOmBvb4+DgwONGjXi0KFDAISGhtK9e3ecnZ2xtbWlTp06bNq0qcix3E+ZjpSaPXs2w4cPNw41nz9/Phs3bmTRokW8++67udovW7aMSZMm0a1bNwBGjhzJtm3bmDVrFj/99BMAe/bsoUePHjz99NOA+pdv5cqVHDhwoJTuSog8GPTwU28I3QWD1kK1e6xKlzNKyrvhnRpSHd6DnwerRbebvqquendsOSRHgUMlqNcvdz+e9dQC2tumwpb31H06C+g6ExoNKVeFoBMsPEiyq0el5JNoz/0OdGGwbwJukQkYzG2ZMno4mFkY29fwtOeF5lUAuB6fxrHweOwszQj0cTL+Cl8qCpKUSouHtFvqe+cqJR6SEEI8zO7UlJKklBBCFJqiQFZq2Vzb3KZA//4wMzNj8ODBLFmyhEmTJhl/FP7ll1/Q6/UMHDiQ5ORkGjVqxDvvvIODgwMbN27kxRdfJCAgIN9ZV3czGAz06tULDw8P9u/fT0JCQp61puzt7VmyZAne3t6cPHmS4cOHY29vz4QJE+jfvz+nTp1i8+bNbNu2DQBHR8dcfaSkpNC5c2datGjBwYMHiY6O5pVXXmHMmDEmibft27fj5eXF9u3buXTpEv379ycoKIjhw/NYyKkA95eTkPrnn3/Izs5m9OjR9O/fnx07dgAwaNAgGjRowHfffYdOp+PYsWOYm6v/jR09ejSZmZn8+++/2NracubMGezs7O5xxQdTZkmpzMxMDh8+zMSJE437tFotnTp1Yu/evXmek5GRgZWVlck+a2trdu3aZfzcsmVLFixYwIULF6hevTrHjx9n165dzJ49O99YMjIyTAp9JiYm5ttWPGYURV2h7tBidYTRfzn7Qp//A7ca9+5n/3w1IQVw9Md7J6Vyipz7tr6zr2Z38KwPkSdg95fQcRrsnqMeazXWJOFiouXrcHGr2qdjZei3FCo2vHesRZCamY21ua7AI4mS0rOwMtdhrrv/YE1FUYhNyQTAxkKHlZkOrVa9Tma2gWX7Qvn674v0zAhiqvlJBtoeps9LH1H34nyIBG1Ah/y/H8DbyRrvvFbIKw0eddXtvZJSOaOkbN3zLnQvhBCPkZyaUpKUEkKIIshKhU+8y+ba710v8LPsyy+/zOeff84///xjXCF28eLF9O7dG0dHRxwdHfnf//5nbP/666+zZcsWfv755wIlpbZt28a5c+fYsmUL3t7q9/HJJ5/QtWtXk3aTJ082vvf19eV///sfq1atYsKECVhbW2NnZ4eZmdk9p+utWLGC9PR0fvzxR2NNq3nz5tG9e3c+++wz44hkZ2dn5s2bh06no2bNmjz99NMEBwcXKSkVHBzMyZMnuXLlCj4+6uriP/74I3Xq1OHgwYM0adKEsLAw3n77bWrWVEuIVKtWzXh+WFgYvXv3pl69eoC6Gm9JKrOkVExMDHq9PtewcA8PD86dO5fnOZ07d2b27Nm0bduWgIAAgoODWbduHXq93tjm3XffJTExkZo1a6LT6dDr9Xz88ccMGjQo31hmzJjBBx98UDw3Jh4eKbGQkQguDzDl6cjSO8mfvESdhFWDYPjfYOWQd5uYixA8/c7nC1vUVeHya391p7r1bXVnn1YLT7wPK/rCgYVg4wrxYWDrpq7Klx+tDgauhHMb1ZX4bFzyb1tEaw5HMGHNcWp7OzC8jT9P1/O6s7rdXRRFYf+VOBb+G0LwuWjMtBoqu9jg72aLv5sdfq62VHGxITYlk5CbKYTEJHMlJoWQmykkZ5iusmRlrsXGwoxsvYHEdPXYObcnIGkZNTJPg10yXNyiNq7+8BTozcW9lrpNjFBHQ+VVpFvqSQkhhJGjjRQ6F0KI8q5mzZq0bNmSRYsW0b59ey5dusTOnTuZPl39N5Ver+eTTz7h559/5tq1a2RmZpKRkYGNjU2B+j979iw+Pj7GhBRAixYtcrVbvXo1c+fO5fLlyyQnJ5OdnY2DQz7/hrvHtQIDA02KrLdq1QqDwcD58+eN+ZA6deqg090px+Ll5cXJkycLda27r+nj42NMSAHUrl0bJycnzp49S5MmTRg/fjyvvPIKy5Yto1OnTvTt25eAALW0y9ixYxk5ciRbt26lU6dO9O7du0h1vAqqzAudF8ZXX33F8OHDqVmzJhqNhoCAAIYOHcqiRYuMbX7++WeWL1/OihUrqFOnDseOHWPcuHF4e3vz0ksv5dnvxIkTGT/+zqpmiYmJJn+A4hGUnQE/dISkG+rqc0VJTN04AZsmqO/bvwf1+5oez0yFFf0g9iJsGAn9f8o9JNWgV49lp4N/B0iIUNuf2whBA3NfMz5MfWl04NPc9Fi1J9UaU+H71Sl5AM1Hgfl9RvlYOULQ8wW/70K4FJ3M5A0nMShw6loib6w6xszN53m5tR/9m/hgZ6kmjjafjmThvyEcj7izul22QSEkJoWQmBQ4m3cduRwajTpoLUd6loH0LHX0lJu9JW89WZ0+jSrB0gUQthcO/gDXjqiNqz1V7PddbKwc1RFsCWFqvbG7E5E5JCklhBBGxpFS6dn3aSmEECIXcxt1xFJZXbsQhg0bxuuvv84333zD4sWLCQgIoF27dgB8/vnnfPXVV8yZM4d69epha2vLuHHjyMzMLLZw9+7dy6BBg/jggw/o3Lkzjo6OrFq1ilmzZhXbNe6WM3Uuh0ajwWDIY6ZOMZk2bRrPP/88Gzdu5M8//2Tq1KmsWrWKnj178sorr9C5c2c2btzI1q1bmTFjBrNmzeL1118vkVjKLCnl6uqKTqczKbYFEBUVle/wNzc3NzZs2EB6ejqxsbF4e3vz7rvvmgwne/vtt3n33XcZMGAAAPXq1SM0NJQZM2bkm5SytLR8qFaWEcXgyI9w64r6/tQaaPt24c5PT4RfXgJ9BlTrrJ6vzWOqWb9lsLgLnPsDdn0JbcabHt87T10VztIBesyDoz/BjhlqTHklpa7enrrn3QAs/zNvV6NRR0stfUb9bOkITYYV7r6KUUa2njdWHSU9y0CrqhVo5leBpXuuci0+jQ//OMOcbRd4pr43uy7dJDwuTQ3ZTEufRpV4ubUfNhY6dUTUzWQu30zhSkwK4XGpONta4O96Z/RUgJstlSvYYK7Vkp6tJzVTT1qmnrQsPRlZBqp52GFlfvtXhTo91aTUnq8BBbwCwf4hX/3Co87tpNRpSUoJIcR95NSUSkjLQlEUWVlZCCEKQ6N5ZMpB9OvXjzfeeIMVK1bw448/MnLkSOP/5+/evZsePXrwwgsvAGoNpQsXLlC7du0C9V2rVi3Cw8O5ceMGXl5eAOzbt8+kzZ49e6hSpQqTJk0y7gsNDTVpY2FhYTJrK79rLVmyhJSUFONoqd27d6PVaqlR4z4lYIoo5/7Cw8ONg23OnDlDfHy8yXdUvXp1qlevzptvvsnAgQNZvHgxPXv2BMDHx4fXXnuN1157jYkTJ7Jw4cLyl5SysLCgUaNGBAcH89xzzwHqX6bg4GDGjBlzz3OtrKyoWLEiWVlZrF27ln797hR5Tk1NNVkCGdRljksyyygeMlnpsPOuGmKn1hUuKaUo8NvrEBeiFhHvOT/vhBRApUbQ7XP4/Q34+0M1CVK1o3os+hz8/bH6vvMn4FgJ6vZRk1KXt0NKDNi6mvaXU+T87npSd/NrA/7tIWQHNBuhjrQpI19sOc/p64m42FrwZb8g3B2sGNHWn3VHrvHDzhBCYlJYeSAMAGcbcwa38OXFFlVwtbuTAPZytKZVVdf8LpGLjYUZNhb3+L+tWs/Cn++A4fa0jmoP8dS9HB514MKfEHUq7+OSlBJCCKOc1ff0BoXUTD22lo/UoH8hhBAFZGdnR//+/Zk4cSKJiYkMGTLEeKxatWqsWbOGPXv24OzszOzZs4mKiipwUqpTp05Ur16dl156ic8//5zExEST5FPONcLCwli1ahVNmjRh48aNrF+/3qSNr68vV65c4dixY1SqVAl7e/tcg10GDRrE1KlTeemll5g2bRo3b97k9ddf58UXX3zgFW71ej3Hjh0z2WdpaUmnTp2oV68egwYNYs6cOWRnZzNq1CjatWtH48aNSUtL4+2336ZPnz74+fkRERHBwYMH6d27NwDjxo2ja9euVK9enVu3brF9+3Zq1ar1QLHey/2rDJeg8ePHs3DhQpYuXcrZs2cZOXIkKSkpxtX4Bg8ebFIIff/+/axbt46QkBB27txJly5dMBgMTJgwwdime/fufPzxx2zcuJGrV6+yfv16Zs+ebcz4icfAkR8h6TrYe6mrzUWfgeizBT//4A9wZgNozaDvkvvXYWo0RK3rpBhg7TC4FQr6bHXanj4Dqj4JDdQsPq5VwSsIFD2cXp+7L2M9qTb5X6/PYnjuO2j3TsHvqZj9e+EmC3eqI9Fm9q6Pu4O6AIGVuY7nm1Vm2/h2LBzcmP6Nffjwubrsebcjbz5Z3SQhVSIcvKBKyzufH+Z6UjnutwKfJKWEEMLI2lyHuU79pVzqSgkhRPk2bNgwbt26RefOnU3qP02ePJmGDRvSuXNn2rdvj6enp3GgS0FotVrWr19PWloaTZs25ZVXXuHjjz82afPss8/y5ptvMmbMGIKCgtizZw/vv/++SZvevXvTpUsXOnTogJubGytXrsx1LRsbG7Zs2UJcXBxNmjShT58+dOzYkXnz5hXuy8hDcnIyDRo0MHl1794djUbDr7/+irOzM23btqVTp074+/uzevVqQB20Exsby+DBg6levTr9+vWja9euxjrber2e0aNHU6tWLbp06UL16tX59ttvHzje/GgU5e5KLaVv3rx5fP7550RGRhIUFMTcuXNp1qwZAO3bt8fX19e4VOI///zDyJEjCQkJwc7Ojm7duvHpp5+a/AVNSkri/fffZ/369URHR+Pt7c3AgQOZMmUKFhb5r8B1t8TERBwdHUlISCh0ITNRxrLSYW6QWkvq6VlwcZs6CqXtBHhi0n1P59oRWNQZ9Jnq6KYWowt+3cVd4foRdZW86l3g35nqFLvR+8DhrlUu9nwNWydD5Rbw8uY7++PDYU5dtZ7Uu6FgaV+oWy+sfy7cZP6Oyygo2FmaY29lhr2VGXaWZjjZmNO5jidVKuQe3huTnEGXOTuJSc5gcIsqTO9Rt0TjLLQDC2HT/9Ri8P+7mP8ot4fFzQvwTRN1nv3Ea6bx6rPhYw8wZMP4s6Z/j4QQpUaeCwquNL6rRh/+RWxKJpvHtaGmp/x5CCFEftLT07ly5Qp+fn65VrEXojjc6+9YQZ8JynzM85gxY/Kdrrdjxw6Tz+3atePMmTP37M/e3p45c+YwZ86cYopQPFIOL1ETUg6VoMGLalLowp9wai10eC93IfK7pcXDL0PUhFTNZ9Qi4gVlbgX9l8H37SDyhPoC6PpZ7kRCnV6w9X219lF8ODjdLqofmlNPKqhICamEtCwOXImjdVVXrC1092y76kAYkzacQm/IPyf96Z/n6FLXk+Ft/GlQWV0VTlEUJqw5QUxyBtU97HivW8kN4yyywIFw7TBU7fTwJ6QAXPzBzEpdovfWFagQcOdYYoSakNJZgt1DXhtLCCFKiaO1ObEpmSSkykgpIYQQ4lFX5kkpIYpNVhrsul1Lqu1bYGYJNbqCmTXEXVYTRV6B+Z//xziIDwWnKtDjm3snsPLiWAn6LIJlz6lT+ap3hcABebSrCFVaQeguNVnWepy63zh1L596Uvdw9kYiI5YdIjwujSoVbPi0V31aBFTI1U5RFL786wJz/74EQM8GFXmipjtJ6dkkZ2SRnJ5NUkY2l6KT2Xkxhk0nI9l0MpKmvi4Mb+tPxK1U/j4XjYWZlrkDG9wpMP4wsbRT64A9KnRm4FYTbhxTp/DdnZQyTt2r8mgk2IQQohQ4WMsKfEIIIUR5IUkpUX4cWgTJUeBYGYJu13CytIPqT8GZX9UEUH5JqbD9ao0njVatI2XtVLQY/NtBj2/h/EZ4enb+ia16vW8npdbclZS6PVKqSuGSUr8fv86ENSdIy1JXfgiNTWXgwn0MbFqZid1qGpfPztIbeHftSdYeiQBg7BNVefPJ6vmuXHQ+MomFO0P49dg1DlyN48DVOOOxSd1qyZSJ4uRR905Sqvazd/ZLPSkhhMjF4a4V+IQQQgjxaJOf3kX5kJkKu+ao79u+BWZ31Q+rq64iwKn16sp6/6UosG2a+j5oEFRs+GCxBA2E/j+BnXv+bWo/pxZSjzwJN89DwjV16pZGC5WbF+gy2XoDMzad5fWVR0nL0tOmmis7J3RgULPKAKw8EMaTs//hrzNRJKVn8fKSg6w9EoFOq+HTXvUY/1SNey6lXcPTni/6BrLrnSd4rV0A9lZqDrtjTXcGt6hS4K9DFICx2Pl/VuCTpJQQQuTimDNSSpJSQgghxCNPRkqJ8uHQ/0FKNDhVVhNLd6v2FFjYQUIYRBwCnyamxy/+BWF71Lo97SdSKmxcIKAjXNwCJ9eAazV1v1cgWN1/BNKtlExeX3mUXZdiAHi1nT8TOtdEp9Xwcc96dA/05t21J7gam8rwHw9RwdaC2JRMrM11fDuoIR1q3iNh9h8eDla827UmY56oysErcbQIqHDPZJYogvxW4JOklBBC5OJw+0cSGSklhBBCPPokKSUefZkpd42Seht05qbHza2hRjc4+bM6he/upJTBAMHq0pc0G6HWeyot9fqoSalTa9QaU5CrnlS23kBsSiY3kzKITkonOjGD6KQMfjkcTnhcGtbmOmb2qU/3QNNi6s39K7B5XFu+3HaBH3ZeITYlE1c7CxYNaUL9Sk5FCtfO0qxQySxRCDlJqVtXICNZnXYKkpQSQog8OMr0PSGEKBQlr9kiQhQDg8HwwH1IUko8+g7+AKkx6j/cAwfm3aZubzUpdXo9dP4YtLcLdJ/8RZ0yZekIrceXWsiAmigzs4a4EEiKAsBQuTVnriWw/Vw0289HczwiId8V8iq72PD9i42o5ZX3yCorcx0Tu9aie31v/jx1gwFNKuPjYlNityMegK2rurpeciREn72TOI27om6d/couNiGEeMjcKXQuSSkhhLgXc3NzNBoNN2/exM3NTWY7iGKjKAqZmZncvHkTrVaLhYXF/U/KhySlxKNNUWDvt+r7vEZJ5Qh4Aqwc1X/0h+1VRyRlZ8L2j9Tjrd9Qp9SVJks7dXXA0+sgKwUDWp5Yk8HV5F0mzbQacLWzxM3eEnd7S9ztrahcwYZBzSrjZHP///HXrehI3YqOJXUXorh41FH/fkadUpNSabcgPV495iw1vIQQIofUlBJCiILR6XRUqlSJiIgIrl69WtbhiHLIxsaGypUro32AlcIlKSUebYnX1H/Ia3RQt0/+7cwsoFZ3OPqTOoXPtzUcXgzxYWDnAc1eK72Yb4tJzmC3vgU9WAfAKUMVriabYWOho3VVVzrUdKd1VVe8nazRaeVXjXLPow5cDr5TV+pWqLq1dQcL27KLSwghHjI5q8ompmWXcSRCCPHws7Ozo1q1amRlSSJfFC+dToeZmdkDj8CTpJR4tN04oW7daoK51b3b1umlJqXO/Aodp8I/M9X97d4p1X/0X76ZzA87r7D2SARku9Pe0gZHTSqpXs1Z/mQzGvs6Y2mmK7V4xEPCo666NSalrqpbqSclhBAmpKaUEEIUjk6nQ6eTf1+Ih5MkpcSjLfJ2Usqr/v3b+rUDmwqQGgurX1DrULn4Q8PBJRsj6qioA1fiWH/0GtvORpFTazCwkitRrkNxuPgDzXu8Bt6uJR6LeEjdvQKfokhSSggh8uFgrT6+Sk0pIYQQ4tEnSSnxaMsZKeVZgKSUzgxqPweH/g+u7lT3PTE5/zpUD+BmUgb7r8SyLySW/SFxXIxONjneqZY7w9v409TPBQ2tgI9BCg8+3lyrg9YMMhIgIUKSUkIIkQ8ZKSWEEEKUH5KUEo+2woyUAqjbS01KAXgFQu2exRqO3qAwaf1JVh0Mz3Wspqc9LQIqMKhZFaq62xXrdUU5YGYBrjUg+rQ6WkqSUkIIkaecmlKpmXqy9AbMdUUvriqEEEKIsiVJKfHoSo2DhNvJH896BTuncgtwrAwJYdBpGjzAKgH/ZTAoTFhzgrVHItBooJanA838XWjmV4Gmfi642BZ9mUzxmPCoczspdQpuXVH3ufiVbUxCCPGQcbC+M8I5MS2LCnaWZRiNEEIIIR6EJKXEoytnlJSzL1g5FuwcrQ4Gb4CkG+oKfMXEYFCYuO4ka49EoNNqmDewAV3reRVb/+Ix4VEHTgI3jkP87YSrjJQSQggTOq0Ge0szkjKySUzPlqSUEEII8QiT8c7i0VWYelJ3qxBQqIRUWGwqG0/cIDUz76WnFUXh/V9PsfpQOFoNzOkfJAkpUTQ5K/Bd3g6KHnSWYOdZtjEJIcRDyEHqSgkhhBDlgoyUEo+uyJPqtqD1pIogKjGdXt/tJiY5EwcrM/o38WFwC198XGwANSE17bfTLN8fhkYDs/oF0j3Qu8TiEeVczgp8mUnq1rlKsU4xFUKI8sLB2pxr8WkkSlJKCCGEeKRJUkqUnZsX4OZZsLQHS4fb29svC7v7r0aXM33PM7BEwsvSGxi9/AgxyZnotBoS07NZuPMKP+y6QseaHgxp6cv289Es3RuKRgMze9enZ4NKJRKLeEzYe4K1C6TFqZ9l6p4QQuTJwUp9hJWRUkIIIcSjTZJSomxkpsAPnSAjIe/jnvXhlWB1RbI8z0+FmAu32xawyHkhffrnOQ6F3sLe0oxfx7TiSkwKS/ZcZefFGLadjWLb2Shj2xk969G3sU+JxCEeIxqNOlrq6k71sySlhBAiT44yfU8IIYQoFyQpJcpG+AE1IWVuAy7+kJEIGUmQnqjW0ok8AWF7wL993udHnwHFALZu6uiSYrbxxA3+b5e6+tmsfoH4u9nh72ZHx1oeXIpO5se9V1l7OIKUTD0fPleXAU0rF3sM4jHlUVeSUkIIcR85NaUS0yUpJYQQQjzKJCklykbobnVbqzv0WnBnv6LAr2Pg2E9wfnP+Sakbx9WtZ/37T/MrpMs3k5mwRu3/1Xb+PFXHNOlV1d2O6T3q8nbnGsSnZhnrSwlRLHLqSgE4+5VdHEII8RCTkVJCCCFE+SAVdEXZuHo7KVWllel+jQZqdFHfX/hTTVLlJaeeVDEXOU/JyOa1ZYdJydTTzM+Ft5+qkW9beytzSUiJ4meSlPItszCEEA+/b775Bl9fX6ysrGjWrBkHDhzIt+26deto3LgxTk5O2NraEhQUxLJly0zaKIrClClT8PLywtramk6dOnHx4sWSvo0icbC6PVIqLe+VcYUQQgjxaJCklCh9WWlw7ZD63rd17uP+7UFnAbeuQkw+D8M3coqcF19SSlEU3lt/kovRybjbW/L18w0w08n/REQpc68FFvZgbitJKSFEvlavXs348eOZOnUqR44cITAwkM6dOxMdHZ1nexcXFyZNmsTevXs5ceIEQ4cOZejQoWzZssXYZubMmcydO5f58+ezf/9+bG1t6dy5M+np6aV1WwXmaK0O9pfV94QQQohHm/yLW5S+a4dBnwl2nmo9qf+ytL+TrLqwOfdxfbZaUwrAq+gr76VkZHMhKom/z0Xx496rvL3mBL8eu45Oq2He8w1xt7cqct9CFJm5Nby8GV7+EyxkJJ4QIm+zZ89m+PDhDB06lNq1azN//nxsbGxYtGhRnu3bt29Pz549qVWrFgEBAbzxxhvUr1+fXbt2AeoPM3PmzGHy5Mn06NGD+vXr8+OPP3L9+nU2bNhQindWMFJTSgghhCgfpKaUKH3GqXst868HVb0LXP4bLmyBVmNNj8VehOx0dTRJIWvuJGdk8/HGM2w5HUVcSmaebSZ2rUlTP5dC9StEsfKsW9YRCCEeYpmZmRw+fJiJEyca92m1Wjp16sTevXvve76iKPz999+cP3+ezz77DIArV64QGRlJp06djO0cHR1p1qwZe/fuZcCAAcV/Iw9AakoJIYQQ5YMkpUTpC1V/lcW3Vf5tqneGPydA2F5IuwXWzneOGafu1QVtwQf7nbmeyJgVRwiJSTHuc7Ayo5KzDZWcranobE2jKs48Xc+rMHcjhBBClKqYmBj0ej0eHh4m+z08PDh37ly+5yUkJFCxYkUyMjLQ6XR8++23PPnkkwBERkYa+/hvnznH8pKRkUFGRobxc2JiYqHvpyiMI6UkKSWEEEI80iQpJUpXdiaEH1TfV8mjnlQOZ19wqwU3z8KlYKjX586xyMLVk1IUheX7w5j+xxkysw14Oljxae96NKzibCyUKoQQQpR39vb2HDt2jOTkZIKDgxk/fjz+/v60b9++yH3OmDGDDz74oPiCLCAZKSWEEEKUD1JTSpSu60cgOw1sKoBb/ivbAepoKchdV+rGcXXrWe++l0tMz2LMyqNM3nCKzGwDT9R0Z9MbbWhfw10SUkIIIR5Jrq6u6HQ6oqKiTPZHRUXh6emZ73larZaqVasSFBTEW2+9RZ8+fZgxYwaA8bzC9jlx4kQSEhKMr/Dw8KLeVqE4GmtKZaPkt1KvEEIIIR56kpQShRd+MP9V8e4ntAD1pHJU76JuL/6lFjcHUJQ7I6W8co+U0hsUohPTORYez2/Hr/PM3F1sPHEDM62GSd1q8cPgxrjYWhQtdiGEEOIhYGFhQaNGjQgODjbuMxgMBAcH06JFiwL3YzAYjFPv/Pz88PT0NOkzMTGR/fv337NPS0tLHBwcTF6lIeeHJb1BISVTXyrXFEIIIUTxk+l7ouAUBf79ArZ/pI50evMMmBdyhTpjkfN7TN3LUamJWksq7RZEHFATWfFhkJ4AWnNwq0VkQjqL91zh8NVb3EhIJyoxnWyD6S+mFZ2smfd8AxpUds7nQkIIIcSjZfz48bz00ks0btyYpk2bMmfOHFJSUhg6dCgAgwcPpmLFisaRUDNmzKBx48YEBASQkZHBpk2bWLZsGd999x0AGo2GcePG8dFHH1GtWjX8/Px4//338fb25rnnniur28yXlbkWC52WTL2BxLQs7CzlkVYIIYR4FMl/wUXB6LNh43g4slT9nBqrTqur81zh+gjfr76/V5HzHDozqPoknPxZvVaVlsZRUhku1Zmy4RzrjkaQpTdNQmk14G5vhZeTFfUqOvLWkzVwtJGpekIIIcqP/v37c/PmTaZMmUJkZCRBQUFs3rzZWKg8LCwM7V2LgaSkpDBq1CgiIiKwtramZs2a/PTTT/Tv39/YZsKECaSkpDBixAji4+Np3bo1mzdvxsqqkD9AlQKNRoODtRkxyZkkpGXh7WRd1iEJIYQQogg0ikzEzyUxMRFHR0cSEhJKbRj6Qy0jGdYMhYtbQaMFryC1NlSNbjBwZcH7iTgMPzwBVo4w4WrBVs47tRbWvAxuNWH0fiJ/nYLn0a/4Wd+OCVmvAtDUz4WBTX2oUsEWL0cr3OwsMdPJzFQhhBDFQ54LCq40v6snZu0g5GYKq0Y0p7l/hRK9lhBCCCEKp6DPBDJSStxbcjQs7ws3joGZNfT5P3Dxh2+bq0mqlFiwLeCDYOgudVu5ZcESUgABHUGjg5vnmLLkD9pc3omnDk4bfOlUy4OR7f1pVMWlSLcmhBBCiEdXTl2pRFmBTwghhHhkSVJK5C/mIvzUG+JD1RpSA1eDTxP1mGd9dSrd6XXQdHjB+gvdo24LMnUvh7WTOm3v6k40F7dS1+wqAMP69qByUOOC9yOEEEKIciVnBb4ESUoJIYQQjyxJSgkI+QciDkLidUi8dvt1Xa0bBeDsBy+shQoBd84JHKAmpU6sLlhSyqCH0L3q+yqFSEoBp+1aUIed9NH9g5cmDtBQuVbTQvUhhBBCiPLF4XZSKjE9u4wjEUIIIURRSVLqcRd3BX58Nv/jVVpB36Vg52a6v24f2DpZTWbFXjZNWOUl6hRkJICFvTrKqoDOXE/kf8c9+VMH9bRX1Z0u/mBpX+A+hBBCCFH+OFqrj7EyUkoIIYR4dElS6nEXd1nd2rpBo6Hg4A0OFW9vvcHaGTSa3OfZe0DAE3BpmzpaqsN7977O1d3qtnIzdVW9AriVksmrPx0iPMuDSEtvPLOvqwe8Cp7UEkIIIUT5JDWlhBBCiEefLFH2uEuOVree9eGJSdB4KFR/Cjzrgo1L3gmpHPUHqNsTq+F+iziG3k5KFXDqnt6gMHbVUcLj0qjsYotT0F2juTzrFagPIYQQQpRfOTWlJCklhBBCPLokKfW4S4pUt3YehT+3Zjcwt4VbVyF8f/7tDIa7ipy3LlDXn285z86LMVib6/j+xUZY1e5256BnYOFjFUIIIUS5cqemlCSlhBBCiEeVJKUedzkjpeyLkJSysIXat0cwHV+Vf7ub5yAtDsxtwCvovt3+fvw68/9RpxXO7FOfWl4OULkF2HuBhR1UbFj4WIUQQghRrsjqe0IIIcSjT5JSj7vkBxgpBVC/v7o9vR6yM/JukzN1r1ITMLPIt6tr8WmMX32MsauOAvBqW3+6B3qrB80sYNhfMOIfdVqhEEIIIR5rd6bvyep7QgghxKNKCp0/7nJGStm5F+18v7bqCKakG3BxK9TqnrvN1V3qNp+pe4npWXy7/TKLdl8hM9sAQL/GlXi7cw3Thk4+RYtRCCGEEOVOTqFzGSklhBBCPLokKfW4M9aU8iza+Vod1OsLe+aqU/j+m5S6eQGu7lTf/6fIeWa2geX7Q5kbfJFbqeoDZXN/F97rVov6lZyKFo8QQgghHguOUlNKCCGEeOSV+fS9b775Bl9fX6ysrGjWrBkHDhzIt21WVhbTp08nICAAKysrAgMD2bx5c652165d44UXXqBChQpYW1tTr149Dh06VJK38egyjpQq4vQ9gMDbq/Bd2AKpcer7m+dhzTD4pimkxoKtG1RsZDwlKjGd7l/v4oPfz3ArNYuq7nb830uNWTm8uSSkhBBCCHFfDtbqb6upmXqy9IYyjkYIIYQQRVGmI6VWr17N+PHjmT9/Ps2aNWPOnDl07tyZ8+fP4+6eezrZ5MmT+emnn1i4cCE1a9Zky5Yt9OzZkz179tCgQQMAbt26RatWrejQoQN//vknbm5uXLx4EWdn59K+vYdfZgpkJqnvi1LoPIdHHfCoB1EnYdeXkBCh1phCUY/XeBo6TgFzKwAibqUy6If9hMamUsHWgvFPVad/Yx/MdGWeIxVCCCHEI8L+9vQ9UKfwudpZlmE0QgghhCgKjaIoSlldvFmzZjRp0oR58+YBYDAY8PHx4fXXX+fdd9/N1d7b25tJkyYxevRo477evXtjbW3NTz/9BMC7777L7t272blzZ5HjSkxMxNHRkYSEBBwcHIrcz0MvLgTmNlBXxXvvOmg0Re9rz9ewdbLpvprPQLt3wKu+cdfVmBQG/bCfa/FpVHaxYfkrzfBxsSn6dYUQQogS9tg8FxSD0v6u6k3dQlJGNn+/1Q5/N7sSv54QQgghCqagzwRlNjQlMzOTw4cP06lTpzvBaLV06tSJvXv35nlORkYGVlZWJvusra3ZtWuX8fNvv/1G48aN6du3L+7u7jRo0ICFCxfeM5aMjAwSExNNXo+Fu6fuPUhCCtS6Uha3HwZrPQuv7YYBy00SUpeik+n3/V6uxafh72rLz6+2kISUEEIIIYrMwVqKnQshhBCPsjJLSsXExKDX6/HwMJ025uHhQWRkZJ7ndO7cmdmzZ3Px4kUMBgN//fUX69at48aNG8Y2ISEhfPfdd1SrVo0tW7YwcuRIxo4dy9KlS/ONZcaMGTg6OhpfPj6PySpvxiLnDzB1L4e9J7y2E8Yehf7LwLOuyeGzNxLp//1eopMyqO5hx6pXm+PpaJVPZ0IIIYQQ9+dgLHaeXcaRCCGEEKIoHqkiPl999RXVqlWjZs2aWFhYMGbMGIYOHYpWe+c2DAYDDRs25JNPPqFBgwaMGDGC4cOHM3/+/Hz7nThxIgkJCcZXeHh4adxO2TOOlMpdv6tIXPzV13+cjEhg4MJ9xKZkUsfbgVUjWuBuLwkpIYQQQjwYx9vFzmWklBBCCPFoKrOklKurKzqdjqioKJP9UVFReHp65nmOm5sbGzZsICUlhdDQUM6dO4ednR3+/ncSIV5eXtSuXdvkvFq1ahEWFpZvLJaWljg4OJi8HgvJt0dK2ef9fT+obL2BH3aG0O/7vcSnZhHk48SK4c1xsbUokesJIYQQ4vHicLvYeaIkpYQQQohHUpklpSwsLGjUqBHBwcHGfQaDgeDgYFq0aHHPc62srKhYsSLZ2dmsXbuWHj16GI+1atWK8+fPm7S/cOECVapUKd4bKA+SbycEi2uk1F1OXUvguW9389HGs6Rl6Wld1ZWfXmmGo7X5/U8WQgghhCgAR6kpJYQQQjzSzMry4uPHj+ell16icePGNG3alDlz5pCSksLQoUMBGDx4MBUrVmTGjBkA7N+/n2vXrhEUFMS1a9eYNm0aBoOBCRMmGPt88803admyJZ988gn9+vXjwIEDLFiwgAULFpTJPT7UknKSUsU3Uio1M5sv/7rA/+26gkEBByszJj1di76NfNBqH7CYuhBCCCHEXe7UlJKklBBCCPEoKtOkVP/+/bl58yZTpkwhMjKSoKAgNm/ebCx+HhYWZlIvKj09ncmTJxMSEoKdnR3dunVj2bJlODk5Gds0adKE9evXM3HiRKZPn46fnx9z5sxh0KBBpX17Dz/jSKliKHQO7Lx4k4nrThJxKw2AZ+p7MaV7bakfJYQQQogSkTNSSqbvCSGEEI+mMk1KAYwZM4YxY8bkeWzHjh0mn9u1a8eZM2fu2+czzzzDM888UxzhlW85SSn7B09KHboax5DFB9EbFCo6WfPhc3V4ombxJLuEEEIIIfJyJyklq+8JIYQQj6IyT0qJEnDmN3CvDa5V829j0EPKTfX9A46USkjN4o1Vx9AbFLrU8WRWv0BsLeWvlhBCCCFKloOsvieEEEI80sqs0LkoIRGH4OcXYd0r926XGguKATRasHUr8uUURWHi+hNci0/Dt4INX0hCSgghhBClRAqdCyGEEI82SUqVN5En1W30WTAY8m+XFKlubVxBqyvy5VYfDGfTyUjMtBq+GtAAO0lICSGEEKKUOFhJoXMhhBDiUSZJqfIm9pK6zU6HpBv5t0uOVrcPMHXvUnQS034/DcDbnWsQ6ONU5L6EEEIIIQpLRkoJIYQQjzZJSpU3sZfvvI8Lyb9d8u2RUkUscp6epWfMiqOkZxloU82V4W38i9SPEEIIIURROdy1+p6iKGUcjRBCCCEKS5JS5U3OSCm4T1Lq9sp7RRwp9emf5zgXmUQFWwtm9QtEq9UUqR8hhBBCiKLKGSllUCA5Q1bgE0IIIR41kpQqT/TZcOvKnc93v/+vpKInpbadiWLJnqsAfNEvEHd7q0L3IYQQQgjxoCzNtFjo1MfZxHRJSgkhhBCPGklKlSfxoWC464GsmEdKGQwKvxwKZ/zPxwAY1tqPDjXcixCoEEIIIcSD02g0ONuqo6XC41LLOBohhBBCFJYkpcqTu+tJQcGSUgWsKXX2RiL9vt/L22tOkJieTcPKTkzoUqOIgQohhBDiQX3zzTf4+vpiZWVFs2bNOHDgQL5tFy5cSJs2bXB2dsbZ2ZlOnTrlaj9kyBA0Go3Jq0uXLiV9Gw+shX8FQB3JLYQQQohHiySlypOcelLutdVt3FXIr+hnAUdKJaVnMf33Mzzz9S4Ohd7CxkLHe91qsvrVFlia6YonbiGEEEIUyurVqxk/fjxTp07lyJEjBAYG0rlzZ6Kjo/Nsv2PHDgYOHMj27dvZu3cvPj4+PPXUU1y7ds2kXZcuXbhx44bxtXLlytK4nQfSpa4XAH+eipRi50IIIcQjRpJS5UnsRXUb8ASggcwkSInJu20BakptPnWDjrP+YdHuK+gNCt3qeRL8VjtGtA3AXCd/dYQQQoiyMnv2bIYPH87QoUOpXbs28+fPx8bGhkWLFuXZfvny5YwaNYqgoCBq1qzJDz/8gMFgIDg42KSdpaUlnp6expezs3Np3M4DaVfdDWtzHdfi0zh1LbGswxFCCCFEIUhmoTzJGSnlUQccfdT3eU3hy0iGrBT1fT5JqRMR8bz20xGikzLwc7Vl6ctN+XZQI7wcrUsgcCGEEEIUVGZmJocPH6ZTp07GfVqtlk6dOrF3794C9ZGamkpWVhYuLi4m+3fs2IG7uzs1atRg5MiRxMbG3rOfjIwMEhMTTV6lzdpCR/sabgBsPn2j1K8vhBBCiKKTpFR5klNTqkJVcPFV3+eVlMqZumduC5Z2eXb1zXY1wfVUbQ82j2tDu+puxRysEEIIIYoiJiYGvV6Ph4fpD0seHh5ERkYWqI933nkHb29vk8RWly5d+PHHHwkODuazzz7jn3/+oWvXruj1+nz7mTFjBo6OjsaXj49P0W7qAXWp6wnIFD4hhBDiUWNW1gGIYpKZAom360JUqAou/nDlX7h1JXfb+xQ5vxiVxJbTapu3O9eQ2lFCCCFEOfLpp5+yatUqduzYgZWVlXH/gAEDjO/r1atH/fr1CQgIYMeOHXTs2DHPviZOnMj48eONnxMTE8skMfVETXcsdFpCbqZwKTqZah72pR6DEEIIIQpPRkqVFzkjoqydwcZFTUrdvf9u9yly/t0/6oirznU85KFOCCGEeMi4urqi0+mIijJdbS4qKgpPT897nvvFF1/w6aefsnXrVurXr3/Ptv7+/ri6unLp0qV821haWuLg4GDyKgv2Vua0ruYKqKOlhBBCCPFokKRUeZFTT6pCVXXr7Kdu80pK3aPIeXhcKr8euw7AqPZViztKIYQQQjwgCwsLGjVqZFKkPKdoeYsWLfI9b+bMmXz44Yds3ryZxo0b3/c6ERERxMbG4uXlVSxxl7S7p/AJIYQQ4tEgSany4r9JqSKOlFq4MwS9QaF1VVcCfZyKP04hhBBCPLDx48ezcOFCli5dytmzZxk5ciQpKSkMHToUgMGDBzNx4kRj+88++4z333+fRYsW4evrS2RkJJGRkSQnJwOQnJzM22+/zb59+7h69SrBwcH06NGDqlWr0rlz5zK5x8J6spYHOq2GszcSCY1NKetwhBBCCFEAkpQqL4xFzgPUrcvtkVJpt9TX3fKpKXUzKYPVB8MBGNU+oKQiFUIIIcQD6t+/P1988QVTpkwhKCiIY8eOsXnzZmPx87CwMG7cuLMS3XfffUdmZiZ9+vTBy8vL+Priiy8A0Ol0nDhxgmeffZbq1aszbNgwGjVqxM6dO7G0tCyTeywsZ1sLmvurqwlultFSQgghxCNBCp2XF/8dKWVhC3aekBwJcVegovOdtvmMlFq8+woZ2QaCfJxoEVChFIIWQgghRFGNGTOGMWPG5Hlsx44dJp+vXr16z76sra3ZsmVLMUVWdrrU8WT3pVj+PBXJq+3kBzYhhBDiYScjpcqL/yal4M5oqf9O4TPWlLpTDDUxPYtle0MBdZSURqMpqUiFEEIIIUpE5zqeaDRwLDyeGwlpZR2OEEIIIe5DklLlQWrcnSl6Lnf9KphTV+rWFdP2xpFS7sZdy/aGkpSRTTV3OzrVyntVPiGEEEKIh5m7gxWNKqujw7fIFD4hhBDioSdJqfIgZ5SUQyWwsLmz3zhS6q6klEEPqTHq+9vT99Iy9SzapbYZ1SEArVZGSQkhhBDi0SSr8AkhhBCPDklKlQfGqXv/qZ2Q1wp8KTdBMYBGC7auAPx8KJzYlEwqOVvTvb53KQQshBBCCFEyOtdRk1IHr8YRk5xRxtEIIYQQ4l4KnZTy9fVl+vTphIWFlUQ8oijyqicF4JxHTamcqXu2bqDVkaU3sOBf9fir7QIw00meUgghhBCPLh8XG+pVdMSgwF9noso6HCGEEELcQ6EzEOPGjWPdunX4+/vz5JNPsmrVKjIy5FeoMpVfUipn+l5yFGSmqO+TTFfe23D0Gtfi03C1s6Rvo0qlEKwQQgghRMnKmcK3WabwCSGEEA+1IiWljh07xoEDB6hVqxavv/46Xl5ejBkzhiNHjpREjOJ+Yi+r2/8mpaydwdpFfZ9TVyr5TlJKb1D4bod67vA2fliZ60ohWCGEEEKIkpWTlNpzOYaE1KwyjkYIIYQQ+SnyXK2GDRsyd+5crl+/ztSpU/nhhx9o0qQJQUFBLFq0CEVRijNOkR+D4a6kVEDu4y7/mcKXfPsXQ3sP/jx1g5CYFBytzRnUvErJxyqEEEIIUQoC3Oyo6WlPll7h50PhZR2OEEIIIfJR5KRUVlYWP//8M88++yxvvfUWjRs35ocffqB379689957DBo0qDjjFPlJug7ZaaA1A6c8Ekv/LXaeHA2AYuvBN9vVZNbQVr7YWZqVRrRCCCGEEKXi5VbqD3OLdl8hS28o42iEEEIIkZdCZyKOHDnC4sWLWblyJVqtlsGDB/Pll19Ss2ZNY5uePXvSpEmTYg1U5COnnpSzH+jy+OPMSUrduj19L0kdKXUhxZqzNxKxtdAxpKVvyccphBBCCFGKejTwZuaW89xISOePE9fp2UBqZwohhBAPm0KPlGrSpAkXL17ku+++49q1a3zxxRcmCSkAPz8/BgwYUGxBinuIuahu/1tPKkc+I6V+vaz+YvhCiyo42ViUZIRCCCGEEKXO0kzH0Fa+AHz/T4iUlhBCCCEeQoUeKRUSEkKVKveuP2Rra8vixYuLHJQohHvVkwJ1BBXkKnR+4KYZlmZaXmntX8IBCiGEEEKUjUHNKvPN9kuci0xi16UY2lRzK+uQhBBCCHGXQo+Uio6OZv/+/bn279+/n0OHDhVLUKIQcqbv3W+kVEIEZGcYk1LRODOgiQ9u9palEKQQQgghROlzsrGgX2MfABb8G1LG0QghhBDivwqdlBo9ejTh4blXMbl27RqjR48ulqAeSwY9HFh4ZzpeQeUkpVyr5X3c1hUs7AEFok5BVioAtzROjGiXz+gqIYQQQohyYlhrP7Qa2HkxhjPXE8s6HCGEEELcpdBJqTNnztCwYcNc+xs0aMCZM2eKJajH0uElsOl/sG54wc/JzoT4UPV9fiOlNBpw8VXfh+4FIEmxpmvDACo6WRc5XCGEEEKIR4GPiw3d6nkB8MNOGS0lhBBCPEwKnZSytLQkKioq1/4bN25gZlboElUix7EV6vb60Tv1n+7n1lVQDGBhB3Ye+be7PYUv8cJOAGIUR0a2zyeJJYQQQghRzoxoqz4L/Xb8Otfj08o4GiGEEELkKHRS6qmnnmLixIkkJCQY98XHx/Pee+/x5JNPFmtwj42Yi3DtrnpcZ38r2HnGelIB6oio/OTUlQpXa4Fl23rg52pbhECFEEIIIR499Ss50czPhWyDwpI9V8s6HCGEEELcVuik1BdffEF4eDhVqlShQ4cOdOjQAT8/PyIjI5k1a1ZJxFj+5YySMrs9ne70hoKdd78i5zluJ6Uc9LcA8PD2KWSAQgghhBCPtlfbqc9DK/aHkZieVcbRCCGEEAKKkJSqWLEiJ06cYObMmdSuXZtGjRrx1VdfcfLkSXx8JNlRaAY9nFitvn9yOqCB60cgPuz+5xYwKaV38jX57OBaqfBxCiGEEEI8wtpXd6equx3JGdmsOlCA5ywhhBBClLgiFYGytbVlxIgRxR3L4+nqTki8BlaO0HAwnPkVQnep25av3/vc2Mvq9j5JqTVXLOh/94571Z8SQgghhCiHtFoNw9v48c7akyzadZUhLf2wMCv077NCCCGEKEZFrkx+5swZwsLCyMzMNNn/7LPPPnBQj5VjK9Vt3d5gbgV1nitEUuqumlL5uBafxvR/4uihMcdKc3uouiSlhBBCCPEY6hFUkS+2XiAyMZ3Fu6/warv8n6GEEEIIUfIKnZQKCQmhZ8+enDx5Eo1Gg6IoAGhuF9rW6/XFG2F5lpF0p6h54PPqtlZ32PQ2RByEhAhwzGeqXUYSJEeq713yfqBSFIX3N5wiJVMh2s6bytmh6gF7SUoJIYQQ4vFjZa7j7c41mLDmBF9uu0C3el74uNiUdVhCCCHEY6vQY5bfeOMN/Pz8iI6OxsbGhtOnT/Pvv//SuHFjduzYUQIhlmNnfoOsVHX6XaXG6j57T6jc4s7x/MRcULe2bmDtlGeTP07c4O9z0VjotLhUqnHngIyUEkIIIcpEeHg4ERERxs8HDhxg3LhxLFiwoAyjerz0bVSJ5v4upGcZmLzhlPEHViGEEEKUvkInpfbu3cv06dNxdXVFq9Wi1Wpp3bo1M2bMYOzYsUUK4ptvvsHX1xcrKyuaNWvGgQMH8m2blZXF9OnTCQgIwMrKisDAQDZv3pxv+08//RSNRsO4ceOKFFuJOn576l7gALg90gyA2j3U7Zlf8z5PUeCfz9X3FRvn2SQ+NZMPfj8NwKgOAdh5Vb9z0M7zQaIWQgghRBE9//zzbN++HYDIyEiefPJJDhw4wKRJk5g+fXoZR/cQUxS1luaVf0Gf/UBdaTQaPu5ZDwudln8u3OT3EzeKKUghhBBCFFahk1J6vR57e3sAXF1duX79OgBVqlTh/PnzhQ5g9erVjB8/nqlTp3LkyBECAwPp3Lkz0dHRebafPHky33//PV9//TVnzpzhtddeo2fPnhw9ejRX24MHD/L9999Tv379QsdV4uLD1CLnaKD+ANNjtW/X5QrfB4nXc5977g+48CdozaHTtDy7/2TTWWKSM6nqbsfI9gHg4qce0OjApkKx3YYQQgghCu7UqVM0bdoUgJ9//pm6deuyZ88eli9fzpIlS8o2uIeZosC3zWFpd0h68CRSgJsdozuoC8VM//00CalZD9ynEEIIIQqv0EmpunXrcvz4cQCaNWvGzJkz2b17N9OnT8ff37/QAcyePZvhw4czdOhQateuzfz587GxsWHRokV5tl+2bBnvvfce3bp1w9/fn5EjR9KtWzdmzZpl0i45OZlBgwaxcOFCnJ2dCx1XiTu+Wt36tQEnH9NjDt7g00x9f/Z302PpibBpgvq+9Thwr5mr6z2XY/j5kDo14NNe9bA004HL7T8bO3fQykozQgghRFnIysrC0tISgG3bthkXiKlZsyY3bsiInXxptWDvpb7P6we7InitvT8BbrbEJGcy48+zxdKnEEIIIQqn0NmJyZMnYzAYAJg+fTpXrlyhTZs2bNq0iblz5xaqr8zMTA4fPkynTp3uBKTV0qlTJ/bu3ZvnORkZGVhZWZnss7a2ZteuXSb7Ro8ezdNPP23Sd34yMjJITEw0eZUoRblr6t7zebfJmcJ3eoPp/u0fQ9J1NcnU5q1cp6Vn6Xlv3UkAXmhemca+LuqByi2heldoWbQplkIIIYR4cHXq1GH+/Pns3LmTv/76iy5dugBw/fp1KlSQkcz35OCtbhOvFUt3lmY6ZvRSR9OvOhjOgStxxdKvEEIIIQqu0Empzp0706tXLwCqVq3KuXPniImJITo6mieeeKJQfcXExKDX6/HwMC287eHhQWRkZL7Xnz17NhcvXsRgMPDXX3+xbt06k18XV61axZEjR5gxY0aB4pgxYwaOjo7Gl4+Pz/1PehDhByDuMpjbqqvt5aXW7Sl8YXsh6fZ3ce0w7P9eff/0bDC3znXa9D/OcDU2FQ8HSyZ0uWsUlbkVPL8KWowqxhsRQgghRGF89tlnfP/997Rv356BAwcSGBgIwG+//Wac1ifyYUxKFc9IKYCmfi4MbKo+901cd4KMbFlFWgghhChNhUpKZWVlYWZmxqlTp0z2u7i4oLm7UHcJ+uqrr6hWrRo1a9bEwsKCMWPGMHToULS3p6SFh4fzxhtvsHz58lwjqvIzceJEEhISjK/w8PCSvAU4vkLd1n4WLO3ybuPkc7uIuaJO4dNnw+9vqJ/r94eADrlO+f34dVbsD0OjgVl9g3CwMi+xWxBCCCFE4bVv356YmBhiYmJMShWMGDGC+fPnl2Fkj4ASSEoBvNulFq52lly+mcL8HSHF2rcQQggh7q1QSSlzc3MqV66MXl88vyK5urqi0+mIiooy2R8VFYWnZ94rxLm5ubFhwwZSUlIIDQ3l3Llz2NnZGetZHT58mOjoaBo2bIiZmRlmZmb8888/zJ07FzMzszxjt7S0xMHBweRVYrLS4NR69X3gwHu3rfOcuj3zK+yfD5EnwcoJnvo4V9PQ2BQm3p62N7p9VVpXcy2+mIUQQghRLNLS0sjIyDDWuwwNDWXOnDmcP38ed3f3Mo7uIedQUd0W0/S9HI425kzpXhuAb7Zf4kpMSrH2L4QQQoj8FXr63qRJk3jvvfeIi3vwefcWFhY0atSI4OBg4z6DwUBwcDAtWrS457lWVlZUrFiR7Oxs1q5dS48eag2mjh07cvLkSY4dO2Z8NW7cmEGDBnHs2DF0Ot0Dx/1Azv8JGQng6AO+be7dNmcKX+hutZYUwFMfgp2bSbOMbD1jVhwlOSObJr7OjOtUrQQCF0IIIcSD6tGjBz/++CMA8fHxNGvWjFmzZvHcc8/x3XffFaqvb775Bl9fX6ysrGjWrBkHDhzIt+3ChQtp06YNzs7OODs706lTp1ztFUVhypQpeHl5YW1tTadOnbh48WLhb7Kk5IyUKobV9/6re30v2lZ3I1Nv4OONUvRcCCGEKC2FTkrNmzePf//9F29vb2rUqEHDhg1NXoU1fvx4Fi5cyNKlSzl79iwjR44kJSWFoUOHAjB48GAmTpxobL9//37WrVtHSEgIO3fupEuXLhgMBiZMUFeks7e3p27duiYvW1tbKlSoQN26dQsdX7HT6sC1hjoF736r4DlXAe+GoBggK1UtVh70Qq5mn/15npPXEnCyMeerAQ0w08nqekIIIcTD6MiRI7Rpo/4otWbNGjw8PAgNDeXHH38s1IIxq1evZvz48UydOpUjR44QGBhI586diY6OzrP9jh07GDhwINu3b2fv3r34+Pjw1FNPce3anVFHM2fOZO7cucyfP5/9+/dja2tL586dSU9Pf7CbLi7GkVLFO30PQKPRMOWZWui0GradjWLPpZhiv4YQQgghcjMr7AnPPfdcsQbQv39/bt68yZQpU4iMjCQoKIjNmzcbi5+HhYUZ60UBpKenM3nyZEJCQrCzs6Nbt24sW7YMJyenYo2rxNTuoY6A0mcVvP31I6A1h2e+zJXI+utMFIt2XwHgiz6BeDvlLn4uhBBCiIdDamoq9vb2AGzdupVevXqh1Wpp3rw5oaGhBe5n9uzZDB8+3Pgj3vz589m4cSOLFi3i3XffzdV++fLlJp9/+OEH1q5dS3BwMIMHD0ZRFObMmcPkyZONo89//PFHPDw82LBhAwMGDCjqLRefu0dKGfTqD33FqKq7PS80q8zSvaFM/+MMG8e2QactnZqpQgghxOOq0EmpqVOnFnsQY8aMYcyYMXke27Fjh8nndu3acebMmUL1/98+ypxGA2YWBWvbcLC6Al/NZ8C9psmh6/FpvL3mOADDWvvRqbZHXj0IIYQQ4iFRtWpVNmzYQM+ePdmyZQtvvvkmANHR0QWuaZmZmcnhw4dNRpJrtVo6derE3r17C9RHamoqWVlZuLi4AHDlyhUiIyPp1KmTsY2joyPNmjVj7969+SalMjIyyMjIMH5OTEws0PWLxM4DNDowZEPKTbDPu/7ogxjXqTrrj17jXGQSvxwKZ0DTysV+DSGEEELcIfO8HnY2LvD8amj4osnubL2BsSuPEp+aRf1KjrzTpWY+HQghhBDiYTFlyhT+97//4evrS9OmTY01NLdu3UqDBg0K1EdMTAx6vd44qjyHh4cHkZGRBerjnXfewdvb25iEyjmvsH3OmDEDR0dH48vHx6dA1y8Sre5OIqqYi53ncLa1YGxHtTbnF1svkJyRXSLXEUIIIYSq0EkprVaLTqfL9yVKx7oj1zgUegt7SzPmDWyIhZnkF4UQQoiHXZ8+fQgLC+PQoUNs2bLFuL9jx458+eWXpRLDp59+yqpVq1i/fj1WVlYP1NfEiRNJSEgwvsLDw4spynzkTOErgbpSOQa38MXP1ZaY5Ay+3X6pxK4jhBBCiCJM31u/fr3J56ysLI4ePcrSpUv54IMPii0wkT+9QWH+v5cBeL1jVSpXsCnjiIQQQghRUJ6ennh6ehIREQFApUqVaNq0aYHPd3V1RafTERUVZbI/KioKT897T2n74osv+PTTT9m2bRv169c3iSmnDy8vL5M+g4KC8u3P0tISS0vLAsf+wOxvx1aCSSkLMy0Tu9ZkxLLD/LDrCgObVsbHRZ61hBBCiJJQ6OE1PXr0MHn16dOHjz/+mJkzZ/Lbb7+VRIziP7aejiTkZgqO1uY836xKWYcjhBBCiAIyGAxMnz4dR0dHqlSpQpUqVXBycuLDDz/EYDAUqA8LCwsaNWpEcHCwSb/BwcHG6YB5mTlzJh9++CGbN2+mcePGJsf8/Pzw9PQ06TMxMZH9+/ffs89SZ1yBr2Sm7+V4srYHLfwrkJlt4NPN50r0WkIIIcTjrNjmfDVv3tzkQUaUDEVR+HaHOkrqpRZVsLMs9GA3IYQQQpSRSZMmMW/ePD799FOOHj3K0aNH+eSTT/j66695//33C9zP+PHjWbhwIUuXLuXs2bOMHDmSlJQU42p8gwcPNimE/tlnn/H++++zaNEifH19iYyMJDIykuTkZAA0Gg3jxo3jo48+4rfffuPkyZMMHjwYb2/vYl95+YGUwvQ9UL+P95+pjUYDG0/c4NDVuBK9nhBCCPG4KpaMRlpaGnPnzqVixYrF0Z24h92XYjl5LQErcy0vtfQt63CEEEIIUQhLly7lhx9+4NlnnzXuq1+/PhUrVmTUqFF8/PHHBeqnf//+3Lx5kylTphAZGUlQUBCbN282FioPCwtDq73z2+N3331HZmYmffr0Meln6tSpTJs2DYAJEyaQkpLCiBEjiI+Pp3Xr1mzevPmB604VK2NS6kaJX6q2twP9G/uw6mA4H/5xhvWjWqHVakr8ukIIIcTjpNBJKWdnZzSaO/9BVhSFpKQkbGxs+Omnn4o1OJHbtzvUgpsDmlSmgl0p1nAQQgghxAOLi4ujZs3cK+bWrFmTuLjCjcYZM2YMY8aMyfPYjh07TD5fvXr1vv1pNBqmT5/O9OnTCxVHqSql6Xs5xj9Vnd+PX+d4RAKbT0fSrZ7X/U8SQgghRIEVOin15ZdfmiSltFotbm5uNGvWDGdn52INTpg6Fh7PnsuxmGk1DG/rX9bhCCGEEKKQAgMDmTdvHnPnzjXZP2/ePJPC4yIfd0/fUxTQlOzIJXd7K15u7cfXf1/i+38u07Wup8lzsBBCCCEeTKGTUkOGDCmBMERBfHd7lFSPoIpUdLIu42iEEEIIUVgzZ87k6aefZtu2bcYC4nv37iU8PJxNmzaVcXSPgJzV9/QZkBoHthVK/JIvtfRlwb8hHI9IYF9IHC0CSv6aQgghxOOi0IXOFy9ezC+//JJr/y+//MLSpUuLJSiR26XoJLacVpd+HtleRkkJIYQQj6J27dpx4cIFevbsSXx8PPHx8fTq1YvTp0+zbNmysg7v4WdmAbbu6vtSmsLnamdJ38aVAPj+38ulck0hhBDicVHopNSMGTNwdXXNtd/d3Z1PPvmkWIISuX23IwSAp2p7UNXdvoyjEUIIIURReXt78/HHH7N27VrWrl3LRx99xK1bt/i///u/sg7t0VBKK/Dd7ZXW/mg1sOP8Tc7eSCy16wohhBDlXaGTUmFhYfj5+eXaX6VKFcLCwoolKGHqWnwavx5Tfw0c1aFqGUcjhBBCCFGGjEmp0hkpBeDrakvXuurUwYX/hpTadYUQQojyrtBJKXd3d06cOJFr//Hjx6lQQebYl4SF/4aQbVBoGVCBIB+nsg5HCCGEEKLslMFIKYARtxeZ+e34da7Fp5XqtYUQQojyqtBJqYEDBzJ27Fi2b9+OXq9Hr9fz999/88YbbzBgwICSiPGxFpeSyaqD6gi0ke0DyjgaIYQQQogyVkZJqUAfJ1r4VyDboLBo15VSvbYQQghRXhV69b0PP/yQq1ev0rFjR8zM1NMNBgODBw+WmlIl4K8zkaRnGajt5UDrqrlreQkhhBDi4derV697Ho+Pjy+dQMoDh4rqNql0k1IAr7bzZ29ILCsPhDH2iWo42piXegxCCCFEeVLopJSFhQWrV6/mo48+4tixY1hbW1OvXj2qVKny/+3dd3hU1dbH8e+k9wQS0oAQQu+hC0hRUZooiFIuSlUvCr4gYsGKFa4iol4vNpoVGyA2FGlKLxJ67yWNml7nvH8cMhBIIIEkE5Lf53nmmZlz9pyz90wIJ2vWXrs4+lfurT1wGoDb6gVisVjs3BsRERG5Fr6+vlfdP2jQoBLqzQ3OTplSAB1rV6JusDe7YhL5Yu1hRqrWp4iIyHUpdFAqR61atahVq1ZR9kUuYRgGaw+aQanW1VWvS0RE5EY1c+ZMe3eh7MjJlDp3HAwDSvBLO4vFwoiONRjzTRQzVx5k+M3VcXN2LLHzi4iIlDWFrinVp08f/vOf/1y2/c033+S+++4rkk6J6diZVI6fTcXJwUKzan727o6IiIiI/Xmbq+CRmQzpCSV++h6NQ6js587JpAx++OdYiZ9fRESkLCl0UOqvv/6ie/ful23v1q0bf/31V5F0SkxrDpwCoHEVXzxcrjmpTURERKTscPEA9wrmYztM4XN2dGD4zdUBc4XkbKtR4n0QEREpKwodlEpKSsLFxeWy7c7OziQklPy3VWVZztS9myI0dU9ERETEJmcKX8Jxu5y+X8uq+Lo7c+hUCj9G2acPIiIiZUGhg1KNGjXim2++uWz7nDlzqF+/fpF0SkxrD5qZUq0VlBIRERG5wI7FzgE8XZ14uEMEABN/20VCWqZd+iEiInKjK/ScsBdeeIF77rmH/fv3c+uttwKwePFivvrqK77//vsi72B5dfxsKkdPp+LoYKF5tQr27o6IiIhI6ZFTV8pOQSmAB9tX5/uNxzh4Mpmpi/byYk99OSsiIlJYhc6U6tmzJ/Pnz2ffvn08+uijPPHEExw/fpwlS5ZQs6aWxS0qa8/Xk2pY2RcvV9WTEhEREbGx8/Q9AFcnRybc1QCA2asPsStGZSxEREQKq9BBKYAePXqwcuVKkpOTOXDgAH379mXcuHE0adKkqPtXbq09cL6eVPWKdu6JiIiISCljm74XbddudKxdia4Ngsm2Grw4fzuGoaLnIiIihXFNQSkwV+EbPHgwoaGhvP3229x6662sWbOmKPtWruXUk1KRcxEREZFL2Lmm1MVe6FkfN2cH1h06zY9R9u+PiIjIjaRQQamYmBgmTZpErVq1uO+++/Dx8SE9PZ358+czadIkWrZsWVz9LFdiE9I4dCoFBwu0CFc9KREREZFcSsH0vRyV/dx57NZaALz+604VPRcRESmEAgelevbsSZ06ddiyZQtTp07lxIkTvP/++8XZt3Jrzfl6Ug1CffF2c7Zzb0RERERKmZxMqbSzkJFs166AWfS8eoAn8YnpTF20197dERERuWEUOCj122+/MXz4cF5++WV69OiBo6NjcfarXFtzvp5Ua9WTEhEREbmcmw+4eJuP7VxXClT0XERE5FoVOCi1YsUKEhMTad68Oa1bt+a///0vJ0+eLM6+lVs59aRaq56UiIiISN5sdaXsP4UPzKLn3Rqq6LmIiEhhFDgoddNNN/HJJ58QHR3Nv//9b+bMmUNoaChWq5VFixaRmJhYnP0sN+IS0zgQn4zFAq3ClSklIiIikqdSVOw8x/N31sfd2ZF1h07z2NebOJei+lIiIiJXUujV9zw9PRk2bBgrVqxg69atPPHEE0yaNInAwEDuuuuu4uhjubLuoDl1r16wD74eqiclIiIikqdSlikFZtHzCXfVx9HBws9boun27l+s2q+ZBSIiIvkpdFDqYnXq1OHNN9/k2LFjfP3110XVp3JtbU49qQhlSYmIiIjkqxRmSgH0axnG9yPaEO7vwYlzaQz8dC0Tf91Jela2vbsmIiJS6lxXUCqHo6MjvXr1YsGCBUVxuHItZ+W91tVVT0pEREQkXzlBqUT7Fzq/VNOwCvzyf+0Z0KoqhgEf/XWAXh+sYk+syl2IiIhcrEiCUlI0TiWlszcuCYBWWnlPREREJH8+lc37UjR972Kerk5MvKcxHz/QnIqeLuyMTuDO91ewdHecvbsmIiJSaigoVYrk1JOqG+xNRU8XO/dGREREpBQrpdP3LnVHg2AWjmlPh9qVyMiyMvLLf9h67Jy9uyUiIlIqKChViqw9H5RqrSwpERERkSvLyZRKjoes9Mv3GwZYS0cdp0BvNz4d1IKbawaQkpHN0FnrOXo6xd7dEhERsTsFpUoRWz2pCNWTEhERkSv74IMPCA8Px83NjdatW7Nu3bp8227fvp0+ffoQHh6OxWJh6tSpl7WZMGECFosl161u3brFOILr5F4BnNzMx5fWlbJa4cv7YHJtiNtZ8n3Lg4uTA9Pub0a9EB9OJqUzeMY6ziRn2LtbIiIidqWgVClxJjmDXTFm8UvVkxIREZEr+eabbxg7diwvvfQS//zzD02aNKFLly7ExeVdryglJYWIiAgmTZpEcHBwvsdt0KAB0dHRttuKFSuKawjXz2LJfwrf+k9h3yJIOQnf3A9pCSXfvzx4uzkza2hLQn3dOHAymQc/20BaZunI5hIREbEHBaVKiX+OnAGgZqAXAV6udu6NiIiIlGZTpkzhoYceYujQodSvX58PP/wQDw8PZsyYkWf7li1b8tZbb9G/f39cXfO/znByciI4ONh2CwgIKK4hFA1bsfOLglJnDsOfE8zHTu5wah/8ONKczlcKBPm4MXtYK3zcnNh4+Ayj52wi21o6+iYiIlLSFJQqJeITzVoI4f4edu6JiIiIlGYZGRls3LiRzp0727Y5ODjQuXNnVq9efV3H3rt3L6GhoURERDBw4ECOHDlyvd0tXrZMqfMr8BkG/PR/kJkM1drB4AXg4Aw7F8Dq/9qvn5eoFeTNJ4Na4OLowO/bY3nlp+0YpSRoJiIiUpIUlColEtIyATOtW0RERCQ/J0+eJDs7m6CgoFzbg4KCiImJuebjtm7dmlmzZrFw4UKmTZvGwYMHad++PYmJifm+Jj09nYSEhFy3EuUdYt4nnK8ptekLOLDMrDV11/tQtRV0nWjuW/QSHFpZsv27gtYR/kzp1wSA2asP869P1rLh0Gk790pERKRkKShVSiSmZQHg4+Zk556IiIhIedStWzfuu+8+GjduTJcuXfj11185e/Ys3377bb6vmThxIr6+vrZb1apVS7DHXDR977gZmPr9OfP5Lc+Bfw3zccsHoXE/MLLhuyEXAlilwJ2NQ3n17ga4ODqw+sAp7v1wNYNnrGPz0bP27pqIiEiJKBVBqcKsHpOZmckrr7xCjRo1cHNzo0mTJixcuDBXm4kTJ9KyZUu8vb0JDAykV69e7N69u7iHcV0SUpUpJSIiIlcXEBCAo6MjsbGxubbHxsZesYh5Yfn5+VG7dm327duXb5vx48dz7tw52+3o0aNFdv4CuXj63i9jIf0chDaDmx690MZigTunQmADSI4zA1PZmSXbzyt4oE04S5/sxIBWYTg5WFi+J567P1jJg7M3sONE6SjQLiIiUlzsHpQq7Ooxzz//PB999BHvv/8+O3bsYMSIEfTu3ZtNmzbZ2ixfvpyRI0eyZs0aFi1aRGZmJnfccQfJycklNaxCS8jJlHJXppSIiIjkz8XFhebNm7N48WLbNqvVyuLFi2nTpk2RnScpKYn9+/cTEhKSbxtXV1d8fHxy3UpUTlDqxCbY/atZP+ruD8DxkuspFw/o9zm4+sDRNbDoxYKf4/RB2PZDsRZKr+znzsR7GrHkiU70aVYFBwv8uTOWHu//zbfrSzjQJyIiUoLsHpQq7Ooxn3/+Oc8++yzdu3cnIiKCRx55hO7du/P222/b2ixcuJAhQ4bQoEEDmjRpwqxZszhy5AgbN24sqWEVWqJqSomIiEgBjR07lk8++YTZs2ezc+dOHnnkEZKTkxk6dCgAgwYNYvz48bb2GRkZREVFERUVRUZGBsePHycqKipXFtS4ceNYvnw5hw4dYtWqVfTu3RtHR0cGDBhQ4uMrsJzpe4bVvO/wJATVz7utfw3o/aH5eM3/IHpLwc4x92H4fphZq6qYhfl78HbfJvzxeEe6NgjGMOC5+VtVa0pERMosuwalrmX1mPT0dNzc3HJtc3d3Z8WKFfme59y5cwBUrFixCHpdPBJSc2pKKSglIiIiV9avXz8mT57Miy++SGRkJFFRUSxcuNBW/PzIkSNER1+onXTixAmaNm1K06ZNiY6OZvLkyTRt2pQHH3zQ1ubYsWMMGDCAOnXq0LdvX/z9/VmzZg2VKlUq8fEVmGclcDifFRXYAG5+/Mrt6/aAWl3MxweXX/346YlwfIP5OGbrtfezkGoGejHt/mZ0bxRMZrbBiC82cuJsaomdX0REpKTYda7YlVaP2bVrV56v6dKlC1OmTKFDhw7UqFGDxYsXM3fuXLKzs/Nsb7VaGTNmDO3ataNhw4Z5tklPTyc9Pd32vMRXjuHi1fc0fU9ERESubtSoUYwaNSrPfcuWLcv1PDw8HOMq08/mzJlTVF0rOQ4OULkFRG+Gu/8LTi5Xf014O9j7OxxZA20fu3LbYxsuZGGdyr+2VnGwWCxMvq8JB+KT2RWTyMOfb+C7f7fF3cWxRPshIiJSnOw+fa+w3n33XWrVqkXdunVxcXFh1KhRDB06FAeHvIcycuRItm3bdsULLbuvHMNFq++5K1NKREREpMAemAujo6Bys4K1Dztfd+vI6qvXiTqy5sLjU/uvqXvXw8PFiU8GtaCipwvbjifwzNwtVw0uioiI3EjsGpS6ltVjKlWqxPz580lOTubw4cPs2rULLy8vIiIiLms7atQofv75Z5YuXUqVKlXy7YfdV47hQqaUjzKlRERERArOxRO8C7HqYEgTcHKDlFNwcu+V2x65qJxECWdK5aha0YP/DWyGk4OFH6NO8NFfB+zSDxERkeJg16DU9awe4+bmRuXKlcnKyuKHH37g7rvvtu0zDINRo0Yxb948lixZQvXq1a94LHuvHGO1GiSlm5lSKnQuIiIiUoycXKFyc/PxkbxrmAKQnWVO38uRFGPWmLKDmyL8eamnWcD9Pwt3sXRX3qtUi4iI3GjsPn2vsKvHrF27lrlz53LgwAH+/vtvunbtitVq5amnnrK1GTlyJF988QVfffUV3t7exMTEEBMTQ2pq6SwQmZieZcseV00pERERkWJmm8K3Jv82sVshMxlcfcHD39xmhyl8Oe6/qRoDWoVhGPB/czaxct9Ju/VFRESkqNg9AtKvXz/i4+N58cUXiYmJITIy8rLVYy6uF5WWlsbzzz/PgQMH8PLyonv37nz++ef4+fnZ2kybNg2ATp065TrXzJkzGTJkSHEPqdASz0/dc3FywM1ZxStFREREitXFdaXykxOwCmsNaQnmdL9T+yA0sti7lxeLxcLLdzVgX1wi6w+dYeCna+lUpxLPdKtL3eCSzfIXEREpKnYPSkHhVo/p2LEjO3bsuOLxbrQCkAmp54uca+qeiIiISPGr2hKwwJmDkBiTd02qnIBV2E1w6gAcXQOn7VvPycXJgU8Ht+SdRXv4Ys1hlu2OZ/meeO5tVoWxd9QmxNfdrv0TEREpLLtP35MLmVIqci4iIiJSAtx8Iaih+TivKXyGcVGmVBvwr2E+tlOx84v5ujsz4a4G/Dm2Iz0ahWAY8N3GY3R6axn/WbiL1Ixse3dRRESkwBSUKgUS0s4XOXdXppSIiIhIiQi7ybzPawrfmUOQFAsOzhDaFPxrmttLQVAqR3iAJx8MbMbcR9vSMrwC6VlWpi3bz8OfbyAjy2rv7omIiBSIglKlgDKlRERERErYlYJSOVlSoU3B2T13plQpKxPRLKwC3/67DR/e3xwPF0f+3nuSJ77bjNVauvopIiKSFwWlSoGE1JyglDKlREREREpETrHzmK2Qnph738X1pAAqRpj3aefMgueljMVioWvDYD68vznOjhZ+2nyCV37eccPVWRURkfJHQalSIPH89D0fd2VKiYiIiJQI38rgFwaGFY6tz73v4npSYGZL+VY1H5eiKXyX6lC7EpPvawLArFWH+GBp6e2riIgIKChVKiScn77nrUwpERERkZKTE3S6uNh5ymk4udt8XLX1he22KXz7S6Zv1+juyMq81LM+AJP/2MNXa4/YuUciIiL5U1CqFEhIPZ8ppZpSIiIiIiUnr7pSR9ea9wG1wdP/wvZSWOw8P0PbVWfULWZ/n5+/lYXbou3cIxERkbwpKFUKJKYrU0pERESkxOVkSh3bANnm9dhl9aRy3EBBKYAn7qjNgFZVsRrwf19HsWhHrL27JCIichkFpUoBW6aUakqJiIiIlJyAOuBeATJTIHqLue3SelI5bEGp0j19L4fFYuG1Xo3o2iCYjGwrD322gcm/7yZbq/KJiEgpoqBUKZCYptX3REREREqcgwNUvWgKX2YanNhkPr+4nhRcWIHv9H6wWkuuj9fB0cHCewOaMqRtOAD/XbqPQTPWciop3b4dExEROU9BqVIg4fzqe5q+JyIiIlLCLq4rdWITZGeAZ+CFIFQOv2rg4ARZaZBwvOT7eY1cnByYcFcD3u0fibuzIyv3neLO91ew8fCZPNvHJ6az8fBpMrNvjMCbiIjc2DRfrBSwZUpp+p6IiIhIybp4Bb7Kzc5vuwksltztHJ2gQnU4tdesK+VXtWT7eZ3ujqxMvRAfRnyxkQPxyfT7aDXPdKtLqJ8720+cY/uJBLafSCA+0cyiuqN+EB/e3xwHB8tVjiwiInLtlCllZ4Zh2GpKKVNKREREpISFRoKjK6SchKivzW2XFjnPkVNX6vSNUVfqUrWDvFkw6mZ6NA4hy2rw2i87efTLf/hg6X6W7Y4nPjEdi8Wc9vfHjlgm/7Hb3l0WEZEyTqk5dpaeZSXjfHq0j5s+DhEREZES5eQKlZvDkVVmFhRcIShVw7y/QYqd58XL1Yn/DmhK87AKzFh5kIqeLjQI9aF+iA/1Q32pF+LNH9tjGfNNFP9btp/aQd70alrZ3t0WEZEySlEQO0s4P3XPYgFPF30cIiIiIiWuWhszKAXg7AHBjfNuZ1uBb1/J9KuYWCwWht1cnWE3V89zf6+mldkTm8j/lu3nqR+2UM3fg6ZhFUq4lyIiUh5o+p6d2abuuTppzr6IiIiIPeTUlQKo0gIc8ympUEaCUgUx7o463F4/iIwsKw9/vpETZ1Pt3SURESmDFJSyswtFzlVPSkRERMQuqrQEzn85WDWfqXtwYfremcOQlVHs3bInBwcL7/SLpG6wN/GJ6Tz02QZSMrLs3S0RESljFJSys4Q0FTkXERERsSt3PzNDCqDGLfm38w4xp/cZ2XD2cIl0zZ68XJ34ZFALKnq6sP1EAuO+24zVati7WyIiUoaoiJGd2TKlVORcRERExH7um2VOy6vWNv82FouZLRWz1WwbUKvEumcvVSt68OH9zRn46Rp+3RpDs/2LCPJ2I9DHlUrergR6uxHq50bPxqFU8HSxd3dFROQGo0iIndlqSilTSkRERMR+fKuYt6vxr3k+KHXjrsBXWK2qV2TSPY0ZP3crZ1MyOZuSye7YxFxtZq08xDf/bkMlb1c79VJERG5ECkrZ2YWaUvooREREREq9clTs/GJ9mlehc/0gTpxNJS4xnfjEdOIS04hLSOf37TEcOJnMA9PX8s3DbfD1uPKXrUdOpRDq54aToyqJiIiUd4qE2FmCbfqeMqVERERESr1yGpQC8HV3xtfdmXohubcPaRvOfR+tZldMIoNnruOLB1vj5Xr5nxnnUjOZsGA78zYdp1mYH58Nz7udiIiUH/p6ws5ypu+pppSIiIjIDcAWlCo/0/euJjzAky+Gt8bPw5moo2d5aPYG0jKzc7VZvf8U3ab+xbxNxwH450je7UREpHxRUMrOLkzfU6aUiIiISKlXMcK8TzwB6Un27UspUifYm9lDW+Hp4sjqA6cY+eU/ZGZbScvM5vVfdvCvT9dw4lwaYRU9mHhPI7xcnXK1ExGR8klBKTtLSMspdK5MKRERESm4Dz74gPDwcNzc3GjdujXr1q3Lt+327dvp06cP4eHhWCwWpk6det3HLLc8KoJ7RfPx6QP27Usp06SqH9OHtMTVyYHFu+J49Mt/6PXBSj75+yCGAQNaVeW30e0Z0CqM6YNb4OZstnv8myiyrYa9uy8iInagoJSdJaqmlIiIiBTSN998w9ixY3nppZf4559/aNKkCV26dCEuLi7P9ikpKURERDBp0iSCg4OL5JjlWjmuK3U1N0X48+EDzXF2tLBoRyy7YhIJ8HLh00EtmHhPYzzP15BqHeHPh/eb7X7eEs34uVuwKjAlIlLuKChlZzk1pbwVlBIREZECmjJlCg899BBDhw6lfv36fPjhh3h4eDBjxow827ds2ZK33nqL/v374+rqWiTHLNdyglKnVVcqL7fUCeTd/k3xdnWiS4MgFo7pQOf6QZe161QnkPf6N8XBAt9uOMYrP+/AMBSYEhEpTzRnzM4u1JTSRyEiIiJXl5GRwcaNGxk/frxtm4ODA507d2b16tUlesz09HTS09NtzxMSEq7p/Dcc/xrmvYqd56t7oxC6NgjGwcFyxXbdGoXw1r1NeOK7zcxadYid0Qm0ql6RyKp+RFb1w98r7yCqiIiUDYqE2NmFmlLKlBIREZGrO3nyJNnZ2QQF5c48CQoKYteuXSV6zIkTJ/Lyyy9f0zlvaJq+VyBXC0jl6NO8CimZ2bwwfxtrD55m7cHTtn1VK7oTWbUC97cOo3WEf3F1VURE7ETT9+wo22qQlG4GpXxU6FxERERuMOPHj+fcuXO229GjR+3dpZKhoFSRe+Cmavw5tiOv9WpIn2ZVqFHJE4Cjp1P5afMJ/vXpWr5Yc9jOvRQRkaKmSIgdJZ3PkgJlSomIiEjBBAQE4OjoSGxsbK7tsbGx+RYxL65jurq65lujqkyrGGHep56BlNPminzXavM3sOYDcHIHzwDwrHT+FgC+VaF2F3BwvPbjW60QHQUhTa7vOCWgZqAXNQO9uP+magCcS81ky7GzfLvhGD9tPsHz87dx8GQyz3avh2MBs7BERKR0U6aUHSWcryfl5uyAi5M+ChEREbk6FxcXmjdvzuLFi23brFYrixcvpk2bNqXmmGWaiwf4VDYfH1177cfZ+j3M+zdEb4aja2DXz7BxJvz1Jvz2FMwZAGs/ur6+rpgCn9wCq967vuPYga+7M+1rVeK9/pGMu6M2ANNXHOTfn28gOT3rKq8WEZEbgSIhdpQTlPJRlpSIiIgUwtixY/nkk0+YPXs2O3fu5JFHHiE5OZmhQ4cCMGjQoFxFyzMyMoiKiiIqKoqMjAyOHz9OVFQU+/btK/Ax5RJVWpj3c/4Fvz5pZk0Vxt4/zYAUBjQbBH0/gx5vQ6fx0PJBCG9vtlv/KVzrinRWK2yYaT7e+v21HaMUsFgsjLq1Fv/9V1NcnBz4c2cc9324muhzqbY22VaDfXGJ/Bh1nLf/2M2CzSfIyrbasdciIlIQmr5nRwmpOUXO9TGIiIhIwfXr14/4+HhefPFFYmJiiIyMZOHChbZC5UeOHMHB4cJ3jydOnKBp06a255MnT2by5Ml07NiRZcuWFeiYconuk8HiANvnwbqPYdsP0HkCRN4PDlf53vfIWvjmfrBmQcN74c53L39NeiK8XRdO74dDK6B6+8L38dDfkHDMfBy7Dc4eAb+wwh+nlLizcSihfu48/NkGdkQn0OuDldxaN4id0QnsikkgLTN3EGqKvwePdqpJ72aVcXbUd/EiIqWRxTCu9auXsishIQFfX1/OnTuHj49PsZ3nj+0xPPz5RpqG+THv0XbFdh4RERG5diV1XVAWlMv36sByc6pd/PlVCis3h+5vmfd5idkGs7pD2jmo2Rn6fw1OLnm3/Wk0bJwFje6DPp8Wvm/zRsDmry887z4ZWj1U+OOUMkdPpzB89nr2xCbl2u7h4ki9EB/C/T1ZsiuWMynmrITKfu480qkG97WogqtT6a6rJSJSVhT0mkApOnaUkJaTKaXpeyIiIiI3pIiOMGKFWftp2SQ4vhE+uRUq1TOLlNfuClVagqMTnD4AX9xjBqSqtoa+n+cfkAJoPsQMSu34Ebq9WbiC6ulJsGOB+bhOd9j9K+z5vUwEpapW9OD7R9oy/e+DZGZbqR/qQ/0QH6r5e9oKoCenZ/Hl2sN8/NdBjp9N5fn52/jvkn2M61KHe5tXsfMIREQkh4JSdpRoqymlj0FERETkhuXoDG1HQaN7YdFLsPU7iN9p3lZOBfcKZlbUsfWQFAuBDeBf35gF068ktKm5al70ZjPjqc3Igvdp50+QmQwVa8CtL5hBqYN/QUYyuHhe13BLAx83Zx6/vXa++z1dnXi4Qw0GtQnn63VH+Gj5AWIS0hj33Waijp7hxTsbXHGhoXUHT/PC/G0E+7rxdt8mBHiVw1UmRURKgCZX29GFmlLKlBIRERG54XkHwz0fwZP7oM90c9qdm59ZBH3rd3DmEFQIhwfmmoGqgmg+xLzfOKtwBc83f2XeNxkAgfXArxpkp8OBZQU/Rhng5uzI0HbVWf5UJ8beXhuLBb5Yc4T7p6/lZFL6Ze0zsqy8uXAX/T5eze7YRJbvieeu91ew7fg5O/ReRKTsU1DKjmyr77krU0pERESkzPCoaGZN9fkUntwPQ3+DdmOgQW8Y9KMZvCqohveCswec3ANHVhfsNWePwsG/zceN+4LFYk4jBNizsFBDKStcnRz5v9tq8emgFni5OrHu4Gnu/u/KXMGmfXGJ3DNtJf9bth/DgF6RoUQEeHLiXBr3friKBZtP2HEEIiJlk4JSdnRh+p4ypURERETKJEcnqNYWbn8Z7ptlZkoVhpsPNOxjPt44u2Cv2fINYEB4e6hQzdxWJyco9TtYrfm+tKy7rV4Q80e2pXqAJ8fPpnLvh6v4Meo4n60+RI/3VrDteAJ+Hs5MG9iMqf2bMm9kOzrVqURappX/+3oT/1m4i2xrwTPWDMPgt63RLN0VV4yjEhG5cSkoZUc50/dUU0pERERE8tV8qHm/fR6knL5yW8O4sOJekwEXtldrBy5eZk2r6Khi6eaNomagN/NHtqNjbTPYNHpOFC/+uJ30LCvtawXw+5gOdGsUAoCvuzPTB7dkRMcaAExbtp+HPttgm/FwJcfOpPDA9HU88uU/DJ21nm/WHynWcYmI3IgUlLKjxPSc6XvKlBIRERGRfFRuBkGNzJpQW769ctvjG+HUPnPKX/27Lmx3coUat5iPy+kUvov5ujszY8iFYJOrkwMTetZn9tBWBPm45Wrr6GDhmW51ebd/JK5ODizZFcftU5bz/uK9xCdeXpfKajX4Ys1hurzzFyv2neT8goCMn7uVX7dGF/vYRERuJKUiKPXBBx8QHh6Om5sbrVu3Zt26dfm2zczM5JVXXqFGjRq4ubnRpEkTFi68/D/WwhzTXi4UOlemlIiIiIjkw2KB5oPNx1creB51vsB5vZ7g6p17X+1u5r2CUsCFYNNPo25m8RMdGdKuOg45EaQ83B1Zme9HtKWynzuxCem8vWgPbSctZsycTfxz5AyGYXD0dAr3T1/L8/O3kZyRTYtqFfhzbEcGtArDasDoOZtYvie+BEcpIlK62T0o9c033zB27Fheeukl/vnnH5o0aUKXLl2Ii8t73vXzzz/PRx99xPvvv8+OHTsYMWIEvXv3ZtOmTdd8THtRTSkRERERKZDGfcHJHeJ3wtF8vmzNSodtP5iPL566l6PW7YAFojdDgop252hUxZcqFTwK3HbJuI5M7RdJ0zA/MrMN5ked4J7/raLHeyvoMvUvVu0/hZuzAy/eWZ9v/t2GiEpevNarIXc2DiEz22DE5xvZePgq0zBFRMoJuwelpkyZwkMPPcTQoUOpX78+H374IR4eHsyYMSPP9p9//jnPPvss3bt3JyIigkceeYTu3bvz9ttvX/Mx7SUhLSdTSkEpEREREbkCN19oeI/5eOOsvNvsWQhpZ8E7FKp3uHy/VyBUbn6+7e/F0ctywdXJkV5NKzPv0XYsGNWOe5tXwcXJgR3RCaRkZNOqekUWju7AsJur43g+88rRwcKUvpF0qlOJ1Mxshsxcz44TCbmOm5FlZf2h07y3eC//XbKXQyeT7TE8EZESZdd5YxkZGWzcuJHx48fbtjk4ONC5c2dWr857ydv09HTc3HLP83Z3d2fFihXXfEx7MAyDhNScmlKavicipV92djaZmVcv7Cpyo3F2dsbR0dHe3RC5uuZDIOpLs+B5l9fBo2Lu/VE5Bc77gUM+P9N1usLxDWZQqsXQYu1uedC4ih+T7/Pj2e71mPvPMXzcnbm3WZU8pwG6ODkwbWBzBs1Yy/pDZxg0Yy1v3tuY3TFJrNp/kg2HzpCamW1rP/mPPTSvVoF7mlXmzkah+HoU7IvspPQsdkUnsCM6AavVoHP9oAJngomIlDS7RkNOnjxJdnY2QUFBubYHBQWxa9euPF/TpUsXpkyZQocOHahRowaLFy9m7ty5ZGdnX/Mx09PTSU+/UKQwISEhz3ZFKS3TStb55WQ1fU9ESjPDMIiJieHs2bP27opIsfHz8yM4OBiLJf96MiJ2V6UlBNaHuB3wdh0IagAhkRDSBPxrwL5FZru8pu7lqN0VlrwGB5ZBZio4u5dEz8u8ip4uPNg+4qrt3F0c+XRwSwZ8vIYd0QkMm7Uh135/TxduivAnMT2LFXvj2Xj4DBsPn+HlBTvoXD+Qm2tWwvH8XJeLS4vFJ6az43wg6vCplFzHnPDTDpqF+dGzSSg9GoUQeEkh9zLDMCA53swIFJEbxg2XovPuu+/y0EMPUbduXSwWCzVq1GDo0KHXNTVv4sSJvPzyy0XYy6vLWUbW0cGCh4u+nRWR0isnIBUYGIiHh4f+aJcyxTAMUlJSbHUnQ0JC7NwjkSuwWOCW5+DHkeY0vRObzNvFQptBpTr5HyOoIfhUgYRjcPAvqN2lWLssl/N1d+az4a24/9O1HD+byk0R/rSt4U+bGv7UDvS2ZVnFJqTxY9Rxfth4nN2xify6NYZft8YU6BzBPm7UD/UhOT2LdYdO88+Rs/xz5Cyv/LyD1tUrck/TKtzTrDJOjnav5lJ01vwPfn8W7psNDXrZuzciUkB2DUoFBATg6OhIbGxsru2xsbEEBwfn+ZpKlSoxf/580tLSOHXqFKGhoTzzzDNERERc8zHHjx/P2LFjbc8TEhKoWrXq9QztqnKKnHu7OekPPBEptbKzs20BKX9/f3t3R6RYuLubmSJxcXEEBgZqKp+UbvXuhLo94MxBs2D5iSiIjjLv085C21FXfr3FYgaiNkw3a1ApKGUXAV6uLBzTAcMw8v1bIMjHjYc71OCh9hHsiE5g3j/HOXgymdzNzSfebk7UD/GhfqgP9UJ8qOjpYmsRm5DGr1uj+WnzCf45cpY1B06z5sBpZq8+xBu9G9Gkql/xDbQkbZ5j3u/6WUEpkRuIXYNSLi4uNG/enMWLF9OrVy8ArFYrixcvZtSoK/+H6ubmRuXKlcnMzOSHH36gb9++13xMV1dXXF1di2xcBXEuNafI+Q2XrCYi5UhODSkPD9WikLIt52c8MzNTQSkp/SwWqBhh3hr0NrcZhjkdz6UAv69rdz0flPrdfJ2+ILWbgnw5bbFYaBDqS4NQ32s6R5CPG0PbVWdou+ocO5PCgs0n+HDZfrafSKDX/1Yy6KZqPNGlzo1dUiT5FMRsMR8f32jfvohIodg9X3Ps2LF88sknzJ49m507d/LII4+QnJzM0KFm4cVBgwblKlq+du1a5s6dy4EDB/j777/p2rUrVquVp556qsDHLA1yMqVu6F/+IlJuKKNTyjr9jMsNz2IpWEAKoHp7cHKHhOMQs7V4+yWlSpUKHjzaqSaLn+hEr8hQDANmrz5M57eX88uWaIyLC1Vdo31xSazad5KsbGsR9LiADi6/8Pj0AUg5XXLnFpHrYvc0nX79+hEfH8+LL75ITEwMkZGRLFy40Fao/MiRIzg4XIidpaWl8fzzz3PgwAG8vLzo3r07n3/+OX5+fgU+ZmmQkKZMKRGRG0l4eDhjxoxhzJgx9u6KiMj1cXaHGrfA7l9h67cQ0vjqrzm0En4dB03vhzYji7+PUqwqebsytX9T7m1elefnb+XQqRRGfvUPzcL8CKvogZebE16uzni7OeHl6oS/lwsNQ32p5p93bckzyRn8tOUEP2w8xuZj5wCoH+LD670b0jSsQvEP6MCy3M9PbIKatxX/eUXkulmMogiHlzEJCQn4+vpy7tw5fHx8iuUcX649zHPztnFH/SA+HtSiWM4hInK90tLSOHjwINWrV8fN7cZYredqGS8vvfQSEyZMKPRx4+Pj8fT0LJKpjF9//TX3338/I0aM4IMPPrju48n1u9LPeklcF5QVeq9uIDt/gm/uB4sjDFsIVVvl3zYpHj5sB0nna7be8hx0fCr/9iXFmg0WB00/vE5pmdn8b9l+Ply2n4yrZDf5uDnRqIovjSr70biKLw4WC/M2HWPJrjgys80/Kx0dLLg5OZCckY3FAgNbh/Fkl7r4uhfjDJGpjeHsYfAKMn9Ob3keOj5ZfOcTkasq6DWB0nTsJOF8TSmf4vzlLCJSDkVHR9sef/PNN7z44ovs3r3bts3Ly8v22DAMsrOzcXK6+n+HlSpVKrI+Tp8+naeeeoqPPvqIt99+264Bv4yMDFxcXK7eUETKlno9odF9sPU7+GE4jFgBbnnULLJaYf4I8w99D39IOQVLXwdrFnQab7+AUNwumHEH1O4G93xknz6UEW7Ojoy9vTZ9mlVm9f5TJKVnkZiWRVJ6Fknn74+fTWVHdAIJaVms3HeKlftOXXacBqE+9GlWhbsiQwF449edzP3nOF+sOcLCbTE836M+d0eGFv106dMHzYCUgzO0egiWvKa6UiI3ELvXlCqvEi5afU9ERIpOcHCw7ebr64vFYrE937VrF97e3vz22280b94cV1dXVqxYwf79+7n77rsJCgrCy8uLli1b8ueff+Y6bnh4OFOnTrU9t1gsfPrpp/Tu3RsPDw9q1arFggULrtq/gwcPsmrVKp555hlq167N3LlzL2szY8YMGjRogKurKyEhIbkW6jh79iz//ve/CQoKws3NjYYNG/Lzzz8DMGHCBCIjI3Mda+rUqYSHh9ueDxkyhF69evH6668TGhpKnTrm0vGff/45LVq0wNvbm+DgYP71r38RFxeX61jbt2/nzjvvxMfHB29vb9q3b8/+/fv566+/cHZ2JiYm91LlY8aMoX379ld9T0TETnq8DX5hcPYI/DIu7zZr/gf7/gQnNxj8M9z+irl9+X/MP/7tNenij+ch7RxsmQPxe+zThzKmmr8n/VuF8WD7CB6/vTYv3Fmf/9zbmA8GNmP+yHZsf7kLv/5fe/7TpxEDW4fRuIov4f4ePNwhgoVj2vPL/7Vn2M3VCfByJcDLlSl9I/nqodbUqOTJyaQMxnwTRf+P1/D1uiMcOZVSJPWrgAtT96q2guodzcfHN9rvZ1NECkURETtRoXMRuREZhkFqZrZdzu3u7Fhk364+88wzTJ48mYiICCpUqMDRo0fp3r07r7/+Oq6urnz22Wf07NmT3bt3ExYWlu9xXn75Zd58803eeust3n//fQYOHMjhw4epWLFivq+ZOXMmPXr0wNfXl/vvv5/p06fzr3/9y7Z/2rRpjB07lkmTJtGtWzfOnTvHypUrAXM12W7dupGYmMgXX3xBjRo12LFjR6FXi1u8eDE+Pj4sWrTIti0zM5NXX32VOnXqEBcXx9ixYxkyZAi//vorAMePH6dDhw506tSJJUuW4OPjw8qVK8nKyqJDhw5ERETw+eef8+STT9qO9+WXX/Lmm28Wqm8iUoLcfKHPdJjR1awtVbMzNOl3Yf+JTfDnBPNxlzcgqL55c3CC35+FvyebGVOdJ5RsxtSBZbDvwu8v1n4Id04pufOXU86ODtQP9aF+qA/9WhbsNW1rBPDb6A588vcB3lu8l7UHT7P2oFmEvLKfO+1q+tO2RgBta/gT6HONWcM5QamIThDcyPz5TI4zC/n7Vrm2Y4pIiVFQyk5ypu8pU0pEbiSpmdnUf/F3u5x7xytd8HApmt+Zr7zyCrfffrvtecWKFWnSpInt+auvvsq8efNYsGBBriylSw0ZMoQBAwYA8MYbb/Dee++xbt06unbtmmd7q9XKrFmzeP/99wHo378/TzzxhK2WEcBrr73GE088wejRo22va9nSvPr/888/WbduHTt37qR27doAREREFHr8np6efPrpp7mm7Q0bNsz2OCIigvfee4+WLVuSlJSEl5cXH3zwAb6+vsyZMwdnZ/MLlZw+AAwfPpyZM2faglI//fQTaWlp9O3bt9D9E5ESVLUVdHwalr0BvzxhPq9YHdIT4fthYM2EendBiwu/I2gz0vzD/7enYOVUMzB1x2slE5iyWuGPF873vTUcXQubv4ZbnweP/L8QEPtxcXJg5C01uatJKN9vPMaq/SfZdOQsx8+m8u2GY3y74RgAdYO96VinEp1qB9K8WgVcnAowqcdqvbDyXkQns4h/YH2I2WJmSykoJVLqafqendgypVRTSkSkxLVokXuBiaSkJMaNG0e9evXw8/PDy8uLnTt3cuTIkSsep3HjCytWeXp64uPjc9mUt4stWrSI5ORkunfvDkBAQAC33347M2bMACAuLo4TJ05w2215rxgUFRVFlSpVcgWDrkWjRo0uqyO1ceNGevbsSVhYGN7e3nTsaE6ByHkPoqKiaN++vS0gdakhQ4awb98+1qxZA8CsWbPo27cvnp6e19VXESkB7Z+AsDaQkQhzH4LsTHM63+kD4FsV7nrv8oBT639D98nm49X/NQNa1uvIpD26Hqa1g6VvXHna1dbvzICDqw/0/wqCGkFmCvzz2bWfW0zJpyB2e7EdvmpFDx6/vTbfjWjL5pfuYNbQlvy7QwQNK/tgscCumEQ+Wn6AAZ+soekrf/DQZxuYveoQf++N5+DJZNKz8vj5itkCqWewOnuxNr0aC7dFE+vTAID0IxuKboqgiBQbpenYSULa+ULnypQSkRuIu7MjO17pYrdzF5VLAyXjxo1j0aJFTJ48mZo1a+Lu7s69995LRkbGFY9zaYDGYrFgtea/ctH06dM5ffo07u7utm1Wq5UtW7bw8ssv59qel6vtd3BwuOwCPDMz87J2l44/OTmZLl260KVLF7788ksqVarEkSNH6NKli+09uNq5AwMD6dmzJzNnzqR69er89ttvLFu27IqvEZFSwtEJ7vkYpt0Mx9bDZ73g8ApzZbs+n4J7hbxf1+ohM2Pq58dhw3RIjDHbuxRyldIja+GLPmZQLHYbuHhCu9GXt8tMgyWvmo9vHgOeAXDTI/Djo7DuYzODy1Ff+F4Tw4Av7jGDPMP/hCrNi/V0nq5OdKoTSKc6gQCcSkpnxb6TLN8dz1974zmZlMGiHbEs2hGb63WB3q5UqeCOv5cr8Ynp3Hbqax4DFqfV4aFPNwDQ19GLN51h48o/Gb6yHYE+rgR5u1GlgjtVK3oQVtGDMH8PqlX0oJK3a9EXXheRQlFExE5UU0pEbkQWi6XIptCVJitXrmTIkCH07t0bMDOnDh06VKTnOHXqFD/++CNz5syhQYMGtu3Z2dncfPPN/PHHH3Tt2pXw8HAWL17MLbfcctkxGjduzLFjx9izZ0+e2VKVKlUiJiYGwzBsF9lRUVFX7duuXbs4deoUkyZNomrVqgBs2LDhsnPPnj2bzMzMfLOlHnzwQQYMGECVKlWoUaMG7dq1u+q5RaSU8Asz6zL9MNwMSIG5ul7YTVd+XYuhZtBq7sOw+xf47C4Y8A14+hfsvEfWnA9IJYFfNXMVtUUvgk9laHRv7rbrPoJzR819Nz1qbmvYB/58yawftHOB+VwK79h6iI4yH2/6rNiDUpfy93Ll7sjK3B1ZGavVYEd0Asv3xLPh0GmOnUnl2JlUUjOziUtMJy4x3fa6sc5R4AhraEQ1fw8qerpwMrEhpEIjh4OkpWdy+FQ2h0+lsO7Q5ef1cHGkW8MQBrWpRpOqfiU1XBG5SNn7y+IGkVNTStP3RETsr1atWsydO5eePXtisVh44YUXrpjxdC0+//xz/P396du372Xfynbv3p3p06fTtWtXJkyYwIgRIwgMDLQVNV+5ciWPPfYYHTt2pEOHDvTp04cpU6ZQs2ZNdu3ahcVioWvXrnTq1In4+HjefPNN7r33XhYuXMhvv/2Gj4/PFfsWFhaGi4sL77//PiNGjGDbtm28+uqrudqMGjWK999/n/79+zN+/Hh8fX1Zs2YNrVq1sq3g16VLF3x8fHjttdd45ZVXivT9E5ES0Ohe2L8Eor6E8PbmtL6CaNALvALh6wFmcGP67XD/D2Ztqis5vAq+uBcyk6F6BzOYteRVc8W/+Y+AVxBUP7+CZ8pp+Ott8/Etz5m1gwCc3aDFcFg+CdZMU1DqWm2cfeHxtnnQ9T/me2sHDg4WGlb2pWFlX9s2wzA4k5LJsTMpHDuTyqnkDILc4eYFeyAbnn/sEV4IrGs2tt4EE5/FOzOZFcOqctw5jJiENI6dSeHo6RSOnE7h8KkUTpxNJSUjmx/+OcYP/xyjSRVfBrUJp0fjENzOZ2dnZVvZdiKB1ftPsfrAKXZGJ9Aw1IfujUK4o34wvh76W07keikoZScJ5zOlVOhcRMT+pkyZwrBhw2jbti0BAQE8/fTTJCQkFOk5ZsyYQe/evfOcJtCnTx8eeOABTp48yeDBg0lLS+Odd95h3LhxBAQEcO+9F7IFfvjhB8aNG8eAAQNITk6mZs2aTJo0CYB69erxv//9jzfeeINXX32VPn36MG7cOD7++OMr9q1SpUrMmjWLZ599lvfee49mzZoxefJk7rrrLlsbf39/lixZwpNPPknHjh1xdHQkMjIyVzaUg4MDQ4YM4Y033mDQoEHX+5aJiD3cORVq3Q41bgOHQkybrtYWhv9hZj2d3m8Gpv71LVRulnf7Qyvgy75mQCqiE/T/2pz2d8frcO6YmfU0ZyAM/x0C68FfkyH9HAQ1hCb9cx+r5XBYMcUMiB1dD1XzWBrOajWPGVALghpcvr88S0uA7XPNx84e5vu8+1doeI99+3URi8VCRU8XKnq60LiKn7nxwHLITgfvECyV6lxo7OAIIU3gyCoqp+ygcmRknsfMzLay5dg5vlxzmJ+3RLP52Dme+G4zr/+6kzsbh3DsTCrrDp4mKT0r1+uW7o5n6e54nnXcSruaAXRvFEIXBahErpnFUPW3yyQkJODr68u5c+eu+u3ytcjKtlLzud8A2PTC7VTwdLnKK0RE7CMtLc22Mpybm32+MZUby/Dhw4mPj2fBggX27kqhXOlnvbivC8oSvVdCQjR8eR/EbgVnT4gcYBZL961y/r4ynNpnZlVlpkCNW82C5c4X1a3LTDXrWh1dAz5VzDpVs3uaKwHePxdq5rEYxPxHzQyvhn3g3hm592WmmplX2+eZfXposRnoEtOGGWZdsIA6UO9O+PttqNUFBn5r755d2Z8vm8HIJgOg94e59/3+nFmAv+WD0OPtqx7qZFI636w/ypdrDnPiXFqufT5uTrSO8KdNhD/1Q31Ye+A0v26NZndsoq2No4MZNPN2c8LHzRkfd2d83JzwdnPGw8URN2cH3JwccXN2xM3FEXdnRyp6OlPJy41AH1f8PV1wctQaZFK2FPSaQGk6dpCYdiHa7qVMKRERKQPOnTvH1q1b+eqrr264gJSIFCGfEBj6K3w7CA4shfWf5t+2Zmfo9+Xl08Sc3WHA1zD9Dji1F2Z1B8MKEbfkHZACaD3CDEptnw+3v2oGvwCS4mHO+WmFYGZmzfkXPLQU3P2ud7RlQ87Khc0GQe0uZlBq35+QFGdOyyytDiwz7yM6Xb4vJ0Pv+D8FOlSAlysjb6nJvztEsHhXHMt2xxMR4EmbGv7UC/HB0eFClvNNEf6M7lyLfXGJ/LIlxhagik9MJ/6ieleFYbFARQ8XKnm7UtHThQqeLlTwcKaihwt+Hi5U8HTGz90FXw9nfN2d8XM3A1/OCmRJGaCIiB3kBKU8XBz1i0RERMqEu+++m3Xr1jFixAhuv/12e3dHROzJzcecurd9HpzcbU7Hy7klHAdrFtS9E/pMz79ukUdFuP97+PR2SI4DLHD7FWrVhTQ262Ad+hvWfwKdJ0D8bjNr6+xhcPOFu96H35+H0wdg7kMwYE7+UxRPH4Sf/g9O7jNXJ3RwNlf2c3A2n9e6Azo+Aw43+LV89BY4sckcV5P+5oqGlVvA8Q2w9Xto86i9e5i31DNmvwGqd7x8f+XzhdpjtkJWOji5FuiwTo4OdGkQTJcGwVdtWzPQm9GdvRnduRYx59I4lZxOYloWCamZ5n1aJgmpWaRmZpOWmU16VjapGdmkZVpJzsjidHIG8YnpnExKx2rAqeQMTiVfedXfS3m5OlEz0Ivm1SrYbkE+hc9sT0rPwtnRgqtT0a10LFJQCkrZgepJiYhIWbNs2TJ7d6Hc+eCDD3jrrbeIiYmhSZMmvP/++7Rq1Srf9t999x0vvPAChw4dolatWvznP/+he/futv1Dhgxh9uzZuV7TpUsXFi5cWGxjkDLMyQWa9Lt8uzUb0hMLlqVUIdycQvbdEKh/txl4upKbHjGDUhtmQtWbzBUB08+dP873Zj2pCuFmBtbeP2DZRLj1+cuPc/BvM9Mr9XT+5zqxCbLSrhwouxHkZEnVu9MMSIEZnDq+ATZ/VXqDUgf/AgyoVNfMzruUXzXw8IeUUxCzrdhXEwz2dSPY99rKHGRbDVuAKj4pnTPJGZxOzuBsSgZnUjI5nWI+PpuSyblU85aT5JCUnkXU0bNEHT3L9BUHAajs507zahVoVb0i7WoGEO7vkWc9y6T0LH7fFsP8qOOs3HcSd2dHOtUJ5I4GQdxSN1CrxEuJUVTEDnKCUvqHLiIiItfim2++YezYsXz44Ye0bt2aqVOn0qVLF3bv3k1g4OXTbVatWsWAAQOYOHEid955J1999RW9evXin3/+oWHDhrZ2Xbt2ZebMmbbnrq4Fyy4QKTAHx8JNmwttCqM3F6xt7a5m0OnMIfj6fECsamuzZlVOwCWkCfR8D+Y9DH+9ZT6v1/PCMTbMgF+fNLO5QptC10lgcTTrWVmzIDvTzL758yVY+S54h8JNIwo+ntIkIwW2nK8b1eyixSka9oGF481xxmyD4IZ5vz4/malm8NHVq+j6eqkrTd0Dcz5caDPYtwhO/FPsQanr4ehgoZK3K5W8C/77NttqkJCayankDLafOMfGw2fYePgMO6MTOH42leNnU1mw+QQAob5utK0ZQNsa/rSO8Gd3TALzNp1g0Y4Y0jIvrDScnJHNL1uj+WVrNM6OFtrUCKBLgyACvd2ITUgjNiGNmHNpxCamE5eQRnJGFlaruTKi1QDr+ft6Id6Mvq0WLcIrFvl7JWWTglJ2kJBqRraVKSUiIiLXYsqUKTz00EMMHToUgA8//JBffvmFGTNm8Mwzz1zW/t1336Vr1648+eSTALz66qssWrSI//73v3z44YUCwa6urgQHX33aikip5OBo1pZaeP7fQMM+cPf/Lp8i2KQfREfBmv/BvBEQUBsqRpiBmPWfXPTaD3IXYM9R8zYwsmHxK+a5vIOhQa/iHFnx2LnAzCTzC4PqnS5s96gIdbrCzp9gyxwIfi3v18duh6ivIDEGkmLNW2KseUyLAzToDe1Gm4G/ona1oBSYU/j2LYLjG4GHir4PduToYDHrTnm6UDPQi7sjzRpqSelZbDl6lvWHzrBq/0k2HTnLiXNpfL/xGN9vPHbZcSICPLk7sjJ3R4ZyLjWT37fH8Pv2GPbHJ/PXnnj+2hNf6L79vTedv/eepGPtSjxxR+0LqyWK5ENRETuwZUq5K1NKRERECicjI4ONGzcyfvx42zYHBwc6d+7M6tWr83zN6tWrGTt2bK5tXbp0Yf78+bm2LVu2jMDAQCpUqMCtt97Ka6+9hr+/f759SU9PJz39QmHfhISEaxiRSBFqNhhO7gH/mtD6kfxrPt3+ipkJdOhvs/C5T2U4uNzcd+sL0P4JM9smPzePhYQTZiH3uQ+bBcGrtb2+vifFw66fYNcvZjCs07MQVP/6jnklG89P12066PL3qcmA80Gpb+G2CWYdrYtFb4aZPSAjkTwZVtj2g3mLuMUMTkV0uvJ7WlBnDpt1wSyOUK1d/u1y6kod33j957xBeLk6mVlRNQMY3bkWqRnZrD90mpX7T7Jq3ym2nTiHv6cLPZuE0iuyMo2r+Oaa2tekqh9Pda3Lvrgk/tgRw5KdcWRkWwnycSPYx40gH1fzsa8bnq5OOFgsOFjAwWLBYoGsbIM564/y3YajLN8Tz/I98XRpEMTY2+tQJ9jbju+MlGYKStlBzhxgTd8TERGRwjp58iTZ2dkEBQXl2h4UFMSuXbvyfE1MTEye7WNiYmzPu3btyj333EP16tXZv38/zz77LN26dWP16tU4OuZd/HbixIm8/PLL1zkikSLk4gF3vnP1do7OcO9M+LgTnNpn3pw94Z6PzfpKV2OxQLc3zSyhXT/D1/1h2B8QWNfcb7XC0TXmaoC7fobMFAhqCMGNzdpYwY3MDK2U02bG0o4f4fBKM5iTY9evZk2njs8U/VS4k3vhyCozoynyX5fvr3k7uFc0s58OLINanS/sO7UfvuhjBqSqtDTrfXkFg3cQeJ2/nT0Cq96DbXPNVRgPLDXHfvPjZgbV9QSncoKHVVqYRfXzk7MC38m9kHbOLHZfzri7ONKhdiU61K4EQGpGNi5ODrlWE8xLzUAvagbW5NFONQt9ziZV/RjRMYJ3F+9l/qbj/L49lj92xFI70JvMbOv5ou/mfVqWFScHCxU8XPDzcKbC+ZUGfd1d8HRxxGIBy/mAlwXz3tnBgquzI65ODhfunRwI9HajaZgfbs4q1n6jUVDKDhJSVehcRERESpf+/fvbHjdq1IjGjRtTo0YNli1bxm233Zbna8aPH58rAyshIYGqVasWe19FioRXJej/Bcy+C9wrmLWnClM/ycER+nwKn90NR9eagZoek2H/EtixAJJicrc/9Ld5y+HoCtkZgHFhW2hTqHeXmd2z62dY9b4Z2Ok60dxemGCOcf64eb3mn/NZUrXuAN/Kl+93coFG98G6j2Dz1xeCUgnR8HkvSI43A2v3/5B3sMfdz3xvbn3BnCb5z2cQswW+HwqHVkD3yde2cmHySVhxPuh4pal7YNYR8wszA2QnoiAij1X6yhl3l3wCNgf/Bp9Q8K9RJOep5u/JlL6RPNqpBu/8uZdftkSzOzbvrLpsq0FMQhoxCWnXfV4XRwciw/xoE+HPTRH+ClLdIBQVsQNbppSm74mIiEghBQQE4OjoSGxsbK7tsbGx+daDCg4OLlR7gIiICAICAti3b1++QSlXV1cVQ5cbW2hTeHw7OHtcPkWtIJzdYcAcmNHFnDb49YXgLm6+UKeHWW/KO/h84fCtEL3FvM+Z+la5hZltVP8us1B7jj2/m0XXzx42VwOs2RnajDKzfpJiITHarOGUGA2pZ8xsrMzU3PduvlC3JzS8B6p3NMeYlQFRX5vnuLjA+aWa9DeDUrt+hrQEs47WF33MIE+F6nD/3KtnH1WoBt3+Ax2fNoNTf02GDdPNlQvvet8M7BVURgp81decuucbBi0LUCeqcnOzv8c3KiiVn12/mFNYPQJg5DrwzH/KdmHVDPTmg38144nbkzh2JhU3Z0fcnB1wdbpwn5lt5cz51QUvvk/NzAbDDNnmFFM3DMiyWknPtJKedVHGVaaVAyeTiE1IZ93B06w7eJp3F+/FxcmBeiE+hJyfcmhOPTSnIFat4EGVCu55rkwoJUtBKTvIqSmlTCkRkdKrU6dOREZGMnXqVADCw8MZM2YMY8aMyfc1FouFefPm0atXr+s6d1EdR8omFxcXmjdvzuLFi20/I1arlcWLFzNq1Kg8X9OmTRsWL16c6+d30aJFtGnTJt/zHDt2jFOnThESksdy6yJlyZWmgBWER0UzY2hWDzNgVPdOqN/LzORxcrnQ7uKC31arGWxycjUzVPJSuwuEt4cVU8yV/vb9ad4KI+0cRH1h3jwCzk+1C4SUk+Y0u1p35P/a0KYQUAdO7obNc8z6UHHbzdc9MM88TkF5VIRbn4dKdc0aXFFfmoGzez42p1JeTXYWfD/MDC65VzDfb69KV39daDPYPs9cgU8ul3YOfnnCfJxy0izc3+eTIj9NRCUvIirlPwW1akWP6z6HYRgcOpXCmgOnWHPgFKv3nyIuMZ3NR8+S3/qdFTycaVzFjyZVfGlcxY/GVX3x93Tl+JlUDpxM4tDJZA6dSuHAyWTiEtLIzLaSmW2cv7eSkWXF2dGBiEqe1Az0okYlL2oGelEryJtQXzcFvApIURE7SMwpdK6aUiIiRa5nz55kZmaycOHCy/b9/fffdOjQgc2bN9O4ceNCHXf9+vV4enoWVTcBmDBhAvPnzycqKirX9ujoaCpUqFCk58pPamoqlStXxsHBgePHjyvr5QYxduxYBg8eTIsWLWjVqhVTp04lOTnZthrfoEGDqFy5MhMnTgRg9OjRdOzYkbfffpsePXowZ84cNmzYwMcffwxAUlISL7/8Mn369CE4OJj9+/fz1FNPUbNmTbp06WK3cYrcMPzC4LFN5lS5gmT/ODhAxepXb+fiYQZzGveHRS+YK955B5uBIe8Qs46Tdwh4+JvZXs4e5muc3c3HJ/eY0/92zDeDDhumXzh25MArB4QsFjNbavHLsPBps96Vq6+ZIVWQvuel0b3g6GIGmLbPNTOm7ptlBufyYxjw6zjY8xs4uZmZaZVqF+x8tmLnCkrladGLZqadT2Xzfuu35mdU+8b7vW+xWKge4En1AE8GtArDMAwOnkxmT2wSseenB8aeS7NNFTx6OoUzKZm2guw5HB0sZFuNK5zpcqeSM1h/6EyubS6ODni7OZ2/OePlaj4O9HGla4MQ2tTwv2Jtr5NJ6fwYdYI9MYm0qxXA7fWC8p9+eYNTUMoOElLN6XvKlBIRKXrDhw+nT58+HDt2jCpVquTaN3PmTFq0aFHogBRApUoF+Ea2iFxpSlVR++GHH2jQoAGGYTB//nz69etXYue+lGEYZGdn4+Sk/x+vpl+/fsTHx/Piiy8SExNDZGQkCxcutBUzP3LkCA4X1Wtp27YtX331Fc8//zzPPvsstWrVYv78+TRsaNbPcXR0ZMuWLcyePZuzZ88SGhrKHXfcwauvvqpApUhBXcv0v4IKqAkDvi7867wCIfxmsyj7weVmgGrnT2ABmg+5+usb94PFr5gBKSc3+NecwtXdykv9u8z6Xd8+ALt/Nac89vvSDKbl5e/JsHEmYDHrVIXdVPBzhTQxi7knHDeL0nuX3P+vRSp2hzm1M7/36FocWgEbZ5mP7/nE/CxW/xd+fhweXXP9GYR2ZrFYrpihlZ6Vzc7oRLYcO8vmo+fYcuws++KTyLYauDg5EO7vQbi/J9UreVLd35NQP3dcnRxwdnLAxdEBZ0cHnBwtpGZksz8+iX1x5m1vnJlhlZFt5VRyBqeSMy479xdrjhDk40qvyMr0blaZusE+tj4t2RnHD/8cY9nueLLOB8e+2XAUTxdHujQI5q7IUG6uGYCTo/l/fGpGNluPnyPq6Bmijp7l0MkUQv3cCPf3JPx8kC48wJMQHzccrlLg3l4shmEULgxYDiQkJODr68u5c+fw8Sn6f4x3vv83244nMHNoS26pU4i0VxGREpaWlsbBgwepXr06bm5u9u5OgWRlZVGlShVGjRrF888/b9uelJRESEgIb731Fvfddx+jRo3ir7/+4syZM9SoUYNnn32WAQMG2Npfbfre3r17GT58OOvWrSMiIoJ3332XO+64I9e0u6effpp58+Zx7NgxgoODGThwIC+++CLOzs7MmjXLltWSY+bMmQwZMuSy6Xtbt25l9OjRrF69Gg8PD/r06cOUKVPw8jIvtIYMGcLZs2e5+eabefvtt8nIyKB///5MnToVZ+crZ+Xecsst9O/fH8MwmDt3Ln/88Ueu/du3b+fpp5/mr7/+wjAMIiMjmTVrFjVqmMVQZ8yYwdtvv82+ffuoWLEiffr04b///S+HDh2ievXqbNq0icjISADOnj1LhQoVWLp0KZ06dWLZsmXccsst/Prrrzz//PNs3bqVP/74g6pVqzJ27FjWrFlDcnIy9erVY+LEiXTufGH1p/T0dF588UW++uor4uLiqFq1KuPHj2fYsGHUqlWLESNGMG7cOFv7qKgomjZtyt69e6lZ8/LVhK70s17c1wVlid4rkRtAdiZYs8G5gP+vfzsY9iw0M5rqdCu6fhxYbgakMlOg6k3Q7AGoGGHWq/IONjO1or6C+Y+Y7bu9Ba0fLvx5/tcG4nZA74/MzK+iknIajqyGw6vMjLQat0GLYbmnbF6v9ERzet2Wb8C/Jgz6EXyrXP11qWfB1Tv/rL3MVJjW1qzP1WKYuWJlRoq57czBC9vKmaT0LBJSMwnycbvqCoVXkpltJTYhjcS0LJLSs0hMyyQxLYvEtCx2RCfwy5Zozp1f/AygXogPDUN9WLQzlrMpF7Y3qeJL07AKLN4Vy9HTqbbtAV4utKkRwP64JHbHJhYos8vTxZH7WlTlkU41CPIpmWv6gl4T6KtIO8jJlNL0PRG54RiGefFoD84eBVp1yMnJiUGDBjFr1iyee+4523z+7777juzsbAYMGEBSUhLNmzfn6aefxsfHh19++YUHHniAGjVq0KpVq6uew2q1cs899xAUFMTatWs5d+5cnrWmvL29mTVrFqGhoWzdupWHHnoIb29vnnrqKfr168e2bdtYuHAhf/5p1gjx9b28YGxycjJdunShTZs2rF+/nri4OB588EFGjRrFrFmzbO2WLl1KSEgIS5cuZd++ffTr14/IyEgeeij/QrD79+9n9erVzJ07F8MwePzxxzl8+DDVqlUD4Pjx43To0IFOnTqxZMkSfHx8WLlyJVlZ5v9j06ZNY+zYsUyaNIlu3bpx7tw5Vq5cedX371LPPPMMkydPJiIiggoVKnD06FG6d+/O66+/jqurK5999hk9e/Zk9+7dhIWFAeb0tNWrV/Pee+/RpEkTDh48yMmTJ7FYLAwbNoyZM2fmCkrNnDmTDh065BmQEhEpVxydC1bHKce9MyEjqegzZyI6mrWpvrwPjq4xbzmcPczMoJN7zOftRl9bQArMKXxxO2Dev+HvKVCvp3kLaVK41QwTY8xA2pFVcHi1WWvrYnv/gLUfQueXzJpi11tP6MQmc5rj6QPm81P7YEY3GDQ//1XyDMPMdvpzgvn+9foQqra8vN2yieZxvUOh88vmNhcPuOs9mN0TNsyAhn3MLLvikpVu9gOLWQi/oEHSYuTl6oSX6/WHSJwdHahSIf+stpd61mfprjjmbTrOkl1x7IxOYGd0AgBBPq70blqFPs0qUyvI29b+nyNn+DHqBD9vieZkUgY/bT5hO16gtyuRVf2IDPOjZiUvYhPSOHgyhUOnkjl0Mpkjp1NIzshm1qpDfLXuCP9qFcaIjjUI9rX/ew7KlMpTcX/LF/nKH5xNyWTR4x1sP2giIqXRZdkjGcnwRj4FWYvbsyfApWA1nXbt2kW9evVsGTkAHTp0oFq1anz++ed5vubOO++kbt26TJ48GbhyptQff/xBjx49OHz4MKGh5vuxcOFCunXrdsUC5ZMnT7bV8oH8a0pdnCn1ySef8PTTT3P06FFbTatff/2Vnj17cuLECYKCghgyZAjLli1j//79ODqa34r27dsXBwcH5syZk+/79Nxzz7Fjxw7mzZsHQK9evYiMjGTChAkAPPvss8yZM4fdu3fnmXFVuXJlhg4dymuvvXbZvsJkSs2fP5+77747334CNGzYkBEjRjBq1Cj27NlDnTp1WLRoUa7sqRwnTpwgLCyMVatW0apVKzIzMwkNDWXy5MkMHjw4z+MrU6po6L0SkUKL3QHrP4XT++H0QTh31JwumKNRXzPL6aIpyYVyar9ZwHv/UrBeyELBNwzq9jCnI/pVM4M4PqEXsosyUswsqP1L4MBSM7B1qUp1zemEvlVg7ceQHGdur9wC7ngNquW/mES+DMNcqXDRS2Z/fapAl9dgyWtmYMorCB6YD0H1c78u9QzMHwm7f7mwzeIA7cZAp2cu1O06EQWf3GqupjhgzuXZbz+NNqf1VYyAESuLdspgjuRT8M1AM9MMICQS+n1u1mYrZ86mZPDzlmgOxCfTqU4l2tUMuGKWVma2lRV7T7Ll2DlqBXkRWdWPkKsUVc/KtrL6wCneW7zXVvvKxcmBAS2r8kinmsUWnFKmVCllGAaJaeczpdyVKSUiUhzq1q1L27ZtmTFjBp06dWLfvn38/fffvPLKKwBkZ2fzxhtv8O2333L8+HEyMjJIT0/Hw6NgF147d+6katWqtoAUkOcqZt988w3vvfce+/fvJykpiaysrEL/ob5z506aNGmSq8h6u3btsFqt7N6921ZDqEGDBraAFEBISAhbt27N97jZ2dnMnj2bd99917bt/vvvZ9y4cbz44os4ODgQFRVF+/bt8wxIxcXFceLECW677bZCjScvLVq0yPU8KSmJCRMm8MsvvxAdHU1WVhapqakcOXIEMKfiOTo60rFj3st7h4aG0qNHD2bMmEGrVq346aefSE9P57777rvuvoqISBELqg93TrnwPCvDDEydPgjpCWZW07UGpMDMKhr4nbnS3J4/YOcCcxXDc0dg7bTcbR2cwa8quFeEmC2QfXE9IIuZXRV+M1Rra0459PS/sLv1I2aW0sr34PgGmNkV6vSAlsMhrE3BgjvJJ83pinvPT6Wveyfc9b65emG1dvBZL3MFxFndzRUILy7k/t0Qc0VHRxcz+yl6M2yZY67euOd36P0hBNaDBaPMgFSDe/Kejnn7K+b7dPqAmcl0x6sFe5/PHjGnW7p4QbNB+WfWxe+Br/qa0wRdfcDBCaKj4KOOcO90qHFrwc5XRvh5uHD/TdUK3N7Z0YFb6gZyS92ClwFycnSgfa1K3FwzgNX7T/HOn3tYf+gMs1cf5ut1R3n0lhqM6VzAxQOKgYJSJSwlI9s251OFzkXkhuPsYWYs2evchTB8+HAee+wxPvjgA2bOnEmNGjVsQYy33nqLd999l6lTp9KoUSM8PT0ZM2YMGRmXF6O8VqtXr2bgwIG8/PLLdOnSBV9fX+bMmcPbb79dZOe42KWBI4vFgtVqzac1/P777xw/fvyywubZ2dksXryY22+/HXd393xff6V9gK3I9sUJ2ZmZmXm2vXRVw3HjxrFo0SImT55MzZo1cXd3595777V9Plc7N8CDDz7IAw88wDvvvMPMmTPp169fgYOOIiJiR04uZiApvylq18rNFxrfZ94yUswMqP1LzODImcNmUMWaeX663Pkpcz5VoMYtZqAkopMZHMqPq5eZkdR8CCybBP98ZmYt7f7FDBRVbW1OWYy4xcwMys6AU3shfjfE7zLvj6yGlFPg6ApdXoeWD16YBugVCEN+Nqc7Ht8As+82C8/H7YTfnzWP51cN+s6G0Kbma+r2MAuXx22HT24xA2oxW8G9gln8Pr/36c4pZr2v1f+FBr0uBL/ycvwfWPU+7PjRDHaBWZy+zSho/W+ztlWOA8vNAvdp58ysqH99ZwbrvnnADEx90QdufQFufvz6pz+WVoZxfWMzDNj2AxxYBlVbmYHLK/1cApw5BCf3YglrQ9uaAbSp4c/q/aeY+ude1h06jbedywopKlLCcrKknBwsuDuXzSUdRaQMs1gKPIXO3vr27cvo0aP56quv+Oyzz3jkkUdsqc0rV67k7rvv5v777wfMGlF79uyhfv36VzqkTb169Th69CjR0dGEhIQAsGbNmlxtVq1aRbVq1Xjuueds2w4fPpyrjYuLC9nZ2Vc916xZs0hOTrYFb1auXImDgwN16tQpUH/zMn36dPr375+rfwCvv/4606dP5/bbb6dx48bMnj2bzMzMy4Je3t7ehIeHs3jxYm655ZbLjp+zWmF0dDRNm5oXx5dOU8zPypUrGTJkCL179wbMzKlDhw7Z9jdq1Air1cry5cvznL4H0L17dzw9PZk2bRoLFy7kr7/+KtC5RUSkHHDxgHp3mrcc1mxIOGFmGyXGmFlR/jULH0DwDoaeU+GmR8xgzf6lkHAMDv1t3pa8Zn7RlpkK5FFJJ6AO3Dsj71UOPSqaNaW+HmAea3bPC1Md6/SAXh+YAacc9e8ys7R+edxcdfHAMnN710ngdYVVhet0g4b3wrbv4dPbzWmKoZHmexISaWa3HVphju/wRbUkw9tDUqxZC2zJq7D6A2j3f9DyIdg+D34eA9YsqNLKXIExpw/Dfodfx8Gmz2Hxy3B8I/SaduU6ZqlnzemVOe9rZqo5bbJqKzMAGFgv/0Lv9nAiCv58CY5vgptHQ5vHCl8UP3Y7/Prkhfd80+fw81gzaNqwj/m5uflAZhocXgF7/4R9i8xpnwBuftD631ha/ftCcOrAKZqFVcj3lCVBQakSlpBmfkvs7eZ0xXmfIiJyfby8vOjXrx/jx48nISGBIUOG2PbVqlWL77//nlWrVlGhQgWmTJlCbGxsgYNSnTt3pnbt2gwePJi33nqLhISEy4I7tWrV4siRI8yZM4eWLVvyyy+/2Go35QgPD+fgwYNERUVRpUoVvL29cXV1zdVm4MCBvPTSSwwePJgJEyYQHx/PY489xgMPPGCbuldY8fHx/PTTTyxYsICGDXNf9A4aNIjevXtz+vRpRo0axfvvv0///v0ZP348vr6+rFmzhlatWlGnTh0mTJjAiBEjCAwMpFu3biQmJrJy5Uoee+wx3N3duemmm5g0aRLVq1cnLi4u12qIV1KrVi3mzp1Lz549sVgsvPDCC7myvsLDwxk8eDDDhg2zFTo/fPgwcXFx9O3bFwBHR0eGDBnC+PHjqVWrVp7TK0VERGwcHM2pe35Vi+Z4lerA3f81M1tOHzDrUh1YBgf/hrSzZhv3ClCpntm2Ul3zvlrbC/Wf8uLqbU5H/HYw7P3dnP7W+WVoMzLvAJpXJej7OWz9zqxTVb09NO53ebtLdfuPWcw9ZquZaRW3HaK+vLydg5MZEGkzCkIam8G9bT/A8v+YwZA/J8Df70D6ObN9wz5w9/9yFzZ3djPfqyotzKDLrp/h7SVmjS+vYPAOunCfHG++hzFbctceA/N8W87X0nTxNo9XrR3Uvxsq2Wl62tkjZiByyzcXti1+BTbPge6Tzey5q0k9a2bfrfvYzEZzcofGfeHYBvNz2fu7eXN0NQOHMVsh68JqfTg4gUcAJMWYn8vK96D5YCxtRtK2hv3reCkoVcISzwelVE9KRKT4DR8+nOnTp9O9e/dc9Z+ef/55Dhw4QJcuXfDw8ODhhx+mV69enDt3rkDHdXBwYN68eQwfPpxWrVoRHh7Oe++9R9euXW1t7rrrLh5//HFGjRpFeno6PXr04IUXXrAVEQfo06cPc+fO5ZZbbuHs2bPMnDkzV/AMwMPDg99//53Ro0fTsmVLPDw86NOnD1OmTOFaffbZZ3h6euZZD+q2227D3d2dL774gv/7v/9jyZIlPPnkk3Ts2BFHR0ciIyNp164dAIMHDyYtLY133nmHcePGERAQwL333ms71owZMxg+fDjNmzenTp06vPnmm9xxxx1X7d+UKVMYNmwYbdu2JSAggKeffpqEhIRcbaZNm8azzz7Lo48+yqlTpwgLC+PZZ5/N1Wb48OG88cYbDB069FreJhERketnsVyYjtjyQTNoc3IvePiDZ8C1TeVydof+X5o1nEKamFlMV+tD477Q6L4Lz6/GMwD+/beZPRYdZdaoOnH+PinGrAfVfAi0HgG+lS+8zsHRPFeDe8xA2PL/mFMkwVxlr9P4/M/ffAgENYLvBpt1xU7tu5Dlk5eKNcwgW3h7c9rhsfVwdK0ZrMlIPB8IXApLX4OghtCgNzS8xyzifr2sVrOPqafNz9IjIHfdsNQz8PfbsPajC7XJGt1nZq4tm2hmk312l5mR1uV1M8PuUlnpZoBv0YtmMA6g3l1m+5yi8HG7YPtcs92pfXBsnbndOxRqdYaat5uBLxcvM1tuxTvm57n2Q3OBgUb3matbBta7/vfkGmn1vTwU58oxS3fFMXTWehpV9uWnx4pxiU0RkSJwpRXJREq7v//+m9tuu42jR49eNatMq+8VDb1XIiLlQFK8WUPL+eo1HsnOMovLu/lCzQIujpKdadb5Sow2pwMmxpiBsMQY85zVbjaDUT75rAhtzTZXSzy6FnYvNANT1qwL+0Mizb54+JvBNTdfc9qbq495/OxMs75YduaFxymnzWDiyT3m/al9ubORAJw9zeL3npXMVR9zMuLC25sF5Cs3M5+nnoWlr5tBIcNqZnXd9IiZBXX2yIVbYvSFY/vXgu5v5l8I3jDMDKnozeZ5AuvnHfwzDDNjb8U7cHC5ua1RX+jzyZU/k2ug1fdKqYun74mIiEjRS09PJz4+ngkTJnDfffdd8zRHERERycOV6lFdytHJzE4qDEdnCKhp3q6FgyMENzJvLR80A0o7fzLrWh3863zmV9S1HTvXeZzNjLKUU2Y2VGYynE02A0pgTsm8/RWodUfuAJG7H3R/CyIHwi9jzRpaf+VTeN69gln4vfUjV65BZbGY0ydDGl+5zxbL+eL9t5jnXfEO3DymMKMucoqMlDDDgIqeLlTwLGRRMxERESmQr7/+muHDhxMZGclnn31m7+6IiIiIPXlUhOaDzVvySTNzK2YrpCVAeoK5GmDa+fusNHO1REdnsxZTzmNXb7PwfUDt87da5mqHjk7mH/npieYUu5RT5r2Ds5nV5HiFkEtoJAz/E6K+gL2LwCvInJZnu1Uz+15ctagrN4d+XxTPsQtB0/fyoNRzERGTpu9JeaHpe0VD75WIiIhAwa8JHEqwTyIiIiIiIiIiIoCCUiIiIiIiIiIiYgcKSomIyFVppreUdfoZFxERESl5CkqJiEi+nJ2dAUhJSbFzT0SKV87PeM7PvIiIiIgUP62+JyIi+XJ0dMTPz4+4uDgAPDw8sBTXCiAidmAYBikpKcTFxeHn54ejo6O9uyQiIiJSbigoJSIiVxQcHAxgC0yJlEV+fn62n3URERERKRkKSomIyBVZLBZCQkIIDAwkMzPT3t0RKXLOzs7KkBIRERGxAwWlRESkQBwdHfWHu4iIiIiIFBkVOhcRERERERERkRKnoJSIiIiIiIiIiJQ4BaVERERERERERKTEqaZUHgzDACAhIcHOPRERERF7y7keyLk+kPzpGkpERESg4NdPCkrlITExEYCqVavauSciIiJSWiQmJuLr62vvbpRquoYSERGRi13t+sli6Gu/y1itVk6cOIG3tzcWi6XIj5+QkEDVqlU5evQoPj4+RX780kbjLfvK25g13rKtvI0Xyt+YCztewzBITEwkNDQUBwdVPriS4ryG0s9p2Vfexqzxln3lbcwab9lXmDEX9PpJmVJ5cHBwoEqVKsV+Hh8fn3Lzwwsab3lQ3sas8ZZt5W28UP7GXJjxKkOqYEriGko/p2VfeRuzxlv2lbcxa7xlX0HHXJDrJ33dJyIiIiIiIiIiJU5BKRERERERERERKXEKStmBq6srL730Eq6urvbuSonQeMu+8jZmjbdsK2/jhfI35vI23rKivH1u5W28UP7GrPGWfeVtzBpv2VccY1ahcxERERERERERKXHKlBIRERERERERkRKnoJSIiIiIiIiIiJQ4BaVERERERERERKTEKShVwj744APCw8Nxc3OjdevWrFu3zt5dKjJ//fUXPXv2JDQ0FIvFwvz583PtNwyDF198kZCQENzd3encuTN79+61T2eLwMSJE2nZsiXe3t4EBgbSq1cvdu/enatNWloaI0eOxN/fHy8vL/r06UNsbKydenx9pk2bRuPGjfHx8cHHx4c2bdrw22+/2faXpbHmZdKkSVgsFsaMGWPbVtbGPGHCBCwWS65b3bp1bfvL2ngBjh8/zv3334+/vz/u7u40atSIDRs22PaXpd9b4eHhl32+FouFkSNHAmXv883OzuaFF16gevXquLu7U6NGDV599VUuLqVZlj7f8qCsXkPp+knXT2VlrHnR9VPZGy+Ur+sn0DVUsV9DGVJi5syZY7i4uBgzZswwtm/fbjz00EOGn5+fERsba++uFYlff/3VeO6554y5c+cagDFv3rxc+ydNmmT4+voa8+fPNzZv3mzcddddRvXq1Y3U1FT7dPg6denSxZg5c6axbds2IyoqyujevbsRFhZmJCUl2dqMGDHCqFq1qrF48WJjw4YNxk033WS0bdvWjr2+dgsWLDB++eUXY8+ePcbu3buNZ5991nB2dja2bdtmGEbZGuul1q1bZ4SHhxuNGzc2Ro8ebdte1sb80ksvGQ0aNDCio6Ntt/j4eNv+sjbe06dPG9WqVTOGDBlirF271jhw4IDx+++/G/v27bO1KUu/t+Li4nJ9tosWLTIAY+nSpYZhlL3P9/XXXzf8/f2Nn3/+2Th48KDx3XffGV5eXsa7775ra1OWPt+yrixfQ+n6SddPZWWsl9L1k6msjbe8XT8Zhq6hivsaSkGpEtSqVStj5MiRtufZ2dlGaGioMXHiRDv2qnhcelFltVqN4OBg46233rJtO3v2rOHq6mp8/fXXduhh0YuLizMAY/ny5YZhmONzdnY2vvvuO1ubnTt3GoCxevVqe3WzSFWoUMH49NNPy/RYExMTjVq1ahmLFi0yOnbsaLuoKotjfumll4wmTZrkua8sjvfpp582br755nz3l/XfW6NHjzZq1KhhWK3WMvn59ujRwxg2bFiubffcc48xcOBAwzDK/udb1pSXayhdP5XN/28upeunsjVmXT/lVh5+b+kaqmg/Y03fKyEZGRls3LiRzp0727Y5ODjQuXNnVq9ebceelYyDBw8SExOTa/y+vr60bt26zIz/3LlzAFSsWBGAjRs3kpmZmWvMdevWJSws7IYfc3Z2NnPmzCE5OZk2bdqU6bGOHDmSHj165BoblN3Pd+/evYSGhhIREcHAgQM5cuQIUDbHu2DBAlq0aMF9991HYGAgTZs25ZNPPrHtL8u/tzIyMvjiiy8YNmwYFoulTH6+bdu2ZfHixezZsweAzZs3s2LFCrp16waU7c+3rCnP11Dl4edU109lc6y6ftL1U1n9vaVrqKL/jJ2KpttyNSdPniQ7O5ugoKBc24OCgti1a5edelVyYmJiAPIcf86+G5nVamXMmDG0a9eOhg0bAuaYXVxc8PPzy9X2Rh7z1q1badOmDWlpaXh5eTFv3jzq169PVFRUmRsrwJw5c/jnn39Yv379ZfvK4ufbunVrZs2aRZ06dYiOjubll1+mffv2bNu2rUyO98CBA0ybNo2xY8fy7LPPsn79ev7v//4PFxcXBg8eXKZ/b82fP5+zZ88yZMgQoGz+PD/zzDMkJCRQt25dHB0dyc7O5vXXX2fgwIFA2f9/qSwpz9dQZf3nVNdPun7KcSOPWddP5ef6CXQNBUX/f5OCUiJFYOTIkWzbto0VK1bYuyvFqk6dOkRFRXHu3Dm+//57Bg8ezPLly+3drWJx9OhRRo8ezaJFi3Bzc7N3d0pEzrcfAI0bN6Z169ZUq1aNb7/9Fnd3dzv2rHhYrVZatGjBG2+8AUDTpk3Ztm0bH374IYMHD7Zz74rX9OnT6datG6GhofbuSrH59ttv+fLLL/nqq69o0KABUVFRjBkzhtDQ0DL/+YrcKHT9VPbo+knXT2WdrqGK/jPW9L0SEhAQgKOj42VV+GNjYwkODrZTr0pOzhjL4vhHjRrFzz//zNKlS6lSpYpte3BwMBkZGZw9ezZX+xt5zC4uLtSsWZPmzZszceJEmjRpwrvvvlsmx7px40bi4uJo1qwZTk5OODk5sXz5ct577z2cnJwICgoqc2O+lJ+fH7Vr12bfvn1l8jMOCQmhfv36ubbVq1fPlnJfVn9vHT58mD///JMHH3zQtq0sfr5PPvkkzzzzDP3796dRo0Y88MADPP7440ycOBEou59vWVSer6HK8s+prp90/XSxG3nMl9L1U9n9vaVrqOK5hlJQqoS4uLjQvHlzFi9ebNtmtVpZvHgxbdq0sWPPSkb16tUJDg7ONf6EhATWrl17w47fMAxGjRrFvHnzWLJkCdWrV8+1v3nz5jg7O+ca8+7duzly5MgNO+ZLWa1W0tPTy+RYb7vtNrZu3UpUVJTt1qJFCwYOHGh7XNbGfKmkpCT2799PSEhImfyM27Vrd9ky5Hv27KFatWpA2fy9BTBz5kwCAwPp0aOHbVtZ/HxTUlJwcMh9mePo6IjVagXK7udbFpXna6iy+HOq6yddP5W1MV9K109l7/dWDl1DFdM11PVUZZfCmTNnjuHq6mrMmjXL2LFjh/Hwww8bfn5+RkxMjL27ViQSExONTZs2GZs2bTIAY8qUKcamTZuMw4cPG4ZhLhvp5+dn/Pjjj8aWLVuMu++++4ZeGvSRRx4xfH19jWXLluVaIjQlJcXWZsSIEUZYWJixZMkSY8OGDUabNm2MNm3a2LHX1+6ZZ54xli9fbhw8eNDYsmWL8cwzzxgWi8X4448/DMMoW2PNz8WrxxhG2RvzE088YSxbtsw4ePCgsXLlSqNz585GQECAERcXZxhG2RvvunXrDCcnJ+P111839u7da3z55ZeGh4eH8cUXX9jalLXfW9nZ2UZYWJjx9NNPX7avrH2+gwcPNipXrmxbznju3LlGQECA8dRTT9nalLXPtywry9dQun7S9VNZGWt+dP1UtsZbHq+fDEPXUMV5DaWgVAl7//33jbCwMMPFxcVo1aqVsWbNGnt3qcgsXbrUAC67DR482DAMc+nIF154wQgKCjJcXV2N2267zdi9e7d9O30d8horYMycOdPWJjU11Xj00UeNChUqGB4eHkbv3r2N6Oho+3X6OgwbNsyoVq2a4eLiYlSqVMm47bbbbBdUhlG2xpqfSy+qytqY+/XrZ4SEhBguLi5G5cqVjX79+hn79u2z7S9r4zUMw/jpp5+Mhg0bGq6urkbdunWNjz/+ONf+svZ76/fffzeAPMdQ1j7fhIQEY/To0UZYWJjh5uZmREREGM8995yRnp5ua1PWPt+yrqxeQ+n6SddPZWWs+dH1U9kar2GUv+snw9A1VHFeQ1kMwzAKn18lIiIiIiIiIiJy7VRTSkRERERERERESpyCUiIiIiIiIiIiUuIUlBIRERERERERkRKnoJSIiIiIiIiIiJQ4BaVERERERERERKTEKSglIiIiIiIiIiIlTkEpEREREREREREpcQpKiYiIiIiIiIhIiVNQSkSkiFksFubPn2/vboiIiIjcMHT9JFI+KSglImXKkCFDsFgsl926du1q766JiIiIlEq6fhIRe3GydwdERIpa165dmTlzZq5trq6uduqNiIiISOmn6ycRsQdlSolImePq6kpwcHCuW4UKFQAzNXzatGl069YNd3d3IiIi+P7773O9fuvWrdx66624u7vj7+/Pww8/TFJSUq42M2bMoEGDBri6uhISEsKoUaNy7T958iS9e/fGw8ODWrVqsWDBguIdtIiIiMh10PWTiNiDglIiUu688MIL9OnTh82bNzNw4ED69+/Pzp07AUhOTqZLly5UqFCB9evX89133/Hnn3/mumiaNm0aI0eO5OGHH2br1q0sWLCAmjVr5jrHyy+/TN++fdmyZQvdu3dn4MCBnD59ukTHKSIiIlJUdP0kIsXCEBEpQwYPHmw4Ojoanp6euW6vv/66YRiGARgjRozI9ZrWrVsbjzzyiGEYhvHxxx8bFSpUMJKSkmz7f/nlF8PBwcGIiYkxDMMwQkNDjeeeey7fPgDG888/b3uelJRkAMZvv/1WZOMUERERKSq6fhIRe1FNKREpc2655RamTZuWa1vFihVtj9u0aZNrX5s2bYiKigJg586dNGnSBE9PT9v+du3aYbVa2b17NxaLhRMnTnDbbbddsQ+NGze2Pfb09MTHx4e4uLhrHZKIiIhIsdL1k4jYg4JSIlLmeHp6XpYOXlTc3d0L1M7Z2TnXc4vFgtVqLY4uiYiIiFw3XT+JiD2oppSIlDtr1qy57Hm9evUAqFevHps3byY5Odm2f+XKlTg4OFCnTh28vb0JDw9n8eLFJdpnEREREXvS9ZOIFAdlSolImZOenk5MTEyubU5OTgQEBADw3Xff0aJFC26++Wa+/PJL1q1bx/Tp0wEYOHAgL730EoMHD2bChAnEx8fz2GOP8cADDxAUFATAhAkTGDFiBIGBgXTr1o3ExERWrlzJY489VrIDFRERESkiun4SEXtQUEpEypyFCxcSEhKSa1udOnXYtWsXYK7sMmfOHB599FFCQkL4+uuvqV+/PgAeHh78/vvvjB49mpYtW+Lh4UGfPn2YMmWK7ViDBw8mLS2Nd955h3HjxhEQEMC9995bcgMUERERKWK6fhIRe7AYhmHYuxMiIiXFYrEwb948evXqZe+uiIiIiNwQdP0kIsVFNaVERERERERERKTEKSglIiIiIiIiIiIlTtP3RERERERERESkxClTSkRERERERERESpyCUiIiIiIiIiIiUuIUlBIRERERERERkRKnoJSIiIiIiIiIiJQ4BaVERERERERERKTEKSglIiIiIiIiIiIlTkEpEREREREREREpcQpKiYiIiIiIiIhIiVNQSkREREREREREStz/AxA/IQes9sCBAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/Thesis/backorder_lstm_model_dataset_3_2.h5')\n",
        "print(\"LSTM model saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DK-rjK856-X",
        "outputId": "4884b167-5efd-4d9a-e671-4eb0a479173d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM model saved successfully!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}